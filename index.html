<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="generator" content="Hugo 0.15-DEV" />

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title> 悟剑阁 &middot; 悟剑阁 </title>

  
  <link rel="stylesheet" href="http://luosha865.github.io/css/poole.css">
  <link rel="stylesheet" href="http://luosha865.github.io/css/syntax.css">
  <link rel="stylesheet" href="http://luosha865.github.io/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://luosha865.github.io/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="http://luosha865.github.io/favicon.png">

  
  <link href="http://luosha865.github.io/index.xml" rel="alternate" type="application/rss+xml" title="悟剑阁" />

  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true
    },
  TeX: {
              equationNumbers: {
                  autoNumber: ["AMS"],
                  useLabelIds: true
              }
          },
          "HTML-CSS": {
              linebreaks: {
                  automatic: true
              },
              scale: 85
          },
          SVG: {
              linebreaks: {
                  automatic: true
              }
          }
  });
  </script>
  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</head>

<body class="">

<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <a href="http://luosha865.github.io/"><h1>悟剑阁</h1></a>
      <p class="lead">
       阁中悟剑，红尘练心。 
      </p>
    </div>

    <ul class="sidebar-nav">
      <li><a href="http://luosha865.github.io/">Home</a> </li>
      
        <li><a href="http://luosha865.github.io/post/"> 归档 </a></li>
      
        <li><a href="http://luosha865.github.io/about/"> 关于我 </a></li>
      
    </ul>

    <p>&copy; 2015. All rights reserved. </p>
  </div>
</div>


    <div class="content container">
<div class="posts">

      
  <div class="post">
    <h1 class="post-title">
      <a href="http://luosha865.github.io/archives/150">
        Elasticsearch-HttpServerModule
      </a>
    </h1>

    <span class="post-date">Mon, Jul 27, 2015</span>

    <p>HttpServerModule的请求主要由HttpServer中的HttpServerTransport(默认为NettyHttpServerTransport）类处理。</p>

<p>NettyHttpServerTransport基于netty框架，负责监听并建立连接，信息的处理由内部类HttpChannelPipelineFactory完成。</p>

<p>每当产生一个连接时，都会发出一个ChannelEvent，该Event由一系列的ChannelHandler进行处理。</p>

<p>为了方便组织，这些ChannelHandler被放在一条“流(pipeline)”里，一个ChannelEvent并不会主动的&#8221;流&#8221;经所有的Handler，而是由上一个Handler显式的调用ChannelPipeline.sendUp(Down)stream产生，并交给下一个Handler处理。</p>

<p>换句话说，每个Handler接收到一个ChannelEvent，并处理结束后，如果需要继续处理，那么它需要调用sendUp(Down)stream新发起一个事件。如果它不再发起事件，那么处理就到此结束，即使它后面仍然有Handler没有执行。这个机制可以保证最大的灵活性，当然对Handler的先后顺序也有了更严格的要求。</p>

<p>在流Pipeline里有一个Map(name2ctx)和一个链表(记录head和tail)，pipeline里面会调度关联的多个channelhandler的运行。</p>

<p><a href="http://static.oschina.net/uploads/space/2013/1109/075339_Kjw6_190591.png" target="_blank"><img src="http://static.oschina.net/uploads/space/2013/1109/075339_Kjw6_190591.png" alt="channel pipeline" /></a></p>

<p>在NettyHttpServerTransport中，会流过的channelhandler就包括解码http请求(把多个HttpChunk拼起来并按http协议进行解析)和http请求处理。</p>

<p>在处理http请求，数据流向为：HttpRequestHandler-&gt;<span class="s1">NettyHttpServerTransport</span>-&gt;HttpServerAdapter(HttpServer的内部类Dispatche)-&gt;RestController。</p>

<p>RestController中的处理代码为：</p>

<pre class="lang:java decode:true ">void executeHandler(RestRequest request, RestChannel channel) throws Exception {
        final RestHandler handler = getHandler(request);
        if (handler != null) {
            handler.handleRequest(request, channel);
        } else {
            if (request.method() == RestRequest.Method.OPTIONS) {
                // when we have OPTIONS request, simply send OK by default (with the Access Control Origin header which gets automatically added)
                channel.sendResponse(new BytesRestResponse(OK));
            } else {
                channel.sendResponse(new BytesRestResponse(BAD_REQUEST, "No handler found for uri [" + request.uri() + "] and method [" + request.method() + "]"));
            }
        }
    }

    private RestHandler getHandler(RestRequest request) {
        String path = getPath(request);
        RestRequest.Method method = request.method();
        if (method == RestRequest.Method.GET) {
            return getHandlers.retrieve(path, request.params());
        } else if (method == RestRequest.Method.POST) {
            return postHandlers.retrieve(path, request.params());
        } else if (method == RestRequest.Method.PUT) {
            return putHandlers.retrieve(path, request.params());
        } else if (method == RestRequest.Method.DELETE) {
            return deleteHandlers.retrieve(path, request.params());
        } else if (method == RestRequest.Method.HEAD) {
            return headHandlers.retrieve(path, request.params());
        } else if (method == RestRequest.Method.OPTIONS) {
            return optionsHandlers.retrieve(path, request.params());
        } else {
            return null;
        }
    }</pre>

<p>可以看到，这里会根据注册的handler，选择合适的处理逻辑。</p>

<p>这些handler由函数registerHandler进行注册，函数签名如下：</p>

<p class="p1">
  <span class="s1">public</span> <span class="s1">void</span> registerHandler(RestRequest.Method <span class="s2">method</span>, String <span class="s2">path</span>, RestHandler <span class="s3">handler</span>)
</p>

<p class="p1">
  比如对RestGetIndicesAction类，有如下构造函数：
</p>

<pre class="lang:java decode:true">public RestGetIndicesAction(Settings settings, RestController controller, Client client) {
        super(settings, controller, client);
        controller.registerHandler(GET, "/{index}", this);
        controller.registerHandler(GET, "/{index}/{type}", this);
    }</pre>

<p>netty参考：</p>

<p><a href="http://my.oschina.net/flashsword/blog/162936">http://my.oschina.net/flashsword/blog/162936</a></p>

<p><a href="http://my.oschina.net/flashsword/blog/164237">http://my.oschina.net/flashsword/blog/164237</a></p>

<p><a href="http://my.oschina.net/flashsword/blog/169361">http://my.oschina.net/flashsword/blog/169361</a></p>

<p><a href="http://my.oschina.net/flashsword/blog/178561">http://my.oschina.net/flashsword/blog/178561</a></p>

<p><a href="http://my.oschina.net/flashsword/blog/197963">http://my.oschina.net/flashsword/blog/197963</a></p>

<p>{{ template &ldquo;_internal/disqus.html&rdquo; . }}</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://luosha865.github.io/archives/100">
        Tornado框架简析
      </a>
    </h1>

    <span class="post-date">Thu, Feb 5, 2015</span>

    <p>Tornado是一款轻量级的Web服务器，同时又是一个开发框架。采用单线程非阻塞I/O模型(epoll)，主要是为了应对高并发 访问量而被开发出来，尤其适用于comet应用。</p>

<p>Tornado服务器3大核心模块:</p>

<p>(1) IOLoop</p>

<p>Tornado为了实现高并发和高性能，使用了一个IOLoop来处理socket的读写事件，IOLoop基于epoll，可以高效的响应网络事件。这是Tornado高效的保证。</p>

<p>tornado.ioloop.IOLoop.instance().start()</p>

<p>IOLoop使用了单例模式，处理所有IO事件，</p>

<p>实现为EPollIOLoop-&gt;PollIOLoop-&gt;IOLoop-&gt;Configurable</p>

<p>IOLoop中有四个重要的数据集： _events 和 _handlers 保存I/O事件和对应的处理器， _callbacks 和 _timeouts 保存（超时）回调。</p>

<p>关键函数：</p>

<pre class="lang:python decode:true ">def initialize(self, impl, time_func=None):
    super(PollIOLoop, self).initialize()
    self._impl = impl
    if hasattr(self._impl, 'fileno'):
        set_close_exec(self._impl.fileno())
    self.time_func = time_func or time.time
    #handlers 是一个函数集字典
    self._handlers = {}
    self._events = {}
    #回调函数集合
    self._callbacks = []
    self._callback_lock = threading.Lock()
    self._timeouts = []
    self._cancellations = 0
    self._running = False
    self._stopped = False
    self._closing = False
    self._thread_ident = None
    self._blocking_signal_threshold = None
    self._timeout_counter = itertools.count()

    # Create a pipe that we send bogus data to when we want to wake
    # the I/O loop when it is idle
    self._waker = Waker()
    self.add_handler(self._waker.fileno(),
                     lambda fd, events: self._waker.consume(),
                     self.READ)</pre>

<p>其中，waker是一个发伪数据用的类，在需要时，我们可以用它唤醒空闲的I/O Loop。当我们调用add_callback时，为了让回调函数运行，可能会需要使用它发送一个伪数据。</p>

<pre class="lang:python decode:true">#将文件描述符发生相应的事件时的回调函数对应
def add_handler(self, fd, handler, events):
    """Registers the given handler to receive the given events for fd."""
    self._handlers[fd] = stack_context.wrap(handler)
    #在 epoll 中注册对应事件
    #epoll_ctl
    self._impl.register(fd, events | self.ERROR)
</pre>

<p>其中stack_context.wrap()对handler进行封装，封装后记录了上下文信息。而_impl是对epoll的封装。</p>

<p>所以，只要把所有事件在IOLoop中进行注册，运行start函数后，就会进入进程的监听循环，循环监听所有的fd，并调用fd对应的handler。循环过程参考start()函数。</p>

<pre class="lang:python decode:true">def start(self):
    while True:
        with self._callback_lock:
            callbacks = self._callbacks
            self._callbacks = []
        #运行所有callback
        for callback in callbacks:
            self._run_callback(callback)
        #取事件
        event_pairs = self._impl.poll(poll_timeout)
        self._events.update(event_pairs)
        while self._events:
            fd, events = self._events.popitem()
            try:
                #调用事件handler
                fd_obj, handler_func = self._handlers[fd]
                handler_func(fd_obj, events)
            except (OSError, IOError) as e:
                if errno_from_exception(e) == errno.EPIPE:
                    # Happens when the client closes the connection
                    pass
                else:
                    self.handle_callback_exception(self._handlers.get(fd))
            except Exception:
                self.handle_callback_exception(self._handlers.get(fd))
</pre>

<p>当poll中发现fp有read事件时，会调用对应的callback方法。如果fd是监听的fd，那么这个回调handler就是accept_handler函数(见下面HttpConnection的bind和add_scokets函数)。该方法会Accept连接并且紧跟着创建IOStream对象，read_until方法读完数据后，则调用_run_callback把处理函数（self._header_callback）加到IOLoop中，等到下次轮询时在最前面处理。</p>

<p>(2) IOStream</p>

<p>为了在处理请求的时候，实现对socket的异步读写， Tornado实现了IOStream类，用来处理socket的异步读写，负责异步通讯。</p>

<p>主要包括3个函数，</p>

<p>1.read_bytes(bytes,callback)在有固定的字节的数据到来的时候调用回调函数</p>

<p>2.read_until(delimiter,callback)在读取到固定的字符序列结尾后调用回调函数</p>

<p>3.write(data)：异步写</p>

<p>(3) HTTPConnection</p>

<p>这个类用来处理http的请求， 包括读取http请求头， 读取post过来的数据，调用用户自定义的处理方法。以及把响应数据写给客户端socket。</p>

<pre class="lang:python decode:true">def bind(self, port, address=None, family=socket.AF_UNSPEC, backlog=128): 
    sockets = bind_sockets(port, address=address, family=family,backlog=backlog)
        if self._started:
            self.add_sockets(sockets)
        else:
            self._pending_sockets.extend(sockets)
def add_sockets(self, sockets):
    if self.io_loop is None:
        self.io_loop = IOLoop.current()
    for sock in sockets:
        self._sockets[sock.fileno()] = sock
        add_accept_handler(sock, self._handle_connection,io_loop=self.io_loop)
</pre>

<p>socket启动后，监听各个sockets，事件到来时，调用_handle_connection。</p>

<pre class="lang:python decode:true ">def _handle_connection(self, connection, address):
    if self.ssl_options is not None:
        connection = ssl_wrap_socket(connection,self.ssl_options,
                                     server_side=True,
                                     do_handshake_on_connect=False)
        if self.ssl_options is not None:
            stream = SSLIOStream(connection, io_loop=self.io_loop,
                                 max_buffer_size=self.max_buffer_size,
                                 read_chunk_size=self.read_chunk_size)
        else:
            stream = IOStream(connection, io_loop=self.io_loop,
                              max_buffer_size=self.max_buffer_size,
                              read_chunk_size=self.read_chunk_size)
        self.handle_stream(stream, address)
def handle_stream(self, stream, address):
    context = _HTTPRequestContext(stream, address,
                                  self.protocol)
    conn = HTTP1ServerConnection(
        stream, self.conn_params, context)
    self._connections.add(conn)
    conn.start_serving(self)
def start_serving(self, delegate):
    assert isinstance(delegate, httputil.HTTPServerConnectionDelegate)
    self._serving_future = self._server_request_loop(delegate)
    # Register the future on the IOLoop so its errors get logged.
    self.stream.io_loop.add_future(self._serving_future,
                                   lambda f: f.result())
</pre>

<p>如前面所述，这里Accept连接并且紧跟着创建IOStream对象(不考虑https)，调用handle_stream-&gt;start_serving-&gt;_server_request_loop处理请求。最后会调用_read_message读取数据，并注册回调函数。</p>

<p>最后抄一张图过来：</p>

<p><img class="alignnone wp-image-108 size-large" src="http://blog.sword865.com/wp-content/uploads/2015/02/QQ20150205-1@2x-1024x593.png" alt="QQ20150205-1@2x" width="615" height="356" /></p>

<p>参考：</p>

<p><a href="http://www.cnblogs.com/Bozh/archive/2012/07/22/2603976.html">http://www.cnblogs.com/Bozh/archive/2012/07/22/2603976.html</a></p>

<p><a href="http://kenby.iteye.com/blog/1159621">http://kenby.iteye.com/blog/1159621</a></p>

<p><a href="http://www.nowamagic.net/academy/detail/13321030">http://www.nowamagic.net/academy/detail/13321030</a></p>

<p><a href="http://www.yeolar.com/note/2013/02/09/tornado-async-networking/">http://www.yeolar.com/note/2013/02/09/tornado-async-networking/</a></p>

<p>源码：</p>

<p><a href="https://github.com/tornadoweb/tornado">https://github.com/tornadoweb/tornado</a></p>

<p style="margin:0;padding:0;height:1px;overflow:hidden;">
  <a href="http://www.wumii.com/widget/relatedItems" style="border:0;"><img src="http://static.wumii.cn/images/pixel.png" alt="无觅相关文章插件，快速提升流量" style="border:0;padding:0;margin:0;" /></a>
</p>

<p>{{ template &ldquo;_internal/disqus.html&rdquo; . }}</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://luosha865.github.io/archives/86">
        Lucene索引文件学习
      </a>
    </h1>

    <span class="post-date">Wed, Feb 4, 2015</span>

    <p><span style="font-size: 12px;"> 最近在做搜索，抽空看一下lucene，资料挺多的，不过大部分都是3.x了……在对着官方文档大概看一下。</span></p>

<p><span style="font-size: 12px;">优化后的lucene索引文件(4.9.0)</span></p>

<p><span style="font-size: 12px;"><img title="NewImage.png" src="http://blog.sword865.com/wp-content/uploads/2015/02/NewImage.png" alt="NewImage" width="200" height="146" border="0" /></span></p>

<p><span style="font-size: 12px;">一、段文件</span></p>

<p><span style="font-size: 12px;">1.段文件：segments_5p和segments.gen。</span></p>

<p><span style="font-size: 12px;">segments.gen保存当前段文件版本信息。</span></p>

<ul style="color: #353833; font-family: Arial, Helvetica, sans-serif; font-size: 12px;">
  <li>
    <span style="font-size: 12px;"><tt style="font-size: 1.2em;">segments.gen</tt>: GenHeader, Generation, Generation, Footer</span>
  </li>
</ul>

<p><span style="font-size: 12px;">segments_N（segments_5p）保存最新的段的信息，包括段的个数，每个段的段名、文档数等信息。</span></p>

<ul style="font-size: 12px; color: #353833; font-family: Arial, Helvetica, sans-serif;">
  <li>
    <span style="font-size: 12px;"><tt style="font-size: 1.2em;">segments_N</tt>: Header, Version, NameCounter, SegCount, <SegName, SegCodec, DelGen, DeletionCount, FieldInfosGen, DocValuesGen, UpdatesFiles><sup style="font-size: 0.6em;">SegCount</sup>, CommitUserData, Footer</span>
  </li>
</ul>

<p><span style="font-size: 12px;">  源码参考：SegmentInfos.read(Directory directory, String segmentFileName):</span></p>

<p><span style="font-size: 12px;">2.段信息：*.si，存储段的基本信息。</span></p>

<ul style="color: #353833; font-family: Arial, Helvetica, sans-serif; font-size: 12px;">
  <li>
    <span style="font-size: 12px;"><tt style="font-size: 1.2em;">.si</tt>: Header, SegVersion, SegSize, IsCompoundFile, Diagnostics, Attributes, Files</span>
  </li>
</ul>

<p><span style="font-size: 12px;">       只对4.0-4.5使用，新版已经抛弃了，可以无视。  </span></p>

<p><span style="font-size: 12px;">二、域文件</span></p>

<p><span style="font-size: 12px;">1.域(field)：*.fnm ，存储域的信息。</span></p>

<ul style="font-size: 12px; color: #353833; font-family: Arial, Helvetica, sans-serif;">
  <li>
    <span style="font-size: 12px;">FieldInfos (.fnm) &#8211;> Header,FieldsCount, <FieldName,FieldNumber, FieldBits,DocValuesBits,DocValuesGen,Attributes> <sup style="font-size: 0.6em; color: #353833; font-family: Arial, Helvetica, sans-serif;">FieldsCount</sup>,Footer</span>
  </li>
</ul>

<div>
  <p style="margin: 0px; font-size: 11px; font-family: Monaco;">
    <span style="font-size: 12px;">  源码参考：org.apache.lucene.codecs.lucene46.Lucene46FieldInfosFormat</span>
  </p>
  
  <p style="margin: 0px; font-size: 11px; font-family: Monaco;">
    <span style="font-size: 12px;">2.域(field)索引：*.fdx，存储到域数据的指针。</span>
  </p>
</div>

<ul style="color: #353833; font-family: Arial, Helvetica, sans-serif; font-size: 12px;">
  <li>
    <span style="font-size: 12px;">FieldsIndex (.fdx) &#8211;> <Header>, <ChunkIndex></span>
  </li>
</ul>

<p><span style="font-size: 12px;">   源码参考：org.apache.lucene.codecs.lucene41.Lucene41StoredFieldsFormat</span></p>

<p><span style="font-size: 12px;">3.域(field)数据：*.fdt，存储文档的域，话说这个结构比较复杂，简单列一下。</span></p>

<ul style="font-size: 12px; color: #353833; font-family: Arial, Helvetica, sans-serif;">
  <li>
    <span style="font-size: 12px;">FieldData (.fdt) &#8211;> <Header>, PackedIntsVersion, <Chunk><sup style="font-size: 0.6em;">ChunkCount</sup></span>
  </li>
  <li>
    <span style="font-size: 12px;">ChunkCount is not known in advance and is the number of chunks necessary to store all document of the segment</span>
  </li>
  <li>
    <span style="font-size: 12px;">Chunk &#8211;> DocBase, ChunkDocs, DocFieldCounts, DocLengths, <CompressedDocs></span>
  </li>
</ul>

<p><span style="font-size: 12px;">  源码参考：org.apache.lucene.codecs.lucene41.Lucene41StoredFieldsFormat</span></p>

<p><span style="font-size: 12px;">三、字典文件</span></p>

<p><span style="font-size: 12px;">4.项(term)字典：*.tim，存储项的信息。</span></p>

<ul style="color: #353833; font-family: Arial, Helvetica, sans-serif; font-size: 12px;">
  <li>
    <span style="font-size: 12px;">TermsDict (.tim) &#8211;> Header, <em>PostingsHeader</em>, NodeBlock<sup style="font-size: 0.6em;">NumBlocks</sup>, FieldSummary, DirOffset, Footer</span>
  </li>
</ul>

<p><span style="font-size: 12px;">  源码参考：org.apache.lucene.codecs.lucene41.Lucene41PostingsFormat</span></p>

<p><span style="font-size: 12px;">5.项(term)索引：*.tip，到项字典的索引。</span></p>

<ul style="color: #353833; font-family: Arial, Helvetica, sans-serif; font-size: 12px;">
  <li>
    <span style="font-size: 12px;">TermsIndex (.tip) &#8211;> Header, FSTIndex<sup style="font-size: 0.6em;">NumFields</sup> <IndexStartFP><sup style="font-size: 0.6em;">NumFields</sup>, DirOffset, Footer</span>
  </li>
</ul>

<p><span style="font-size: 12px;">  源码参考：org.apache.lucene.codecs.lucene41.Lucene41PostingsFormat </span></p>

<p><span style="font-size: 12px;">四、其他文件 </span></p>

<p><span style="font-size: 12px;">6.频率：*.doc，包括一个文档列表，列表中每一个项都有一个频数。</span></p>

<ul style="color: #353833; font-family: Arial, Helvetica, sans-serif; font-size: 12px;">
  <li>
    <span style="font-size: 12px;">docFile(.doc) &#8211;> Header, <TermFreqs, SkipData?><sup style="font-size: 0.6em;">TermCount</sup>, Footer</span>
  </li>
</ul>

<p><span style="font-size: 12px;">  源码参考：org.apache.lucene.codecs.lucene41.Lucene41PostingsFormat </span></p>

<p><span style="font-size: 12px;">7.位置：*.pos，存储项在索引中出现的位置信息。</span></p>

<ul style="color: #353833; font-family: Arial, Helvetica, sans-serif; font-size: 12px;">
  <li>
    <span style="font-size: 12px;">PosFile(.pos) &#8211;> Header, <TermPositions> <sup style="font-size: 0.6em;">TermCount</sup>, Footer</span>
  </li>
</ul>

<p><span style="font-size: 12px;">  源码参考：org.apache.lucene.codecs.lucene41.Lucene41PostingsFormat</span></p>

<p><span style="font-size: 12px;"> 8.norm文件：<em>.nvd，</em>.nvm，编码文档和域的长度已经boost factors。</span></p>

<ul style="font-size: 12px; color: #353833; font-family: Arial, Helvetica, sans-serif;">
  <li>
    <span style="font-size: 12px;">Norms data (.nvd) &#8211;> Header,<Uncompressed | TableCompressed | DeltaCompressed><sup style="font-size: 0.6em; color: #353833; font-family: Arial, Helvetica, sans-serif;">NumFields</sup>,Footer</span>
  </li>
</ul>

<p><span style="font-size: 12px;">  源码参考：org.apache.lucene.codecs.lucene49.Lucene49NormsFormat</span></p>

<p><span style="font-size: 12px;"> 除此之外，还可能有一些其他文件，暂且不表。</span></p>

<p><span style="font-size: 12px;"> 参考：</span></p>

<p><span style="font-size: 12px;"><a href="http://lucene.apache.org/core/4_9_0/core/org/apache/lucene/codecs/lucene49/package-summary.html#File_Naming">http://lucene.apache.org/core/4_9_0/core/org/apache/lucene/codecs/lucene49/package-summary.html#File_Naming</a></span></p>

<p><span style="font-size: 12px;"><a href="http://www.cnblogs.com/forfuture1978/category/300665.html">http://www.cnblogs.com/forfuture1978/category/300665.html</a></span></p>

<p> {{ template &ldquo;_internal/disqus.html&rdquo; . }}</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://luosha865.github.io/about/">
        关于
      </a>
    </h1>

    <span class="post-date">Sun, Dec 7, 2014</span>

    <p>这里是我的技术博客。</p>

<p>后台/算法工程师</p>

<p><del>机器学习方向研究生</del></p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://luosha865.github.io/archives/5">
        基于标签的推荐系统
      </a>
    </h1>

    <span class="post-date">Mon, Nov 17, 2014</span>

    <p>一、基于图模型的推荐</p>

<p>在不考虑标签时，基于二项图有两种随机游走的图推荐算法：</p>

<p>1.probability spreading</p>

<p>随机游走算法，在游走中，每个目标得到权重是基于归属者的边计算出来的。</p>

<p>每次传播(item-&gt;user-&gt;item)后用户Ui的兴趣向量：</p>

<div>$$f_j^p=\sum_{l=1}^{n}\sum_{s=1}^{m}\frac{a_{lj}a_{ls}a_{is}}{K(U_l)K(I_s)},j=1…m$$</div>

<p>2.heat spreading</p>

<p>规则与ProbS相反，在游走中，每个目标得到权重是基于自己的边计算出来的。</p>

<p>每次传播后用户Ui的兴趣向量：</p>

<div>$$f_h^p=\frac{1}{K(I_j)}\sum_{l=1}^{n}\sum_{s=1}^{m}\frac{a_{lj}a_{ls}a_{is}}{K(U_l)},j=1…m$$</div>

<p>其中：</p>

<div>$$K(I_j)=\sum_{l=1}^{m}a_{lj}$$</div>

<p>是节目j的邻域大小，</p>

<div>$$K(U_l)=\sum_{l=1}^{n}a_{ls}$$</div>

<p>是用户l的邻域大小。</p>

<p>$a_{ij}$是表示用户i和物品j之间是否有边存在的二元向量。</p>

<p>相比之下，Heats算法倾向于降低热门item的权重，而Probs中与增强对热门item的推荐。</p>

<p>&nbsp;</p>

<p>在随机游走算法的基础上，有基于<span style="color: #333333; font-family: arial; font-size: 13px; line-height: 20.0200004577637px;">三分图的标签推荐算法：</span></p>

<p><img title="NewImage.png" src="http://images.cnitblog.com/blog/52809/201411/171255254884996.png" alt="NewImage" width="600" height="305" border="0" /></p>

<p>图中，用户i的每个item的权重（1 or 0）会同时像用户和标签进行传播，这样每次传播后的兴趣向量：</p>

<p>$f_j^t=\lambda f_j^p + (1-\lambda) f_j^{pt}$，其中$f_j^p$和$f_j^{pt}$分别是从(item-&gt;user-&gt;item)和(item-&gt;tag-&gt;item)传播后得到的权重。</p>

<p><span style="font-size: 14px;">二、矩阵分解的张量模型</span></p>

<p>对三元阵$Y_{(n\times m\times t)}$进行矩阵分解，C为核张量，U,I,T为用户特征，物品特征和标签特征矩阵。</p>

<p>根据分解结果对Y进行填充。</p>

<p><img title="NewImage.png" src="http://images.cnitblog.com/blog/52809/201411/171508548949009.png" alt="NewImage" width="600" height="260" border="0" /></p>

<p>填充后即得到评分矩阵</p>

<p><span style="font-size: 14px;"> </span></p>

<p>{{ template &ldquo;_internal/disqus.html&rdquo; . }}</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://luosha865.github.io/archives/6">
        Google在KDD2013上关于CTR的一篇论文
      </a>
    </h1>

    <span class="post-date">Sat, Aug 3, 2013</span>

    <p>最近在做CTR，刚好Google在KDD发了一篇文章，讲了他们的一些尝试，总结一下：</p>

<p>先是一些公式的符号说明：</p>

<p><a href="http://images.cnitblog.com/blog/52809/201308/04011358-7d9b9023e473455e9c21b18486a58fa8.png"><img style="background-image: none; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border-width: 0px;" title="image" src="http://images.cnitblog.com/blog/52809/201308/04011358-949b9f116ca94563ab5a0efa047697db.png" alt="image" width="447" height="98" border="0" /></a></p>

<p>一、优化算法</p>

<p>CTR中经常用Logistic regression进行训练，一个常用的Loss Function为</p>

<p><a href="http://images.cnitblog.com/blog/52809/201308/04011358-9e64ee86e7f14dbd8a3da9f8a2bb7c13.png"><img style="background-image: none; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border-width: 0px;" title="image" src="http://images.cnitblog.com/blog/52809/201308/04011358-03407ff016d04735b28103abc573d428.png" alt="image" width="329" height="34" border="0" /></a></p>

<p>Online gradient descent(OGD)是一个常用的优化方法，但是在加上L1正则化后，这种方法不能产生有效的稀疏模型。相比之下 Regularized Dual Averaging (RDA)拥有更好的稀疏性，但是精度不如OGD好。</p>

<p>FTRL-Proximal 方法可以同时得到稀疏性与精确性，不同于OGD的迭代步骤：</p>

<p><a href="http://images.cnitblog.com/blog/52809/201308/04011358-2e856d4483c64ef0a668ee8c8df2a548.png"><img style="background-image: none; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border-width: 0px;" title="image" src="http://images.cnitblog.com/blog/52809/201308/04011359-6f55d3e1f55f4389979bec14102120b5.png" alt="image" width="187" height="39" border="0" /></a></p>

<p>其中$\eta_t$是一个非增的学习率</p>

<p>FTRL-Proximal通过下式迭代：</p>

<p><a href="http://images.cnitblog.com/blog/52809/201308/04011359-900ea01f64a547bd99cefe8e375a3a9d.png"><img style="background-image: none; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border-width: 0px;" title="image" src="http://images.cnitblog.com/blog/52809/201308/04011359-37b635900b57402a9efc1d0fbf12e7d2.png" alt="image" width="482" height="60" border="0" /></a></p>

<p>&nbsp;</p>

<p>参数$\sigma$是学习率，一般我们有 ${\sum_{s=1}^t\sigma_s=\frac{1}{\eta_t}}$。</p>

<p>更新公式：</p>

<p><a href="http://images.cnitblog.com/blog/52809/201308/04011359-5cd9cb60ba40409ca3ef8988e2e11f47.png"><img style="background-image: none; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border-width: 0px;" title="image" src="http://images.cnitblog.com/blog/52809/201308/04011359-ade11cdad0064b918877e4fbdd0babb1.png" alt="image" width="377" height="74" border="0" /></a></p>

<p>算法如下：</p>

<p><a href="http://images.cnitblog.com/blog/52809/201308/04011359-8100f10672694bffa4e1a46fc3b01719.png"><img style="background-image: none; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border: 0px;" title="image" src="http://images.cnitblog.com/blog/52809/201308/04011400-cbd594724918403f8c25f0a88ee489ae.png" alt="image" width="428" height="368" border="0" /></a></p>

<p>这里多个一个 $\lambda_2$ 是一个L2正则化参数。</p>

<p>二、学习率</p>

<p>$$\displaystyle \eta_t=\frac{1}{\sqrt{t}}$$</p>

<p>由于在求解时，这样，对每一个坐标我们都使用了同样的参数，这样一些没有使用的坐标的参数也会下降，显然这不太合理。</p>

<p>一个近似最优的选择是：</p>

<p><a href="http://images.cnitblog.com/blog/52809/201308/04011400-7ee5511abe4e40a38bf4950df39c1335.png"><img style="background-image: none; padding-top: 0px; padding-left: 0px; margin: 0px; display: inline; padding-right: 0px; border: 0px;" title="image" src="http://images.cnitblog.com/blog/52809/201308/04011400-76896e8c7af94f00a204a895b9e243d8.png" alt="image" width="244" height="78" border="0" /></a>g是梯度向量</p>

<p>&nbsp;</p>

<p>三、存储空间</p>

<p>1.特征选择</p>

<p>在CTR中，跟多特征仅仅出现了一次(In fact, in some of our models, half the unique features occur only once in the entire training set of billions of examples)，这样特征几乎没有什么用，但是存储起来非常浪费空间。L1正则化虽然解决了一些问题，但是这样降低了一些精度，因此另一个选择是</p>

<p>probabilistic feature inclusion，这种方法中，一个特征第一次出现时，会以一定的概率被保存使用。关于这个概率Google尝试了两种方法：</p>

<p>Poisson Inclusion：以概率p增加特征，这样一般特征被加入就需要出现1/p次</p>

<p>Bloom Filter Inclusion：用一系列的Bloom flters来检测特征的前n次出现，一旦检测到出现了n次（因为BF有冲突，所以实际可能少于n），就加入模型并用在后面的训练中。</p>

<p>2.系数编码</p>

<p>因为大部分系数都在-2和2之间，因此使用了定点的q2.13编码，同时也保证了小数的一些精度。编码包括一位的符号，2位的整数和13位的小数。</p>

<p>因此误差可能在OGD算法中发散，因此使用了一个简单的随机取整策略：</p>

<p><a href="http://images.cnitblog.com/blog/52809/201308/04011400-578afca151244861974554d833d64ade.png"><img style="background-image: none; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border: 0px;" title="image" src="http://images.cnitblog.com/blog/52809/201308/04011400-eea1a760e2124dcca8efa0e15f16c808.png" alt="image" width="285" height="46" border="0" /></a>R是一个0到1的随机整数。</p>

<p>3.多个相似模型的训练</p>

<p>在测试一些超参数的影响时，同时训练多个模型非常有用。观察发现，有些数据可以被多个模型共用，但是另外一些（如系数）不能，如果把模型的系数存在一个HASH表里，就可以让多个变体同时使用这些参数，比如学习率。</p>

<p>4.单值结构</p>

<p>有时我们想训练一些模型，他们之间只是删除或增加了一些特征。单值特征为每一个特征存了一个权重，权重被所有有该特征的模型共享，学习方法如下：</p>

<p>在OGD更新中，每个模型用他自己的的那部分特征计算一个Loss, 然后对每一个特征，每一个模型计算一个新的系数，最后把所有值平均后存为单值。该单值下一步被所有模型使用。</p>

<p>5.计数与梯度</p>

<p>假设所有事件包括统一特征的概率相同（一个粗糙但是有效的估计），其中出现了P次，没有出现N次，那么出现的概率就是p=P/(N+P),那么在logistic regression中，正事件的导数是p-1,负事件p，梯度的平方和就是：</p>

<p><a href="http://images.cnitblog.com/blog/52809/201308/04011401-abaa4c9233c443179f17fc62822d599f.png"><img style="background-image: none; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border: 0px;" title="image" src="http://images.cnitblog.com/blog/52809/201308/04011401-7fc7cc332f634239bff48a489dd1c997.png" alt="image" width="389" height="145" border="0" /></a></p>

<p>&nbsp;</p>

<p>6.采样训练数据：</p>

<p>CTR中的负样本远高与正样本，因此采样的数据包括满足所有的正样本和部分负样本：</p>

<p><a href="http://images.cnitblog.com/blog/52809/201308/04011401-46a2083bf5904c3c986dcacfc63bb0e2.png"><img style="background-image: none; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border: 0px;" title="image" src="http://images.cnitblog.com/blog/52809/201308/04011401-10e2c56d7cf94e08ab2d89e884481391.png" alt="image" width="421" height="64" border="0" /></a></p>

<p>在训练中给正样本1的权重，负样本1/r的权重以避免模型结果出错。权重乘如Loss Function对应项中。</p>

<p>&nbsp;</p>

<p><a href="http://images.cnitblog.com/blog/52809/201308/04011401-301af9b06f524c5d947e9739b2e16cf8.png"><img style="background-image: none; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border: 0px;" title="image" src="http://images.cnitblog.com/blog/52809/201308/04011401-cf3e0ae967e148a7ae5365ccc0f7fc51.png" alt="image" width="349" height="64" border="0" /></a></p>

<p><a href="http://images.cnitblog.com/blog/52809/201308/04011402-eeef6de793ad4baaae18d7251f6d482d.png"><img style="background-image: none; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border: 0px;" title="image" src="http://images.cnitblog.com/blog/52809/201308/04011402-a833a1c25f19478f92c19b6b06db8ed0.png" alt="image" width="467" height="52" border="0" /></a></p>

<p>四、模型评价1</p>

<p>1.进度验证(Progressive Validation)</p>

<p>因为计算梯度的同时需要计算预测值，因此可以收集这些值。在线的loss反映了算法的表现&#8212;他度量了训练一个数据前得到的预测结果。这样也使得所有数据被同时作用训练集和测试集使用。</p>

<p>2.可视化加强理解</p>

<p><a href="http://images.cnitblog.com/blog/52809/201308/04011403-ea4fafaae6b5448ca3826eb98a107bf1.png"><img style="background-image: none; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border: 0px;" title="image" src="http://images.cnitblog.com/blog/52809/201308/04011404-eaf5de3e66314e82aa675ba92be4fcd8.png" alt="image" width="562" height="267" border="0" /></a></p>

<p>&nbsp;</p>

<p>上图对query进行了切片后，将两个模型与一个控制模型模型进行了比较。度量用颜色表示，每行是一个模型，每列是一个切片。</p>

<p>五、置信估计</p>

<p><a href="http://images.cnitblog.com/blog/52809/201308/04011405-1ba03bff12c740beb22d7c59e6e6d899.png"><img style="background-image: none; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border: 0px;" title="image" src="http://images.cnitblog.com/blog/52809/201308/04011405-3f7f56dae9a34817a96f412ad13a8dcd.png" alt="image" width="434" height="119" border="0" /></a></p>

<p>六、预测矫正</p>

<p>矫正的数据<a href="http://images.cnitblog.com/blog/52809/201308/04011405-372b84501cc84940a965b739cf97a9d9.png"><img style="background-image: none; padding-top: 0px; padding-left: 0px; display: inline; padding-right: 0px; border: 0px;" title="image" src="http://images.cnitblog.com/blog/52809/201308/04011405-93a76b43c030441c9295ded6239bbb1c.png" alt="image" width="71" height="34" border="0" /></a>p是模型预测的CTR，d是一些训练数据。</p>

<p>一个常用矫正：<a href="http://images.cnitblog.com/blog/52809/201308/04011406-75988e6dea0d4d83b698e96019c9753b.png"><img style="background-image: none; padding-top: 0px; padding-left: 0px; margin: 0px; display: inline; padding-right: 0px; border: 0px;" title="image" src="http://images.cnitblog.com/blog/52809/201308/04011406-e83e0f3784944b10812b43ca5c74a2c4.png" alt="image" width="112" height="43" border="0" /></a></p>

<p>两个参数可以用Poisson regression在数据上训练。</p>

<p style="margin:0;padding:0;height:1px;overflow:hidden;">
  <a href="http://www.wumii.com/widget/relatedItems" style="border:0;"><img src="http://static.wumii.cn/images/pixel.png" alt="无觅相关文章插件，快速提升流量" style="border:0;padding:0;margin:0;" /></a>
</p>

<p>{{ template &ldquo;_internal/disqus.html&rdquo; . }}</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://luosha865.github.io/archives/7">
        [转] Deep Learning（深度学习）学习笔记整理系列
      </a>
    </h1>

    <span class="post-date">Fri, Apr 26, 2013</span>

    <p>转一套Deep Learning的文章</p>

<p><a href="http://blog.csdn.net/zouxy09/article/details/8775360">http://blog.csdn.net/zouxy09/article/details/8775360</a></p>

<p>&nbsp;</p>

<p>顺便附上翻译的UFLDL</p>

<p><a href="http://deeplearning.stanford.edu/wiki/index.php/UFLDL%E6%95%99%E7%A8%8B">http://deeplearning.stanford.edu/wiki/index.php/UFLDL%E6%95%99%E7%A8%8B</a></p>

<p>{{ template &ldquo;_internal/disqus.html&rdquo; . }}</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://luosha865.github.io/archives/8">
        决策粗糙集
      </a>
    </h1>

    <span class="post-date">Thu, Apr 25, 2013</span>

    <p>今天收拾资料，发现了以前刚接触粗糙集时写的一个综述，好久没写博客，发上来充数好了</p>

<p>一、粗糙集模型<a href="data:image/png;base64,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">1</a></p>

<p>粗糙集是Pawlak于上世纪八十年代提出的一种不确定数学模型。该模型以有限集合上的等价关系为基础，定义了上下近似两个基本操作。该模型与它的其他一般化或变种形式有着较为广泛的应用。</p>

<p>1.1<a name="OLE_LINK19"></a><a name="OLE_LINK18"></a>Pawlak粗糙集模型</p>

<p>Pawlak粗糙集模型是以一个有限集合与集合上的一个等价关系为基础的。所谓的二元等价关系是一种满足自反性，对称性和传递性的关系的二元关系。因为这些性质，一个二元等价关系将一个集合分割成一到多个互不相较子集，形成了集合的一个分割，记为U/R，其中的元素与他们的并被称为精确集。</p>

<p>在这一基础上，Pawlak提出了近似的概念，所谓近似，是通过一个已有集合U的一个分割中的集合的并集对一个U的任意子集X进行逼近，作为X的近似。包括上近似于下近似两种。如，设R是U上一个等价关系，则，X的上下近似分别为:</p>

<p><img src="data:image/png;base64,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" alt="" /></p>

<p>通过2中近似，我们可以把U分为三个部分，分别称为<a name="OLE_LINK4"></a><a name="OLE_LINK3"></a>正域POS(X)，边界域BND(X)，和负域NEG(X),这三个域都是U/R上一些集合的并，也就是可以用R精确表示的精确集：分别表示一定属于X，可能属于X，和一定不属于X三种定义。</p>

<p><img src="data:image/png;base64,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" alt="" /></p>

<p>进一步的，对于任意两个等价关系R，D定义：</p>

<p><img src="data:image/png;base64,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" alt="" /></p>

<p>可以证明的是，在Pawlak粗糙集模型中<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHEAAAAaCAIAAAAPLyQeAAACbUlEQVRoge1Y27XEIAi0LguiHqqhGYvJ/VCjvLLGNZu9ezJ/+xBhGEAN24PVCHc78IN4OF2Ph9P1+FecEkRM7xhIGIFWeeNCcZowhhBCCNz9/etjKI8J5M8JYYaYhFFbnzMzmxgeS2eGgNl0dEpgENQvJZCsS8slC8wIgUrWEBYROm/McjxhDAGIQFqzOSWIMRpS3RcXe9JZpN2Aqdpt0x4MQGTrbZxk1d8+oWJpczhNiKSUyHoRQceYrOasUNuNjvdRLBVpwYksuSooNhJGYcritHAk6r8fEIxSOTlmC9yB1wFFd3M7+rFRx0ozZc9Flmc5+SxOCbMVVuCSUjeOCyjVRJUwCPIvWiuvYMwDb3tr7koVsc8Gp9VRtnNf3yxMuWkufOGHSMKZSraCrzHMU+qkyvyfCs8g+QWnrDvW+j+YT1XV/QrT2zkBG5ymVMsobzMz92oQp2rf6cJyf+N8ygbOfmDg88mnxtRpXTY38+3d9mCnjhKjOm2p87bRylWc9uztm4sDrhVky4Wtx/Eghta1CK1Y+Q3FK5rRmnFlsolpXSA4dVpy2948kckvc0FFQ+9DMSiXrNN2bBksA1z2vdgmrZnhM4cpNMJ2qQ7iL0Gx0SR41HuMC4C8zGqOx6aWKC6RwGpIVddhGxw+n/ZVIEPynL7pDSURJQKgsTvA6XsUPwio7nDFLaLDbe9SucvI7u3hHKuKUnUpWXrVlbhLpzlqAqCqVDUM1YpRJnpK1Sy6mtDtJk5r0Lw1Zs0eKXfk/dR9kCsb3/F+ehsSIn0m5qvxNZwmRDDOev8RX8JpbXsf6HbX40s4/Sk8nK7HH1sU7gL5/NBzAAAAAElFTkSuQmCC" alt="" />。</p>

<p>1.2变精度粗糙集模型(VPRT)<a href="data:image/png;base64,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">2</a></p>

<p>在原有粗糙集模型的基础上，又可以引入变精度粗糙集的概念，变精度粗糙集通过引入一个精度参数<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABcAAAAfCAIAAACDG8GaAAAAlUlEQVRIie3SwQ3EIAwEwK2LglwP1bgZinEedyQo8dpwukce+AcSw7IC9o/BVrYyTKsFfUR/UVotQKnNzMxUXAdACLVaTqKTjpIHyZFEUcGIqIyrWaUjKrzYVLklMRUGBcodoa1EygNxdlLFR0gzTPkUejE8R6B8D10/nwtm7O/GN09mCRqYV5YRR1l9DcuyPlt5v3IAOP7MKTnaHTcAAAAASUVORK5CYII=" alt="" />，定义<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAOAAAAAhCAIAAABP+zCnAAADOklEQVR4nO1aybXDIAx0XRREPVTD6XdCMfkH44RFG2ADydPcEiyYkcYYsI+XQrExjtUEFAoKalDF1lCDKraGGlSxNdSgiq2hBlVsDTWoYmuoQRVbQw2q2Bpq0Inw9khg/Wo+34ABg3prXOgNDs5mwcGZd+X4btNKk3UOzvT6oGQ4huBMIczbSupDSchGoETVrZPKRIxYGjS/ydHegzPln1lkbMMZgspbvSQJCs4IUgkG0gZt0estzLP4/7EkJBcTooDGaWVCR4RmUG+z/J5ZL/IIj1dExn8gf8xUjvOlo/gZVKaXGt/bpGmtQaG2LQ1a95fXwVt8SspjiQfsXOU9FhU94kV6MxNSjUsNCjZtadB6EkgNytT6QyY4QzxaZyun7iqsc8kaVKCXTsQuBoVbdjRo5c9zYZz4k6z0aWZHFgXgAYu41nTJ4Cm5BuXtS1HhJonXO2RQJgNwEA5UFNIgKNPDDCuDFv6M27are8FYwO5UwIPoODIC6tyiHFocwjvCuEX9E+7iWb3jMyieASII4QKLkv4/n2Fp0PM4xJi0VMXZCDc1VneQhAcl4vTRoPLmh5NwBuX13vCIRzNABcFcRBMl2jCf4VE2030xBg3OGOerIz8BD3Jg7JRmuUFFeu9Yg2IZIIPAiyUrTbxlPsPCoNwMSbW/C1EfSvM8WINCjaMGHXvES/XeZVBE6bhBG7b28xnmBmWf4OhYWRUEjJrWoNbBW5zRNSgJ7qWLWO8da1AsA+zg1cX8WSfVNp/hkbVJZr6aRl17vqeGxY31n2HPX2BQ8hYO8fJdu/hGvaMGpTJQBtFJAEU1vVyaz/Cowvglf5HRIkjWFa88Pz8oThPAoMsJ0MH4PeegXXq7DSrIABiEJgES1fZ2fj7Djo9F2msN4IkT4HjrAvyYtwsiht2Ye1CPJ+G8uE3U3DJBI3Z9zXSDRR9Qfm15ampdfO/9mkk45INJiBcvN2gjw87P7dqXdAyPceXeHtYDs1Xv3fSVBsWS8Ll4tUFbGa76HrQEtLqjhv6s+qLy+KgspIf+70EX4KEkfDXDn/ii/kqbceElfJP1e9g/CV0Mf8Kgit+FGlSxNdSgiq2hBlVsjX9sY9kgdo3PogAAAABJRU5ErkJggg==" alt="" />,重新定义正域为<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFMAAAAkCAIAAAB695EuAAAB00lEQVRoge2Y27UDIQhFrYuCrIdqbMZicj/moSAPzc3ErKXnL6MjbFBkEl6rKsx2YJo2+Xra5Otpk6+nTb6efp48RcA8+lJGiMmZY5GnGAQpS9LJzaQyfIAk7ODJCII5Yukcrp/FdL5qh8zLeYqE47DAvOEPM8JNeE+4fx6jWgCLZGzZLW7DX8AlzwiChYZSTvH1NMXWJxe8eclyTFnQZA8heBueOsCZ+Hjl2DXQLJIxOnvdyderRs8IaoyM+Nnkgs/ADpe8MCE/j8NApfJP6ZUCNLDthUxyBk5PaHOamUE6dpYgd5OX13vOgx/OdtNessiPxAGUstmEoRe8PO1Jve6ua0ScJQbRILcjb0RcvAAGvO0gzwiAiRwpdeI4uW0/a2YJXUYUbkBvIzvkd0lTfWDeDJJ7gZeTTvPdll1h1bsLoVe+Eh6ypF8Qxs95bzh5wyLVNdYIEU/LTVy3qUpJlrsVZ3uotV0jEoqaINqz8rkpxsQmNe0fYBbqAr/Pa58uKz1+Wve5gfW8Sp6bLszp4bqk90NOA/e4qg0u9J//ZrcXmElOMq5dE+/Cu3GbSJ4ixAheMZnyff6s3kL6oGaRWx9Y39HP/xv1mDb5etrk62mTr6c/nE5I7YZQGGoAAAAASUVORK5CYII=" alt="" />，边界域为<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFEAAAAcCAIAAACWK8TTAAAB30lEQVRYhe1YUZbDIAjMuTgQ5+E0XsbDdD+SGIEBTXc36Xspf7U4zAgi7fJ6ni13E7jBvpqfYV/Nn2aFSerZTVWIS+YANBdevB0oVWhd0nTa8uoMQZYzCqrQ4rkr3O3rfo3LtjUJFeS5cE9wBVUECtuVdbELVYW0yo1bnoRjb+jnY2u6IwCs2R7UmsQOozARgTh9GE8EAIWqspKoQh1IUMuxaqy5sCZmT7aKFKfJxNbENFRe42mSDXYVCsGik4OatWRf2VVYqjsJ3XACyROZHtzGgxNLIjgBQppN/wG5khVJ6TI9FlV225Npjg4LcJw5GeADNOvjgf2rfTxQt9wPwk2QDXdajmO34Pi8ZudoWSp1e32D/gWTNc7PWHMVIin2VcCOc5pt/7KZNgndcLvcx8Gm2vZAc2ta7imEvlOaR5JfWl0bRlz/8nRQjlvvaOvZfVZdenzx5+6zYbsPV2oKc2EsNNCGx5EDrG+AQbvFc8egJAZ9ux8eYdvuHAzSUe545AyucGGSCnqkfZ97ZjuOZouFn3qfr7Ejt654BnPYlJ2dw66wrpzBhfm16gTgNs0qy9Hw8q7s/MTu0lyYmCm5jLvXNb+fr7C3xPyV3aI5+zF0gX32f0P/Y1/Nz7Anav4BBdfEmcOg3+gAAAAASUVORK5CYII=" alt="" />，负域为<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFAAAAAcCAIAAAB56a/tAAAB60lEQVRYhe2Y2ZnEIAiAqYuCqIdqaMZi3IdEBcUjuxN3vpnwOJHj54oZiF8m8N8B7JYH+NPlAf50eUtgIeRwSSMwkiydTMCBEQAAwLrKP4+lcSZUPw5MSxCBsTZnjJ3P9G8kp95KmmyFhZzohYoloTol5nHMKTJGhJpM+uLQdiNrQ+lrKzHAQojomMlWAmObkMAs2YBb7xiF5qE0uau8aNedFl5A1sCBWZrEGdNCxik57e9HrJLSlUm0hTgwdvMyylmM0QCfAFXz6AVieOvNsty3HZkO4REYD2hXrChg4eOgaZ6at7uqXsE7acclF86WMQLqJOlRPJR025qQ6iE6+nm0Xic4s0DHI1OdGniCclBNZGrrwcJK/aA1XEeLpZ8AB0Zk4Walegf7wABQ3sNmA51qquqTiNwKJ7XFDd01n7dUmBP3gQ/YBKzRCgDYAXZclUT5lez4z82eFbqBmp08n/R+4jSw91ozmm5q6x8PCnQ6pUHI9yXLUnvwLxeT1h88BgBQl8fqYCpevZyHi6i9izbuhZCDM/PmPaztJAvWto915T28SUpVm76aRjuTizetLaK62BmkvyGvaO8GNvX1olv96nEs/+Jr6XYRQiIczGA6dfv38B65TvJy2Qk8+srZJm/5F8+d8gB/uvwAaPuG9PA2Px0AAAAASUVORK5CYII=" alt="" />。</p>

<p><img src="data:image/png;base64,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" alt="" /></p>

<p>1.3概率粗糙集模型<a href="data:image/png;base64,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">3</a></p>

<p>概率粗糙集模型是变精度粗糙集模型的进一步泛化，通过引入两个参数<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACwAAAAbCAIAAACImfpDAAAA30lEQVRIie3UwRGEIAwF0NRFQb8eqkkzFPM9LFmEoKOu4h7IkYHwQgDhH4S8DSAnosREWEyExVhEikEsoC8gUgwiISaSpGLNGIVIMXwFJhqN2DW0CIW1LC+pDvFyKKokijql9GemGATain81WIltRkO47RQBuIXQngMVTVrZGM+v6QaCM/iCZcNQvyFbesXkDH5ELH81qpDudfw09RSlb6hTiJuZ+wBASSqaLbd8O4b1fG9iuZjlbeY5+Yf1VZ96MXnP8l13+c9+Vt26ByN898cjjhoeRBxsxbOIEzERFgtAyO1vipj9nAAAAABJRU5ErkJggg==" alt="" />将正域、边界域和负域分别定义为 <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAUMAAAAqCAIAAACm3a52AAAFIUlEQVR4nO2b24G0KhCEjYtITgTGQzQkYzCcB0eFvtB4aWeWv+pt1YHmswuwdacMQdDf1/TtACAIekBwMgSNIDgZgkYQnAxBIwhOhqARBCdD0AiCkyFoBMHJEDSC4GQIGkFwMgSNIDgZgkYQnAxBIwhOhqARBCdD0AiCkyFoBA3q5DSHuJz6xRLDnJyi+eM6DzN385ymaZoGTUJRbjBViGmeBCnt1Rezi47T6yhSPD+Yfi0x0BCq+D7nymNz+vzuAuW2RIxHdEsMJRh2eL1YvhePxypJgElHdYXnfuX5aAxcDTXycju9xNmRqhPMVU2Uaa7GvzYvmoTmZtFpmos/P8z9Vj8Z1h5odaqKzPj1HdX9CBR5aOvBIrglhjrYz7123Uc0cTzAs3QyN576MxMXD4TQFPMwza7ToztMo+9myq085KluO0oQOm9jWW91x0WwShgOXqbTKaOW5hCCcN/KOITk1PA/phbM/ARP4mTtFAvLwMXzNue8xJj2BpQ5MM1+NP1htjsnvVOPynNYtX6wRhw3MIYND1pLDCpWA/l5pblOGzr/LjEmhoncSzE5fZcRe067ylNcfrudbOOqgNN0Y3tG2rSL/GDuajhZ8GCxBjSSqN4JrjPgGw915rPE6qHYINXTyknVRubrwSfV2JMMW8aFTHBclXsw3OV5ZU22cVXAaYHJeQut6BWYzZbpg9qOqD2z0XNvPNPp6V6o6z5KG9nrItUqYV39lP+q8EkCaiH5ObkDZr7HkzwM9zrZxEXLg28+Cyvyh5kbTl4X1lAUBZmte418HHWFaDuwFTa56il31JOoWO0q1o8tOLIlVEfml5hd09ktnqSy1elkE1fVG33eFGc+c669LX+YWXdyO50bGaSWEzpDvS6D1xJDiImWgOULH7ufrC1KrvLstmUUql1iQI4rTNe0eJ1n+Wx85jnZxEU6I+879eR0XaydYa7SnNzunL0TqU5sZ1gBQU3JR9QKea8iqJFX12qwTn/DQKtdNJfI4vvpulh4GvG4lq57psUbPLl7u5xs4+rIW6Vq/aXMzI8l56W+lSmsTlNeg6tbPf86at8Hhfk/Hp06yCoQe8Vtjv2cmS0j59qz4kOIcnvJHXgNZr7PU9xRT0xiUwYu5d4dM4CcuGQQd2DGhVXZXGHuUvYwfXMD/QBEqnORsq1uc0sH3jSHuAj1eKmwJ79gN2bIxmk1yZSWJnKbJitjaMBC6rEC4lswhfBu8Ty5Jpu4xFDoQeFdCn22vgcz85dFr8AULj3UHlJdKuAemhO5SHvJcuSm/t5ty7ijGX5jq1+XI9k66xmd+T65x8l1RwKB4gI2gVfrhyS21XGHmV149pBknSu4VFh14vGxkFb5d9EWTw4zM55vwBSPeqvCtQ+6tRoevyhnQOMTxwuyX+H/nH4XZjZ49jv5NVEj2zwlmJnz9Id5r+2Lqt//7QWy1rct5RZKXUfyXWKPf+D1gn4W5hMNvC22v7F4ijDpH58rXWF+y8nlN5/bLjyEmGhNY7uomPeKjZD6tusSsj+Xdqt+E2b+mzxrDDZPGSZrKG+X+MH80vammMmO+k25eagGneYwz4E+PrQqjP/U/yebMHPJ8w2YRoO/rHqwVnLKMHNj+O//f7KzOiqES0pb5Ud8sXC2xDiu+lisPAHT0G2Y3W08qy+WHJoTzcFCpHJpZhtZ1qz9oQiYPboDM3+L588VDyEIuiA4GYJGEJwMQSMIToagEQQnQ9AIgpMhaATByRA0gv4HcFPRS3/biycAAAAASUVORK5CYII=" alt="" />。</p>

<p><img src="data:image/png;base64,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" alt="" /></p>

<p>值得一提的是，这些参数并非一定要考实验者手动选择，有时可以作为数据集的一种性质而导出，比如当我们只有两个X和~X两种结论时，我们可以通过使用成本矩阵中提供的信息对参数<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACwAAAAbCAIAAACImfpDAAAA30lEQVRIie3UwRGEIAwF0NRFQb8eqkkzFPM9LFmEoKOu4h7IkYHwQgDhH4S8DSAnosREWEyExVhEikEsoC8gUgwiISaSpGLNGIVIMXwFJhqN2DW0CIW1LC+pDvFyKKokijql9GemGATain81WIltRkO47RQBuIXQngMVTVrZGM+v6QaCM/iCZcNQvyFbesXkDH5ELH81qpDudfw09RSlb6hTiJuZ+wBASSqaLbd8O4b1fG9iuZjlbeY5+Yf1VZ96MXnP8l13+c9+Vt26ByN898cjjhoeRBxsxbOIEzERFgtAyO1vipj9nAAAAABJRU5ErkJggg==" alt="" />进行求解。<a href="data:image/png;base64,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">1</a></p>

<p>1.4其他粗糙集模型</p>

<p>除了上面提到的3种模型外，还有其他一些模型如模糊粗糙集模型、代数粗糙集模型(如粗糙群、粗糙环)<a href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHEAAAAaCAIAAAAPLyQeAAACbUlEQVRoge1Y27XEIAi0LguiHqqhGYvJ/VCjvLLGNZu9ezJ/+xBhGEAN24PVCHc78IN4OF2Ph9P1+FecEkRM7xhIGIFWeeNCcZowhhBCCNz9/etjKI8J5M8JYYaYhFFbnzMzmxgeS2eGgNl0dEpgENQvJZCsS8slC8wIgUrWEBYROm/McjxhDAGIQFqzOSWIMRpS3RcXe9JZpN2Aqdpt0x4MQGTrbZxk1d8+oWJpczhNiKSUyHoRQceYrOasUNuNjvdRLBVpwYksuSooNhJGYcritHAk6r8fEIxSOTlmC9yB1wFFd3M7+rFRx0ozZc9Flmc5+SxOCbMVVuCSUjeOCyjVRJUwCPIvWiuvYMwDb3tr7koVsc8Gp9VRtnNf3yxMuWkufOGHSMKZSraCrzHMU+qkyvyfCs8g+QWnrDvW+j+YT1XV/QrT2zkBG5ymVMsobzMz92oQp2rf6cJyf+N8ygbOfmDg88mnxtRpXTY38+3d9mCnjhKjOm2p87bRylWc9uztm4sDrhVky4Wtx/Eghta1CK1Y+Q3FK5rRmnFlsolpXSA4dVpy2948kckvc0FFQ+9DMSiXrNN2bBksA1z2vdgmrZnhM4cpNMJ2qQ7iL0Gx0SR41HuMC4C8zGqOx6aWKC6RwGpIVddhGxw+n/ZVIEPynL7pDSURJQKgsTvA6XsUPwio7nDFLaLDbe9SucvI7u3hHKuKUnUpWXrVlbhLpzlqAqCqVDUM1YpRJnpK1Sy6mtDtJk5r0Lw1Zs0eKXfk/dR9kCsb3/F+ehsSIn0m5qvxNZwmRDDOev8RX8JpbXsf6HbX40s4/Sk8nK7HH1sU7gL5/NBzAAAAAElFTkSuQmCC">4</a>等，这些模型都是原有Pawlak粗糙集模型的泛化，可以根据不同的需要进行选择。</p>

<p>二、决策粗糙集</p>

<p>决策粗糙集是根据一张决策信息表定义的粗糙集模型，一张决策信息表是一个四元组{U，AT&cup;D，V，f},其中：</p>

<p>U={u1,u2,u3&hellip;.} |U|=n&lt;+&infin;</p>

<p>AT&cup;D表示属性的集合，分为信息属性AT和决策属性D两个互不相交的子集</p>

<p><img src="data:image/png;base64,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" alt="" /></p>

<p>通过属性的不同取值，我们可以对U进行分类，而根据AT和D两组属性，我们可以在U上定义两个等价关系，R<sub>AT</sub>与<a name="OLE_LINK8"></a><a name="OLE_LINK7"></a>R<sub>D</sub>。通过根据这两组划分中的元素的相互关系，我们可以将他们间的元素联系起来，这样我们就得到了一系列的决策规则用于未知数据的预测。</p>

<p>2.1完备信息系统</p>

<p>完备信息系统是指信息系统中U中每个元素ui在AT&cup;D上的各个属性值确定已知，没有未知或丢失属性的情况发生，对于这种信息表，我们可以简单通过观察属性值是否相同来判断两个元素是否等价。</p>

<p>2.1.1<a name="OLE_LINK17"></a><a name="OLE_LINK16"></a>不可分辨关系</p>

<p>当信息系统中的属性都是简单的定性分类数据时，我们就可以简单的在U上定义两个等价关系，分别为：</p>

<p>&nbsp;<img src="data:image/png;base64,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" alt="" /></p>

<p>通过这两个等价关系，我们得到了U上的两个划分，将U/R<sub>AT</sub> 中的元素记为pi<a name="OLE_LINK11"></a>(i=1,2..|U/R<sub>AT</sub>|),U/R<sub>D</sub>中的元素记为qj(j=1,2..|U/R<sub>D</sub>|)，如果有i、j满足集合pi属于集合qj说明当一个元素与等价集合pi中的元素在AT上属性值相等时，就一定有i在D上与qj的元素属性值相等，即可得出一条规则pi-&gt;qj。</p>

<p>根据这一思想，我们可以引出更为一般的决策规则。定义信息原子表达式<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAJwAAAAiCAIAAAAlGicfAAAClElEQVRoge1ayZXDIAx1XRSkeqiGZijGczCYxRJIONjPjP5pJnG0fW2QbLtiOWxvG6D4PZTUBaGkLggldUEoqQtCSV0QSuqCUFIXhJxUB8b6CZbs+757a8BNkv2PICPVW7PNjbq3ZpuXNB04iM452Cg8YV2pPhjlraleoSAgdT6jz+pB1EbCHJx/emuyIM5sU4g9dQY56BK67xJSM0dn4wVajzIIDqaKrUPr7GNdpMymwyxmVLikPhznBzMoqANAq8DBMw0XtSnXLCGASWpz1MVmb6zlhCAOjPNBpNEg+vpasqHDGj2ZQeBwDx2IxHT94ttZFqq3RpBaPFKvraB45+xa7D2i7mqXwizzlKFltLZjuNCSpP2mpbX9YtuZ28PuuwE8UqkmhISeqb1ORKik5+8ztFwF8HBWACEVL7W2wJZfbDszOVJK75FavyqaP2UmXqxOTnG0XBoar/3WB5f6+ZGB2vSLb+c5DUb27Ruk1vu1LARphiGUZqSytMhGTpKUBGNiJQO1MJz0i29nsGfsCDU+U5HtLD3TvxoKIqkHo/SmlkKauE3mH8AcFA/U/FOEX1w7j8ZvBu/XxrffPI8dbMYEZyx6LMB7G1naWfdhapH0iesZHinKTp3iTvX84top2DkR3DinltdW4T9jfZ3i6SxSJ0UzZOFxUgv6od6syodavk0XL9aTjzxxUGt4p776drZOkKFZQWOLnnKjhPYewWXMSxeFA3jwhikohNTByBBJLvS5tGKcYm35rp7XIXHqRwpN6i902su/penG+8Kp9KjzCUbfuD+MnPZWuAnfp94Y8vp9ahthGhuAeCviHBIv/eXDl0EUmJL6ZRB7mpL6YVD7h5K6IJTUBaGkLggldUEoqQviD0AoRYNKApd8AAAAAElFTkSuQmCC" alt="" />表示满足信息属性ai等于v的所有元素集合。决策原子表达式<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIkAAAAlCAIAAAD5mF0LAAACfUlEQVRoge1Z3dXsIAi0LguiHquxGYvJ96Ax/oGQ9e5yz2EeNwkzYRA06y6DVrhfCzCgMG/0wrzRC/NGL8wbvTBv9MK80QvzRi/MG73geRPBh4Rec8455yC+FpGCZzx9gOj/wt6bFPwuHSl4h5vHATPC50TV4R4fBn0voGQ2BT/8cm29YRhzJGM8qjNEORFtnJKu7y3ISUER0SugvYnAycUc9R227hwiijAvlFy433InBT+QRZjJKW9Yi+acNdeuFg4RzYmp0b/V24bqQBJNeEN2kLtB+hCZjebus/XexcJeUHKJmo5NbxkQa4iVw1EuktFLSMGvY+HeYO/QS5NV2/BS8zLpC4pNxOu9K4pBG+0opVwio5WwamYFuDfYOyzSx280Y8XAqu2X62yiOQwB7LV2VbZTLpDRhCKckXuz6JSiGdCXzPTkE49PNLURqqdFoBoXVfUb5QIZtXNTx8ZL7M0wjuXz85koq/d7LBAQof0aoZcNG65ygYyS2Y0z0nnT+xXB+3487w/4JSp2402wIxpjMrOCDHFWiW2U82VkEZ7IVNEj26eNnTKCcxCQPpu3N6OC/Cu+BPIlERExRBbc/X3LY+cL5QIZjErINkvPN/WLA8S7E9w0w0J7Nr/jTowsmGb/ghFhj1KNfv2pZh30jXKmjGtzNMm+AXgf0pHvAg3r4kgX2AGYZ91vQaD8ECHUpuFD2n/rFLizsiaFwE62rBD+NSTKDxGW9NUS5X2H5uRssoY5BOrNeowRKT+Ee7E0m/zP/7957pHup1tdinrZj3DvSkId2/a/p1ZEMG+0IlLnG8MvEcGZN3ph3uiFeaMX5o1emDd6Yd7ohXmjF398uo8Q2Re48gAAAABJRU5ErkJggg==" alt="" />表示满足决策属性di等于v的所有元素集合。</p>

<p>现在对信息表达式进行定义，如果<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAhCAIAAABWXBxEAAAAkklEQVQ4je3UzQ3AIAgFYOZ6AzkP07AMw9iD1SYFlf4cmkbOfj6ERMoPihb+EVYGWO/hvp3jgZ3ikR1gZVCrJHGsDAJrzVWGyz0saY+qPde7DCY6+eNke2+7bZZ8wVoc7nmUbGYlycTbN5cdAWVR/SV7ya35c4yXHLTKsFNzsROSszIi2LVR7JYkO75Pf0MLv4Y3qPIxo0q+Q44AAAAASUVORK5CYII=" alt="" />是信息表达式则<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIsAAAAmCAIAAAB7+f+YAAABsElEQVRoge2Zy6HCIBREqYuCqIdqaIZieItnPgYI3BtIRp1ZRj0MnpAQNYnBjnm6ANMIDaGHhtBDQ+ihIfTQEHpoCD00hB4aQs9lQ9Fb6yMCZDb2oZJXDVHQbOxFQxQ0HXvNEAXNx2oNRW/NGhfugwTXfOeQbiJavVRwpqygu6TGUPTWWB+XEyB6q/gedJDgjHNnjoZ0U9DKjipLRFRSbii4l/Nl+GW8+ZDmjIZ009EKpSp+hCVNOiy4ctaxN9o6/jpid3SQ3YTLcx/STU87lqouKxm2Zw3thnpO0GH+BUcPC0rvN53GBa4fKzRUXaEdN/A9TwzJX8qOtK8es0tuI1T3aPKSyjV08yah/K0cjj61Scg+5kLdohwrNPS6aVn7f+fa5EtOTymkey9bwa7vlV3ylDON3p6OIy2peh7KSrZaTYN0YPd8MR2gpMZQiS+e/hBIH1YPRyipMFTkS3sPgXRiF7b4wQiipOqJNecHV7iozoZ0YlNKAwXdXvLr/8GL3m1bJ9SclfwBQ3bID6hTc1by6w19fGgIPTSEHhpCDw2hh4bQQ0PooSH00BB6aAg9fx1epYKxOiUQAAAAAElFTkSuQmCC" alt="" />也都是信息表达式，同时所有信息原子表达式是信息表达式。</p>

<p>同理定义决策表达式，用<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABgAAAAfCAIAAAByEJoXAAAAlklEQVRIie3UyRGAIAwF0F8XBaWeVJNmKEYPjGExkBw84AyclOXxI4y4Pmo40IF2hYQAIHEur5mTPpchkAQTCdXZmdOzru22FaCDbCdzanJGErUrquPGeUNCE8eN00NNIHWijFEaiTqWImSVOX5sPWZ4h71OVIPNCTuRCa0cLT4ATbd0thkhx4lDThPC5D7s/Rs50F+gG9s7LIQF46mPAAAAAElFTkSuQmCC" alt="" />表示。</p>

<p>用<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADUAAAAcCAIAAABOJ2DZAAAA+0lEQVRYhe3W7RGDIAwG4MyVgZgn07BMhrE/+DBRgiiejXe+P2tDnwTkCovvwL8BB/l8c3mvjwmR+EFKM6bPB8/0OeFZvgnevZ3tfEwINSFeWZMJrdIYAACqX/aSHm3rlI8JAYlLGRPOCKE5xhhWBBOW9eXHhi+G/I3SVeFeSh7Htr7NY0KjnepbMXXoFayiDsBQxBoSsvKs4QnfMG807eMUg8Gz9glE4X2bm2ZszL6OIT3v6fbzm341lm5r9dXOvD5uke9H6g2xeazP6brVeeMHLzB9/8UwceJORFwsB1E+fzzle4p35nf0/eyO9+L/pz7y+eby+ebi3fcDVcgo4aUgmNkAAAAASUVORK5CYII=" alt="" />表示规则<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAhCAIAAABWXBxEAAAAkklEQVQ4je3UzQ3AIAgFYOZ6AzkP07AMw9iD1SYFlf4cmkbOfj6ERMoPihb+EVYGWO/hvp3jgZ3ikR1gZVCrJHGsDAJrzVWGyz0saY+qPde7DCY6+eNke2+7bZZ8wVoc7nmUbGYlycTbN5cdAWVR/SV7ya35c4yXHLTKsFNzsROSszIi2LVR7JYkO75Pf0MLv4Y3qPIxo0q+Q44AAAAASUVORK5CYII=" alt="" />中的所有元素属于<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABgAAAAfCAIAAAByEJoXAAAAlklEQVRIie3UyRGAIAwF0F8XBaWeVJNmKEYPjGExkBw84AyclOXxI4y4Pmo40IF2hYQAIHEur5mTPpchkAQTCdXZmdOzru22FaCDbCdzanJGErUrquPGeUNCE8eN00NNIHWijFEaiTqWImSVOX5sPWZ4h71OVIPNCTuRCa0cLT4ATbd0thkhx4lDThPC5D7s/Rs50F+gG9s7LIQF46mPAAAAAElFTkSuQmCC" alt="" />。即如果元素满足表达式<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA8AAAAgCAIAAABCTrX+AAAAfElEQVQ4je3TsRHAIAgFUOb6AzkP07gMw5jCoEbBkM4itD7+IZ5UvhT9+gQtDLAEtYNt7WFTu3jSwqBWKW+0MAgsmiyM1avO6Q7TMbTZ0P2ozdzaFx3FVcfGmLN3FxxvKQwioO7PWXZ57DsnJ9HSAdx1BI+v847P/2nH6wv5pzEE+KJs/AAAAABJRU5ErkJggg==" alt="" />，则判断其满足表达式<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAeCAIAAACqmwlGAAAAfUlEQVQ4je2SyRXAIAgFf10WRD1WQzMUEw8YgkpicvC9HPTkMiOL4vg4sIUtLBCYACBl0aXkZHM9AnEXgUl3K19nzTbmvOTk4nrBn1y8vyWoIeTt+lZwAYzv8SAlYuNHui/a2oezieMIHs7185XwzI8CU5zKnTDj//691wgFBK4w0rbwGEAAAAAASUVORK5CYII=" alt="" />。这样我们就定义了最一般的规则表达式。</p>

<p>根据粗糙集的正域POS(X)，边界域BND(X)，和负域NEG(X)，我们可以从决策信息表的两个划分中定义以下两种规则</p>

<p>1正规<a name="OLE_LINK13"></a><a name="OLE_LINK12"></a>则：如果<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAH8AAAAdCAIAAAAM4yQVAAACh0lEQVRoge2YXbrtEAyGOy4Dyngymkwmg3Eu0BKJ0rL7rJ5+V2tjo6/8sflPz2l7egP/tT76T+qj/6Q++k/qo/+kPvqZCBzy3CkZHZDZu4o+wabI2Eg5uBp0dAc4hLMZee8ZnbW9+xNbh7rS9gkKlgGi+ELZyOh2yvuA/c/QO5/SMvQn0y+kz+gEKHEcgaVu6qmVQBhO25WvqVpkugz+C+kXVru35FxlfxCjOzqqSRhhMqjFhh+lnvB2dOZBtwoASdH3T0O5yi0zdZO9oB83ttA0rbisZ67L56QuU9h+BMbo9K8d8VABv4zY5uGqfZHDGvus42NsBfKeIPSYRAZUhwIZeZqGNuTzwYBd5ijVUfTCP1pXuIAGJVWeM+GrxyziPoFpY1XMaXmiblH5KgZJtTDK1p/OX6HPzHHBsA+CGX7XSd8G2v/pmkWJjZgJN/UwolKdzo4/5k73q9cc+Of0CQDtu8EA/jZ8y/hLu6+XO5v1kgwvPZBr8LM4cDUReu8L+iHKpdycYt7ZBIpM05bbF5cqLdeKy9qCzKsUI3lTqjQEj2Qb3Y5h1jxaPdL3KFCNK5ND+wTKqerMByQGtZa6cS6i3he2k5ap7uhpe53G36z3f05MxARAdXoY1/hdNxlF77/9/V13tUJNokXIcQ3yJ9iAxvKgOvRn6cdvJwBiRLp9I2g9RUrFYJ/hN+JTGv3EG+dCpQ/PgnRwgluu0PO+nzg75Lx2sPLAM+/7fy5GpPpTibJnpbEKcXj1+GPkCfYt9BkR5D39iAxEKTvHe+z81feX2xHfewf9dBHJHZ8RAI5yaP7LdLH6tcL3HfRrMQJSFgUWwr+hN9KP5Uv2hrDqnnxXb6T/O/oH/MCpGEoCNbEAAAAASUVORK5CYII=" alt="" />，则有：</p>

<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAX8AAAAuCAIAAABPg47WAAAFG0lEQVR4nO2c24HzKgyEU5crORVQR0qggFMHzVCM/weDzdXLRUJxMt/TbhIbjMaDkEleOwAASPCS7gAA4EeB+wAAZID7AABkgPsAAGSA+wAAZID7AABkgPsAAGSA+wAAZID7AABkgPuAfqzelCm9+tq0FegPeCZ97mP19vL8rTOjzg+/CmIFjyXUQUyoCqhlKUaRW395lqFjwH16+zN0kAD1W4q+9yvbYsDqraB0q7eo949WS2iG98GJP5l94nr7GDKjGdLDdOhJT8yXz8J9Yqzekonaq4c+BivbouUH3GffXTiuvhzRCfuWvnJMKsHQGBX866YclqmMccQYTw/3SYj04mHSzcq2SPkN98m7EtrREadyquNfNSqJL8dSJmuEHDb/+Tb3Kd8XHRQdoTCrUbCyLVLqC8dvcp88PJe1GFUJUZTQZmewWhGHlTnxcTA53LT7+MVCNCMkI75UT5PNVRyBxRLm28psoHrh5TrG4EAN5z4iaqlc+l+L3IJ1+Gyn6j3pcvpomnEiqdVlSMPdVv55v9+9p6XJfVyg6qJcOptNGUXNEQqr/mkm22qfkFzCb9RxyukEcW7ltVIt1SHuPTJYEN/pK3/P+QDPDVAeLepw703jKOY+tx4vkUu7kA8M+mPcpz2J949i6dQ4WfdZppaJMsuRw2xBaun722c+16scKVBJQfTh3qthCR1Hzn12o6qaodbTTRpNkGw+ZeVVGYjSJkBr3QHHm0ZNR2O27rNILbPmUz74ZtlVnzWYankFBTGEey+Px/v9/iD3qVylYO4z0OpTqs69M9q5F41CjbPPvBapZcJ9blYa+UaJ8A3/jtU6bvrmmse5yZ4Jw70XwvLOGDgrVd1H6WpdKjoomDXZanGVZ6FtFOOZmBlRRJva2ms3UZf9XD0u9b07KLN1nya1EEhl+FHNbZmjnPzEeU8+QuMVqBsqQ0wc7r3c+2HTOaFwn2OB6cvifrlZO8jHheoWLvVxPMpP2m3YqudwRPz9mESpMygz7tOhFgKpDN3z1ewmfD/dVFiqNSc7FRn0XlA7fbjrN5Wk+wTPAbL/qge5gWDaQVDNCI7x0zfl3LZixnEJs0Jqb+t+JZI9WC2P/jUkvuHkc51B+cN93PhMq4VIKj1P3OPA3DQbnzSv/F67goqRSQQwLqfE8lnC/bn7fXoPEvsygdVq25Qhedy8eP8Se2MtQemu96v/J9XylO+dDGCNsUYpk5eH+ul3ht6BTZNaMla7j1EvZUieAXZytknzyGeZ+ywyH46gTKpFTCpLOOKaLTyH6PSf3oHl+yrHYve5cvK0JmfOD/yd9Y5AueBb6D7LzCcKSiVh72ROLVWp7E4tDVJpyNdkvM1dlVHK+OxnalNQT7GzL9ys3yJb+Ps+/uBN26Rudw2EMT4ZddsWqDj7QnAv32z4IIe7rUpQSLx6XC3/qZpU9uvO5ZIKP17vcZHmGPPxbKjl9306w809933AbxtarZS6Vr/0X8Tb2yIDTs5qxMo1ZhuhWlikIoXV2iTDzb4gCJp2f6wNt7j7WK20CS6a51vA31m75OIqhdLUJeiI1PJt5qNU8oiQe0FwNS0UblH3cavV9DHHZwn+56g/JpYlUctXScVvSzrXPisWBFfTUuEWz30AAAn8C4LPAO4DwCfxSwsCuA8AQAa4DwBABrgPAEAGuA8AQAa4DwBABrgPAEAGuA8AQAa4DwBABrgPAEAGuA8AQAa4DwBABrgPAEAGuA8AQIZ/yYdDh3SayLIAAAAASUVORK5CYII=" alt="" /></p>

<p>2边界规则：如果<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGMAAAAmCAIAAABfzLIdAAACJ0lEQVRoge2Yy43FIAxFqYuCXI+roRmKySwgib/gaKSMJvJdEjCXgzG8V45UTOWvDfwbJamoklRUSSqqJBVVkooqSUWVpKJKUlElqaiSVFQfJdWgYn86qGOF5n59g1SDonV76lhHE1/c1Tw6m0GKxaNjLXrFbPz8TNugzaEe4rdyqgFd1rDIltNAtoxGYrxj5WzmSukoG5M7B7e1DPASKblZI2GIowa1VsM1Na2XpQJxtKaNu7Nz2hxWL5FqwDdT7m5HbIqEWAlfJg81hi0TSsToWF2mJm+L1Hl856Rj24ywtJKoY6Ai3h/12esI2BU/XpYdUCSrVlWGzQ24wHQ4gdycmhvsot/kuba3AtpwhGI0xP1lnb1rTIHmojS8RHjKPv7pG8tzYs4kiIlvkVnNaaG5jhJEQN1Ld3tIL/tuFvRSigdL1hY13+LmX04rt5UxOU+gUc3N+HewPamOtWKTN2jE8rGs6K65dTk04+gHAb2CWPJMlyTPHOtX+/ywIXV5Vo8Ns2+cVANAv0I+QLUDdXAmV8Kqaq4n5Mm5qlPM776gPahTw/1ZYORavGC2RdrvPLbsha6Cy9hGFTYend7dZ78uN+ln3H2iTs2lsAeCx1/9wDBzw69mpIPwdR9I+0eMU5Tle4o6OPtzVw/u9Y/9Qn7ydvH0t2/09/RrVl6Az5GKPdU9LTh/kNRx/Nv/p76hJBVVkooqSUWVpKJKUlElqaiSVFRJKqofoJjgr19ncNoAAAAASUVORK5CYII=" alt="" />，则有：</p>

<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYsAAAAqCAIAAADNteAjAAAE5ElEQVR4nO2c0YHjIAxEU5cLoo6UQAFXB81QjO/DxsGAHDASyJt5X3fZtbHRMAhB9rUCAIBWXrMfAAAASOBQAAC9wKEAAHqBQwEA9AKHAgDoBQ4FANALHAoAoBc4FABAL3AoAIBe4FCACW8X40qfvhbrJzwP+BMwOJS3yyvwXYvOHL/8KggaPJZYB2diVUAtM3GGd7Yoz0qscDlU63PeumgC9LDjf/qRbQng7VKQv7fL6emfqRYyNPsbH06a9cDpysWYeSFOI8F3V9EcGQ5VgbdLor2gSP7YjGyLl7/sUJ+nKOSD4aPkv+cro09nhFjGnuTvDYeqwxl6duR+iZFtsfLnHaoUms1bwqMFp0kfNVkMjQ+xM6ITnKRH/YpDlYdPLUVJBVExh35kW6zQi9QfcqjFWpNnQzUOJRhi2SRnXVdJC5RxqGQuKXT9eM31tEhISkRT/W1lVkG+dVyI7i6J9ORQXwQjoxbi7ekFVxYal7jRVojOs6E6h5KyKKpUxBn9ynLU+/1uvbNgDrXHgRbu6FnxvgAoSSVTKAudbdVPZvuwcWa7ZV+WSd6gYZVHC4ZfLWQvf7vocjgfW2WJdVU6lIScqM7jjn5dh+pyqGyGqbpIll1jrcF4jEN5aypfLQwmNoky1KFIwXCr5eYmeRqakKwen0Wb+adEaqpDlVoTiT7x5LErKXOo1RmyuwU0d5Gy9yazT1nlEb1QOkjp/X7B9kNnuqPBUIeiBMOslruneMpjPXrD83GjfTo0bu4qr9CaVPTzm7zfb+0ORbz63ByqteGnVMpbp8J4VdIdDIa9PEowih3qZFHpgchw/sCYiZXyi4yNN/pZiN4ZN24sWocylqyfnS6KZl/pPdGkGPuqa/dCmvFOM8sYqmlrpUZZk0V9nrj07M1BYahDUYLhVsvNnSc6hzqGOnli86tD3Zw8v0P0OHP0CR+8bUwHYg61rXBDiT+sd6mLgrq5hjnxmOQe8PXIHnnErret2hJw3B1hwCZRagxKp0NdCYZfLXcq5XloUvspf6kkzQxHyim0ly7zuKN/sZenzqHOe63UObTkor135E5VlIZPjUPVFVe2V+g11/q2rlc92ZZTufeTzfz89xqD8sWh9v7JH71CMDJqaThtcFHm/CQixLVrpLT6EOe/fF9dySwhEf2nnYdqvWjOFztiBQgVCqW4W0lpoSYozRsU5t9T1TIc75x3xrjVW9sb63YDaerkNFHmRIVDOfMyrn/Ds5V4mPfPASNMY2RbQkF5rFomsIU5q5DcolHgTZ0s+p0aDQ71yf+T93QuzaBZOyIe5/2zwECHGmZQp6AQq4FGVKilIvWb73/7GzpjnLfWHRuDdx/solSU0RB94a/8Tf/7UOHixYZvC0RdEnZIXMh093McHGQi7RzzzoyTtXRbRFBYyj/PVMt4wgtFRaOt/7tSqpq/D9US/QFzpda/semtMeaz/K4/Kw2kOMohI9ezdfyEWry1Lu964XXGqfX9H2Ojr9OhvDXWndZgf1Fyz+JTr+UpjPDxG2rx1pr0yP24zHFe9PU51L5cjkoPF0fTwSCS5ZYafkUt4fxWvMgalznOjL4+hwIAfOc3Mkc4FADP41cyx3WFQwEANAOHAgDoBQ4FANALHAoAoBc4FABAL3AoAIBe4FAAAL3AoQAAeoFDAQD08h9L/cDSZypaqwAAAABJRU5ErkJggg==" alt="" /></p>

<p>根据这两种规则，我们就得到了从该信息系统中能得出的有效规则，通过这些规则，我们就可以通过任一元素在AT上的值，去估计它在D上的结论值。</p>

<p>另外，有时我们的属性表中虽然有确定已知的属性值，但可能数据并非简单的定性分类数据，而是定量连续数据，对于这种属性，离散化处理使其变为定性分类数据是最为简单有效的方法。</p>

<p>2.1.2定量属性&#8212;相似关系的引入<a href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABcAAAAfCAIAAACDG8GaAAAAlUlEQVRIie3SwQ3EIAwEwK2LglwP1bgZinEedyQo8dpwukce+AcSw7IC9o/BVrYyTKsFfUR/UVotQKnNzMxUXAdACLVaTqKTjpIHyZFEUcGIqIyrWaUjKrzYVLklMRUGBcodoa1EygNxdlLFR0gzTPkUejE8R6B8D10/nwtm7O/GN09mCRqYV5YRR1l9DcuyPlt5v3IAOP7MKTnaHTcAAAAASUVORK5CYII=">5</a></p>

<p>有时，我们并不能用简单的定性分类属性表示AT中的所有属性，因此，就引入了另外两种关系：相似关系与优势关系。</p>

<p>当AT中的属性为量化数据时，我们可以简单改变原来属性值完全相等才属于同一类别的定义，对每一个数值定义一个范围的领域，当另一元素y的该属性值属于元素x的该属性的邻域中时，我们就说y与x相似，这样我们就在U上重新定义的一个二元相似关系。</p>

<p>由于邻域可以任意的选择(一般要包括该值自己)，所以这一新的二元关系并不一定是等价关系了，这个关系将可能不再满足传递性与对称性。我们用xRy表示x相似于y。根据R对任一个x，我们可以定义两个集合，分别表示相似于x的元素集和x相似于的元素集。</p>

<p>&nbsp;<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAWwAAAAlCAIAAADp3UT+AAAENklEQVR4nO2c28GDIAyFncuBmMMRnMZlHIb/oa2CJJBwE/3P99haTMLp4SLtZAEAoIDp7gAAAM8GJgIAKAImAgAoAiYCACgCJgIAKAImAgAoAiYCACgCJgIAKAImAgAoAiYCurGv8zRNZrs7DlAXmAjoyb7OMJG3ARMBPYGJvJC+JrKZed25N4v1tZmBJsv7avhUWzBU9ix8J0e1Ef2kkKEK9Cp5lJjIZ4kbQoe6r3MqiX2dp7iS4rG0qdElzfMm3hvXuFUq0VWSp8P3RBiqf9lZHNoKBNqwQ8ojTxv2ZfIonons6+xWaTNkejKVaC4Mg2j65WHrv68zKWz9UCOrpCDOzC+agvxQCRPRdPmQ8lBrw75MHuXLmWtcH9v0I92MPPQcnbQfgVkdcrPsjPmqpJLZcdYlM9Sv8r3rNNqwQ8pDrQ37MnnUN5GvUpxItf2ulJUNXLoBd5hIWElZmO1nIjVC/ZDhCcPJ4yYTGUce9U2E9JDfBc7qzmyxtc+87sfAJVgPOmONc4vfXakB8LyVaJlZx0TiscUrKS5dj83DZKcLuWxzPFMe1Uwknr5YHnxeQnksy5K6xKOyiRD9HgS+mSMzpsr6ldtm3Hs4dzhfCW+kXWRVmYlEYktVUlq63iaStzy3lq7q8+RRdSbCp5+suSAvmTzuMZGYVxNd/p1VrdxDPe14Gnb35abU40PdhLLicoaNLVXJI45I6TrZiCRUYTNUzzxLHpWXM1z6gpoL8uLk4RrHrTMRcgOLFkp0NPn1imS+yhTFW/3RIiEfm7VdzsRjS1XSBpdxNDcSYaiKZoRvWDuePOrviZDpS2qezOtoyfv0sizDmAi5c0MWZF/NzP+OImOooWdAk9kiRxO0DwVIWWdtrNKxpSp5NBwpXe5TUCWyUHXNODxLHmpt2IQ86PRlNU/kRchjCeDi4qi+sRpkR3T51yJZPy1d9HrNrNR616pdhAmW1UliOkzFlqrk55p06fpvrObaCG0Hj5OHVhs2Kg8ufWnNY3kx8sjzjoPah82s/S3ePNP0kz/SoAuRcTKR7sbEk3SlGMl9K7aB1Jo6jE1USUHpOphIOlRFQ/5nnikPnTYsLw8+fXnN+bwi8rjLRC7rRm9Hx11EujMod1f5/HxQm1oHAchtd/992Z4ImXHs6vTGnBObqJJGULpOB2YEna5o7jIZe6g8FNqwnDyY9I1R1pzLa9hzIhK0D1O1Yyk3841NKBuTNJE2sfU6KFIPpSf8F3mUNc7l1UYevX7FK5aKfpyxbG26/1RSce9GsWXM9W9H0+X/RR6N2m4jj35/BSCJP0siR+vhaYAbh+TkxmqL2PRbjmMg1Pb/kUcJfF6t5PHC/xM5FpMDzuobxlZyXmMEev2fyMjyKCGRV0t54J/NAABFwEQAAEXARAAARcBEAABFwEQAAEXARAAARcBEAABF/AHOhzOtNNe3kgAAAABJRU5ErkJggg==" alt="" /></p>

<p>这样我们就得到了两个U上的覆盖(由于这个关系将可能不再满足传递性与对称性，U上所有相似类也就不再一定会构成一个U的划分，而是构成一个覆盖。于是我们有覆盖：</p>

<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAU0AAAArCAIAAABzSE1gAAAD1klEQVR4nO2b26GEIAxErcuCqMMSqIZmLMb9WB88EggoKjjn695djJBhJKI7LACA3hme7gAAoDrwOQD9A58D0D/wOQD9A58D0D/wOQD9A58D0D/wOQD9A58D0D/wOWiLWY/DMCjzdD/aAj4HzTHrET7PoyGfG1V8HTdq1DP3ZXTWzFrxR97PiRy8g0sGEFUMWlM04vNZj8eY/5VbCJ2TWY+pbM16HJjJcYP23nCOvjpfHP1r1uuHiHkKUoGgdR5N+Nxxuf2Zl5AwJQLh4w3vusazgs56DKalUQM3V99LIKJIQdcYa2va59A6QhM+JxPjJ+A/I9yUGCXPEa3+XdpTl7Lti+BjtvGbCUWUKEhC+hxax2jC596V/09wofsvCFZKxBf4I0AwU96oPZmO1xP2Oq0gybrwuwmA1nEq+Xwtt/4d3GovakXmcNtSC7o/S0ibbw2s8k+ZWJHvpzTUXhSKbh+5Cc3Wvt5yLtJu54SISQXz+vxlradpijeo4HPyAae4JiMxKlG3ExIEGTLKnr1U7oh7Ifoanw51NJSNOauWo9JxDRW02wl6nVJQzue1vt3nwcb4PvTyVYhOoLeQkAkKhByHYdSae/JCdJGr5VKhogfLTr1/QXxcxek1tNshREwpmBX8e1rb3r7b506f3EItrJQkJR8/oS1tRft0sU+tLgq1T4Xaw6WqWf7U+xeMAa72epZ2zlGFIqYUzOv6t7Sepuk5n7sDcCfHiSWBniZO6ontClKaWauRf20yS/t4qDVc1g4wOZNOPkMSU0m7HULElIJ5wT+k9RSQPOelPvfSbfTxd2RFEAZOrNdB8ggh11el2MVDfM+WDrV1QTxmJhL3COnyqr2ads4ZYs/VTjj9e1oL7b1z+Xq+DdaoYRzV8c+gDLnJI4JIDLOCeyuEO42c5YpaACR7sKJQdpek8lsbPvGjq+y3J7SzulhqRl/EtIJlvV8+ovVzPrfv1pSxblrsTBVMUC+/3r2QvQoFp/dmqDLO8em3agjtJaHIlMTu2ciRxUrO65+fp7RbZq3N2rDQitYLbSIF86JDa56b35Mp83nxLk0770hlUfkBepLoT0X4gwpFlMeH1ixN+PzcHp5Mfabha7V/8H04o0q0qH9xgtY8Tfj89B5N6kh+hrxQ+5z7wAps1XvJkbXf14XWHI34fFlOFX7lv0l+GbWL3xTbrrK9HZ9F/QFAa4pbfX5quxY8jb3L1IxbwLIsjfxeDQBwCvgcgP6BzwHoH/gcgP6BzwHoH/gcgP6BzwHoH/gcgP6BzwHoH/gcgP6BzwHoH/gcgP6BzwHonx9yQYDNalfpcAAAAABJRU5ErkJggg==" alt="" /></p>

<p>有了关系R以后，我们认为一个元素x绝对属于X当且仅当x相似于的元素都属于X，同时，所有相似于X中某一元素x的元素都有可能属于X，于是可以定义U的任意子集X在关系R下上下近似为：</p>

<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAaAAAAAwCAIAAADYRTn5AAAGJUlEQVR4nO2d2YGEIAyGrYuCqGNKoBqasRj3wTk4khA0rNf/ve2MAySEPxzqTgsAANyU6egGAADAKCBwAIDbAoEDANwWCBwA4LZA4AAAtwUCBwDBNICjbXoicDpYmYObpsnHo9sBgCEQOPBlDg4C9xii1ya06KfJhXl4i0ZwNYGLvtfTY0atPjqGMgdvGHi8q1puP1gaT9Ib1wICdzbm4IgOiT7Z5Xh/nX7m4xycaf/MwQ0ZTusi8UvS5MSe3BBW4IqyiJ/SPyLMot1OXTVkELT7N7nuWiJ3bLb+Z4FTGDsiTV5G4MRhVvdV0Se6QapuyMCBxIZd9MTH0gxuDi7xwap465+5+v3cRARYj+MMnVzQ7F/2s9NCOEsl5XaJxEjgNKlUHRn2afIqAhe9aHiuOlQmMBt9Y2cKbA/TUtYSuLSodsNrvzXcTlU5xDXt/q0uOjO8nzRSbuRluxkcn0o3NNc4hq4hcG2jf8E9B0d3RudgFWsaNVFgxyijZJLAFfY22/2eLOyb9xo5uULRv0M7xhTJSWop3y0CtgLHptL+iDCVuDEC95m2uhDevvl9Mifz7nV/7DcjZ3yumbiuPw1c9CtL0VB2X7qiKLNXWX8GbSjdt9GTHwsCF30+UOgaJSiHteyVnJwtwVqrGvLHzf69wgSuMX4VUr6YJBI7gRNS6Taxalr3er2URdkLXGpe9GnoRr+GaKlmb3Oin7ynLNNFbl4XdwU3YDuGXKYcacH7A5KNJEbfBIErDesfDpLa8vYyJuzfH9P178Czn//K1m0p15TSxkzghFTKNHNPmlyW5UiBy32RjZHVqvrL6CcXonCAohoc0tyJas1WSKUqTatrVt3N0a1v8inqWtTmPUPB7YK9pJMNjscU/TtA4g7J1m0pXyyytZXACalUNLY3TaaidpTAle1K/65U+f1l9JPzXhKAtsDNwbkQW3swuwWOHz/yyKIOmojgYtvH6hsrcGlRWxVOcjtvL2XEbn3T9W+rad0ck61VUm6QrQ1PUblUqlFGXZp8vV4nELgytjT6ptgabsTENwW0iqJionuJSo8fOViktWuzaEnfWIHLitq4PGwJHG2vvcCp+9d4e/qQbK2W8rMInJhKe9a2bKkfdUtRNPqNpcAV5szZw42FMZ9rNf0kXZNpR6Ow/ftA32LKPTgfxF0DncLR7ROXt8yXRUnbDBdPPFh7ybq2b4n39q/dAvWAbN0h5QbZ2kbgxFSqEDhlmuzVtS/WApeIuXNu3XkNsTA1uVAVlMJWZf6xGBhDTlGXzwTrUzoz3erYRyxGVWPKQghc7QXVrg7ZHNLtgr2ck7do7Ib+HTZ/G5+te6S8bt8GTAROTqWNPbi+NHm8wKV7TT5+/nJhrnahMsmvHFDPd8qlR1pcmlVbGctC336DrD4wEiOmyq+sEjYuyRrjawUgnJAc9XWamvxAY6/kZGGCUXTYpv5VTHs6sMrWVTBzN990SDlTSicGAtdMpXwzN6XJDfzPjb76Br8Pp4KvJ7v7LDbbntl8KjkC24ftazrdbroH1o3tFM4gW9PBnDlpk5QvJtl6n8ApU2kdEXvTZCf/I3D63ZFPsnSulMR9Rtu5zHYY7WS0wPU5zjAut2CY922q4YL5HNlaH8i7lsP9xpqmyX8RuM7dX25LfnMAGw8827XQLsYLnNrtkpOZ+2TYJeoWjI6QdBXpo5kO5lNka63H9q5ZOptrO1pHC1wW2gayjPfBHQLeB5fVZVDVCbJ1fabFVbg3dfRNek2z1DUetgfgBNwuWyu0S6mCmro0dxGYZykIHADPRXiaYFHcGXB+IHAAPJrPuSdz1/CV1W2BwAEA6HsUz3GOthNLgWsdlG3BsHkAgKcBBQEA3BYIHADgtkDgAAA0n/ti1hfdXfLIAQIHAGD5PIkR49WkbQUCB8DjeD+OwT33X7yxy3vqf/JeAwgcAE8keueSB5n5Bw3iddVtgcAB8Ezy9zTkr0P4Cdoc3JXnbxA4AB5JDPn/jiDfRL1O65T/UuScQOAAeBjvHTjidePfGVzyjOq1n9mCwAEAbgsEDgBwWyBwAIDbAoEDANwWCBwA4LZA4AAAtwUCBwC4LRA4AMBt+QNiZZftjDTtSAAAAABJRU5ErkJggg==" alt="" /></p>

<p>有了这个两个近似后<a name="OLE_LINK25"></a><a name="OLE_LINK24"></a>，我们就可以像之前一样计算POS(X),BND(X),NRG(X)并简单的定义信息系统上的两种规则了。</p>

<p>2.1.3优势关系与排序问题</p>

<p>但是当我们决策属不再是简单的分类关系而是一中偏序关系时，我们就不能再像以前一样进行规则的推导了，这是，就要通过引入优势关系下的近似来进行处理。</p>

<p>在优势关系中，在属性集AT上我们定义xDy表示x比y更好，一般来说xDy定义为：</p>

<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAQkAAAAiCAIAAADDFrtyAAAD3UlEQVR4nO1b3ZnjIAykLhekOlwC1dCMi9l7MI75kYTANnHum3m53QvIY6GRBGTdHwAAHNy3CQDASwFtAAAPaAMAeEAbAMAD2gAAHtAGAPCANgCAB7QBADygDQDgAW38t9j84pxzbvGbPCiQ+nG0Q+FeaqX9d/Kcp41AjkHzjR/B5hflwYHco8HAPPB4Hu+kAU9tfnGL3z7/SmNML6oZuYg385xaNza/5GscQ2FuJEYmykpMFWy6oIE+P25+SRxjSJspAjWdag44bXinkQqzeI5hqjYC1elvr6jz1SEVh6c7iPpxZ00460eZRoLvkEYuKx6JCjusckb3/Dbis7k8+zFTG4IvAg32VmIJNaQjpX2ZKI1Ajogly6URu9HW1LH40eJ092Z3cZvOswd3a+OIuPhGaVqU0sRROY6p53u1mlB9z2Co1pUBpnc5t4peWMxjRK+6AjkK/HsEGhJppnd5uuA7Ze20aYVhi0Iu8WzGiWXbsa5rg+NDdSNmhCL4pDyRdVX5IL2OG6C7qFRC1U+lnY1Q3kaT1OEc1iuWbkNCOx2r1vm1s5o+7TfHXeOpxomB59e0wVZYkXAWdIU/kg48wpqaatP857lLs6fV/q9WavM0VL0/oSdYtQSXaLk1VQ8dpTtqSjZWUIuqL/JU40Tgmerhe9pgWhqxS8jjN3utzftQD+7Mp+qUtFIUVaRcGfkgoXvHUpa9cvyFzYZxfzvWjirGu1LWDTzVOOGMr+v6Im04g5TrY6rTIXxOvrVu5Am8kkbKV+p9+mM4K0+c2cHNRiRkk2ZDG+IZHi/kbilf56nFSWV9rWAh+dB+g3y9PZK2VVXPHy+DlG7lpv1GtBXvnpR+Sjxp7hZHMYGLkWc3G60H1GunWB8+L73OU4sTzrpdEh88oI299zu4B6LAaUC69tsdQs27ruvnVMlQovK2I02egdyyLM5RqJu8rv7H1Gk2qoZ6ndCxWeaHMWtnmdaLyzzVOJGmfVMb+U5M6MWbKb2jo5DOiDp3JawvE/oUjt+kgGruN1JnpOde2X+WHuNeQf3ykVmndb5n164gULtbWWONxwWeuRH+w7feb1xHfTQFVGDvyfl8GdtBygPmm/fNDE+epMpTipPfvBc3YPI3Nn4UTGv3J1TLI7bYdq5HHXclY42K+gYZ5Di5j+dLtLG/0Oxv+f0kqn4kBgMbV6dHua+P2fcPdwScyFMnmfFsxcmNwvh7iTbUbh7QEfctwjcOFr+pBz7z/i5C4mkgefDU4+T2nuMV2gAewhGPROMX7Y/jtSShDQDgAW0AAA9oAwB4QBsAwAPaAAAe0AYA8PgHUlH3Du58GJsAAAAASUVORK5CYII=" alt="" /></p>

<p>这样，我们就可以对每个x定义两个集合分别表示比x更优的元素和x比其更优的元素。</p>

<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAUYAAAAqCAIAAABA9GUyAAADyUlEQVR4nO2b26GEIAxELefWYEHUYQlUQzMW4/1Y96EmISCIxDm/KwQyDC/dYQEAGGJo3QAAQElgaQBMAUsDYApYGgBTwNIAmAKWBsAUsDQApoClATAFLA2AKWBpAEwBSwNgirtYOng/t24DAAboxNLBjeLvsx9dKN2mJbhhGBLqnb27cGJKbd1NaCDls3Ssa+ngBoKNpLMf2d++T8R7PPuRKpzN7MfkROcMBUWKYqUvsXWylFQXGkj5PB2rr9KzH7c9W/u+az+3SusGQfqziqrS68qc3ZUpoglOP3BOcqqdbaR8oo7VLU019TWdb3rKWDq4pH4WM3XerJk5FJQp4mLmDNosTrWzjZRP1LG2pZmWBqfZlWTImjhwpMjpFeUNhdMpumiV7lHKJ+pY2dLc3KOavKgz1fvIshZ91fPzUKlz2G56f4f9Vk0FoodCpGw0RWKXr1uk+5TyuEwrpGQsLTc4lh85rl7HaZrkBypbmjshaMYB38u11tmPx7qpiPTVhXh/Edwx9rZqYt0RZne+rC5FbJephlahTymZ9MhSSqu0KEQ0P/Iw6MHS7JlfsxsRLgxewpI/Flm26D3frurg9mGEocCW1aaI7/I1pu5SSnbvLkspbryZBuvyI8UVdPy1cVtLs5cTqvOFdAfId//0OFBWPXt/eEhr6Z+y+hSJzq1u6/6kFFMiSymfpcmKlfmJDSGq7mmabmPpU6ev+Diga6CCJm+8o9s1WnTFhm33VEKK2C4XfHfH0qmUvK1FKeOWPh65lPkR4pI6TgfYdr2paGnmEk93A7hIk3RwznN3J4Xe75GD4X2fwUkuDQWyrD5FbJcv2Xb3KyWXHlFKeWomGqzPDxuX11Hp5A/1LE2Oy2HQTOorzJXn6wDy/vFwDKpy4/2tfHCO/aIxZul9WXWK+C5fcuPdsZTcHkCUkteRbnBCfri4so7tLc3ujhIV2m1F1g8ON+8QiI1ZxffSkS8X4tcqn7LKFEW7XPu9dOdS8umRpCT34nSDk/PDxO3nvfRZbvb12PGSexdetHSVxfTCr8fOcbOvxyQ5av5tg4vbz9djp0kZCYWW6IVO8Bz9ixA/FOJlcyl10riABlIyRonIUc3SQtxyOt7e0urOlvPzJ+p6YGK/hTiWOd55aMvmUegy8CoaSPm7o9XKUdrS8bgldezA0suyLA3/Lz3+ZRwdP63KLhsncrC/K+3+L11XDp5I3NI6dmJpAIAOWBoAU8DSAJgClgbAFLA0AKaApQEwBSwNgClgaQBMAUsDYApYGgBTwNIAmAKWBsAU/+jynOrCHTlSAAAAAElFTkSuQmCC" alt="" /></p>

<p>而处理决策集时，我们不再简单对每一类决策类求近似，而是求他们并集的近似：</p>

<p><img src="data:image/png;base64,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" alt="" /></p>

<p>有了这四种近似后，我们可以将(1)(2)分为一组，(3)(4)分为一组，分别按照原有方法导出两种规则求解一定属于<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAC0AAAArCAIAAABjIZbQAAABFklEQVRYhe3W3RWDIAwF4MzFQMyTaViGYeyDlNOQG0UB29OT+6gRPwL+0PYboW8DStwh4w4Zd8i4Q2bIkXPurk0x8EH1mIMDkR4+c4ipLduPmJrxdWkwmcPHrbQ0RSCftj9ShBPOHEi0phxUx5AjRQIxVzdFonoz0PcU24sr+tixgXYWW3O5IFiOOl4tRA3BDj2HMpaeiLrwpMIogg7JFzrUpc+Fkw0BBf37w2L0dUQ+L93nkQOtSrdjMyb8Hrr//WEx9LpMjHboh+ABhnYMbY55DuOTsbQXwAHuh19h6xz4dY7bkJkns65/5/aNMrtBd763J780TzlWMG44ljCuO/btMZ3yF//rE+MOGXfIuEPGHTLukHkBU2B8TaHjdcAAAAAASUVORK5CYII=" alt="" />的元素规则和可能属于<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACsAAAApCAIAAAAj90ecAAABBklEQVRYhe3W0RHDIAgGYOZyIOZxGpZhmPQhOS/Cb6sX0lx7+GiJfgI1oe3pQU8DUpCCFKTgLwSqOh0rXOoo+oKgFiK/sNbCYsP2Gey4WAXD0FpOm3ijsDdH9IEwPKTWQl06jkkzZwXCBMawisJEbRuQZWH7cOOOBBtI3qEy9m7zkaCt1wJdEoDAu49VfE7dgx8iUJAX9OTOhTJzLlOfBBAw0wcjwFwW+v/C3O9OgGowLdjQIU9Lz9wHI4CvQtQwAt/gdwOM4FITRAgGV/1957cCsBO+jO4Q4MsYH11rjQQtvpn2hghNyvK78d3HxlcE4YBVQTxgUbC3QSzil7+VU5CCFPyb4AUdP3ozW1qttQAAAABJRU5ErkJggg==" alt="" />的元素规则。</p>

<p>2.1.4成对比较表法PCT<a href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAOAAAAAhCAIAAABP+zCnAAADOklEQVR4nO1aybXDIAx0XRREPVTD6XdCMfkH44RFG2ADydPcEiyYkcYYsI+XQrExjtUEFAoKalDF1lCDKraGGlSxNdSgiq2hBlVsDTWoYmuoQRVbQw2q2Bpq0Inw9khg/Wo+34ABg3prXOgNDs5mwcGZd+X4btNKk3UOzvT6oGQ4huBMIczbSupDSchGoETVrZPKRIxYGjS/ydHegzPln1lkbMMZgspbvSQJCs4IUgkG0gZt0estzLP4/7EkJBcTooDGaWVCR4RmUG+z/J5ZL/IIj1dExn8gf8xUjvOlo/gZVKaXGt/bpGmtQaG2LQ1a95fXwVt8SspjiQfsXOU9FhU94kV6MxNSjUsNCjZtadB6EkgNytT6QyY4QzxaZyun7iqsc8kaVKCXTsQuBoVbdjRo5c9zYZz4k6z0aWZHFgXgAYu41nTJ4Cm5BuXtS1HhJonXO2RQJgNwEA5UFNIgKNPDDCuDFv6M27are8FYwO5UwIPoODIC6tyiHFocwjvCuEX9E+7iWb3jMyieASII4QKLkv4/n2Fp0PM4xJi0VMXZCDc1VneQhAcl4vTRoPLmh5NwBuX13vCIRzNABcFcRBMl2jCf4VE2030xBg3OGOerIz8BD3Jg7JRmuUFFeu9Yg2IZIIPAiyUrTbxlPsPCoNwMSbW/C1EfSvM8WINCjaMGHXvES/XeZVBE6bhBG7b28xnmBmWf4OhYWRUEjJrWoNbBW5zRNSgJ7qWLWO8da1AsA+zg1cX8WSfVNp/hkbVJZr6aRl17vqeGxY31n2HPX2BQ8hYO8fJdu/hGvaMGpTJQBtFJAEU1vVyaz/Cowvglf5HRIkjWFa88Pz8oThPAoMsJ0MH4PeegXXq7DSrIABiEJgES1fZ2fj7Djo9F2msN4IkT4HjrAvyYtwsiht2Ye1CPJ+G8uE3U3DJBI3Z9zXSDRR9Qfm15ampdfO/9mkk45INJiBcvN2gjw87P7dqXdAyPceXeHtYDs1Xv3fSVBsWS8Ll4tUFbGa76HrQEtLqjhv6s+qLy+KgspIf+70EX4KEkfDXDn/ii/kqbceElfJP1e9g/CV0Mf8Kgit+FGlSxNdSgiq2hBlVsjX9sY9kgdo3PogAAAABJRU5ErkJggg==">6</a></p>

<p>当我们拥有一张已经排序的信息表时，除了以上提到的方法以外，还有一种成对比较表法可以处理排序问题，导出规则对未知元素进行排序。</p>

<p>该方法的核心是将原来定义在U上的信息表扩展为一个UXU上的信息表。</p>

<p>新的信息表表示为{UXU，AT&cup;D，V，f}}</p>

<p>UXU: |UXU|=n*n</p>

<p>AT&cup;D中的属性与原有信息表中的属性一一对应，但是不再表示具体的属性值，对于AT中的属性a和元素(x,y)，新的信息表中a的值表示在原信息表中元素x比y在属性a上的优异程度。而对于D中的属性值，新的信息表中的属性d仅表示x优于y或y优于x。</p>

<p><img src="data:image/png;base64,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" alt="" /></p>

<p>&nbsp;</p>

<p><a href="http://images.cnitblog.com/blog/52809/201304/26002556-bfb40257e4754eaea461930075596b2b.gif"><img style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image116" src="http://images.cnitblog.com/blog/52809/201304/26002556-b9d91f72f4584968ba8591a70ce244fd.gif" alt="clip_image116" width="203" height="24" border="0" /></a></p>

<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAQAAAAAtCAIAAADOVSJtAAADh0lEQVR4nO2b24GEIAxFrYuCqMMSqIZmLMb9UEeBBAOi4uaev1kd5JFDQGaHGQDFDG9XAIA3gQBANRAAqAYCANVAAKAaCABUAwGAaiAAUA0EAKqBAEA1EACoBgIA1UAAoBoIAFQDAYBqIAD4DN4Ow2B90zLvE8DbYcG4qfBbcRvlRU3OcrfU1Qc0YHIm0+nelgR1ZoSruEmAX6MmZ8QhNzlDCF5UFNc9hYWY4cBeo+BCS4/CJx66YL/QibbeJkP0m1kGrnOKBIh6P2m4t01zwC0CTM6UZyo6/AuLogWoqQ+bbvOjWc8SR2nRkzO9RP88e2tM1JeTM/vcsl7xNqhxaQY4jlcyY31BAGKakH2JnP+vC1BTH9rH+TDgzaF7oHXOv8LknI+j2bv1Uxi2LpzUqwVYbjgo8AEB2Ng5/1bcT6VFkdFSVZ/WAkgSB2VANJm+ytK73tIZic+zFwUIDehcgGhBaJwjVojEYndOhz8pShAHiQDSQpaVZ7z6bpoBBB6mk8Cl4Q4an+2/eOFN13Od7Jld630CBClc1P/jOJ7dstJPBiAXKo9lgAcE2B6Si8TIgEvLrTCwMkHITenpfcli/8hDAogq/EEB6Eb9nyXQyjop8+N3zINNlv+HNEDWW/yQPRnRAf2UAFxSPAZ9RwJQL8niAeE3qd8RIFlEnMLUaE8CV5f/S9f/ZKLDk6l3emt0I/266h4BooCiHjKOY6cCSKEleFkAatiaZIBcCduTL8Z/lFIzAlTsrqhtwL2b4FwCGBNOm/OjGwFe3gPQ1aGVrI7/ZKORe7Ssyt4yCypqFmWWQCIDwrijSsuctmQPe0WvQfePogwgpzMBqK54ZxM8U8EVvpEupOBES/6jF+74LAqbrHqSVsXpiNAmI0DuJJKQ43h7Mgjse7E+BGAP9WXfjJN2aVGJANJCmAiJV8j1i5+yA+SS7S87vR62X8ZNa1NObyUauvXCYRkS33a21ea2eenf/8NPIaqQzXproFr2MEYYOCfl9ApR7Z5OynJQZxxM8srRurn9CCBZqGwbO/a1kVCA03L6JKl21Y+u3iTMNDUvSlq3tx8BMi9e9uvrVTbriwQQlNMjH6125/QkwDxnJd8CoHKP3bych/lotXunNwFybKeo1sr/x+DOch7mo9XunC8JAEBzIABQDQQAqoEAQDUQAKgGAgDVQACgGggAVAMBgGogAFDNH8zM/9A1JGkyAAAAAElFTkSuQmCC" alt="" /></p>

<p>通过对新的信息表，就可以导出一系列的规则，这些规则可以用来比较任意两个元素在d上的优劣，我们可以通过这种思想对未知元素进行排序。</p>

<p>在文献<a href="data:image/png;base64,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">13</a>中，作者引入了一种得分参数，通过将元素两两对比并根据比较结果对每一元素求出一个得分，根据该得分对元素进行排序。</p>

<p>2.2不完备信息系统</p>

<p>在不完备信息系统中，由于未知或丢失属性的情况发生，我们无法通过简单观察属性值是否相同来判断两个元素是否等价，这时等价关系的定义就需要重新进行考虑。关于不完备信息系统的研究有多种处理方式，关键在于对丢失属性值的处理(完全忽视，部分忽视等)，这里仅提出一些常用方案。下文中我们将用*代表未知丢失属性。</p>

<p>2.2.1不可分辨关系与相似关系属性的不完备<a href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFMAAAAkCAIAAAB695EuAAAB00lEQVRoge2Y27UDIQhFrYuCrIdqbMZicj/moSAPzc3ErKXnL6MjbFBkEl6rKsx2YJo2+Xra5Otpk6+nTb6efp48RcA8+lJGiMmZY5GnGAQpS9LJzaQyfIAk7ODJCII5Yukcrp/FdL5qh8zLeYqE47DAvOEPM8JNeE+4fx6jWgCLZGzZLW7DX8AlzwiChYZSTvH1NMXWJxe8eclyTFnQZA8heBueOsCZ+Hjl2DXQLJIxOnvdyderRs8IaoyM+Nnkgs/ADpe8MCE/j8NApfJP6ZUCNLDthUxyBk5PaHOamUE6dpYgd5OX13vOgx/OdtNessiPxAGUstmEoRe8PO1Jve6ua0ScJQbRILcjb0RcvAAGvO0gzwiAiRwpdeI4uW0/a2YJXUYUbkBvIzvkd0lTfWDeDJJ7gZeTTvPdll1h1bsLoVe+Eh6ypF8Qxs95bzh5wyLVNdYIEU/LTVy3qUpJlrsVZ3uotV0jEoqaINqz8rkpxsQmNe0fYBbqAr/Pa58uKz1+Wve5gfW8Sp6bLszp4bqk90NOA/e4qg0u9J//ZrcXmElOMq5dE+/Cu3GbSJ4ixAheMZnyff6s3kL6oGaRWx9Y39HP/xv1mDb5etrk62mTr6c/nE5I7YZQGGoAAAAASUVORK5CYII=">7</a></p>

<p>类似于之前的相似关系，如果对x的所有已知确定属性y的该属性也确定已知且与x的属性值相等或相似，则x相似于y。</p>

<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAT4AAAAnCAIAAAAZ9LOAAAAEs0lEQVR4nO1b27WtIAykLgtKHZZgAbcOmrEY74cvBBJCBM9ir5mfs85WwxAyhIC6DQCAAeH+mgAAABZAugAwJCBdABgSkC4ADAlIFwCGBKQLAEMC0gWAIQHpAsCQgHQBYEhAugAwJCBdABgSvytdT9OyfmlzXSbnnHOlZkvE1mUib2WoQG/7XKNl5yiG7APndOLZnHkz6Z59DtFeOxVkDj+tyyTQ8OS0/gxsMlenZb3+mozExnqht32uPaldnWe2ruQ782zMvGXWXZcpkOuu5T9Qb+RcQbuyrAWbMTw5pSLbTBTv0dt+AIVzKtn0If8Fz5bMW0s3lIInp4noxvAUzxdcatUvYVKbkR1NP2UjWat6evVu/ki8GudUembrQf4rnu2Yt5Ru1LNnEq4Bu7IoT4xZz3hK1vI7dD5UpNxyNw1DpoyUknDZoKyPxIp1yt1GqRFbMBvIF8x9xbMV80rpniK4C8l7UfzQ1VH6kg8eugmXigm5OlWUnOnPya+ZvYZ7j2IJRlIg9JgTivqJjUjOLDQsdy3sDfnjlrSAMdVeyiXGpnaOxTNW8q15KmLbVvLO81zkbcm6xwwVBU2c2tK5Juofkwh0yPedj6tYqMliOVwjeHJP5b5OuhKxnDN507ntQD7u9p5MRDRlruvWC9m+KJ8rt2DzDGNaCB+ZxRuehdhOTSvc3ku6h4e4uSRf4kZd9xTfUbWt9RDX82c+QT79+Wg/df51veBo3ewvE+P6XcxwpfXrPh8RTdOUk64+g2Y562aswk02z2wvyDO27Dzl2E55MsxDuXaTbmbVGtLJavfBd12WTAKoLwXjRwr+ve6OcnD82ON/Wbr6LSrWCN91RcIXrl7riKO4SoeFiaoqFGYWzdaPwTNK40q85SnGtk668zx/J900bQXKyHTz/nFdKOODzlk3SFFxrooj5GmlZFMVP6UAZbfAkyt1C2aZ49usqzhKKZq3eYaxblswv+YpxrZCunMCmcsOW61LS+YcKPifK9L28+6ccIMHVaitdQ/rx4G7sFi+d3c0NrXVolTRJc7UWTedCFXYZxE76J15m2e01lV4yXOTY1tX6+oVe6FeuvtK/iTrad/CjMhksuLedyq+Q9Zjhzl4mCgO+XBu9+SmaXKO/L3uKeww68KHMZJxpq4z1ac0ek6tHlI6x+KZKh59eV7XmNjW7zB3lG543nP9t+9/pLnwSp9h9a6brDf+6Mt4rvu8zJ4JufMoJUrrrM2aiT8yknVmuvzjz30ahG3fc121cwye2Rqe61p5JkbYGEnPWpow//Dzg3Tm7NRMozEt2sxPn8d6kt4Ome0NAD06269xzl++TZXhaRhBLrZTnu2YfyXd5By1Iz4Sb3YJcN4nXjQ22BSd7Vc6p5JNO/I8Ff0I8rHdL+Vu3aW7M22zvqtAu0IotRkcteQOr49mmU0kJbFhdWt3TlUN/Zo8y7NiBEux3VW3W2/ppnXjd+j1ve4//nWEcxjlje5f/l5XeFdD4ZzvvtfleFaMoBzbKc/mbv/dT+3/AmdEEFm/vPhhDOGcIUjugHQBYEhAugAwJCBdABgSkC4ADAlIFwCGBKQLAEMC0gWAIQHpAsCQgHQBYEj8BxPczVOhocp8AAAAAElFTkSuQmCC" alt="" /></p>

<p>有了这样一个相似关系，我们对每一个元素x定义两个集合分别表示相似于x的元素和x相似于的元素，记为：</p>

<p><a href="http://images.cnitblog.com/blog/52809/201304/26002556-08d396544208412db41f55b70cfbfdef.gif"><img style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image114[1]" src="http://images.cnitblog.com/blog/52809/201304/26002557-f694029b8fdd4eb88cffd420159c22b0.gif" alt="clip_image114[1]" width="12" height="19" border="0" /></a><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAWgAAAAyCAIAAAD+5danAAAEbklEQVR4nO2c3ZmrMAxEUxcFUUdKoBqaoRjvw+4SCJKtccDAl3Pe7g3YkjwZ/0D2kQAARB5nBwAA9wPjAAAZjAMAZDAOAJDBOABABuMAABmMAwBkMA4AkME4AEAG4wAAGYwDAGQwDgCQwTgAQAbjAAAZjAPOZRq6x+PRj2fHARIYB5zONHQYx83AOOB0MI77cQHjGPtumLwPP9bU2F9oITwNvZ/qEVwqexd/kLPayN4Z5FIFupM8djeO3y3rFju8aehKgU9D98irJx/LMap4S/PVyeqD97glZWiV9Gnw3QiGur7sVRz76x/QRrqkPOq0ke4lj2NWHNPQLSsz9mZKMWUoF26DOPQL49Z8GjpTzPqUEqtkIM7KL5dAfaiGcShDfkl5yNpI95LHQVuV91h+7XEd3djHw63RxvEzras9bwVdsRaNVLI6zn2pDPVP7avrFG2kS8pD1ka6lzwaGcefOhbRqWMtSilt3PgAzjCObSVjYR6/4tgj1F8qfOBy8jjJOJrJo5FxmL7xf8Fit9aPuX1NN0zzBBXY3y3mlEUX/71aE92rq9C2cR/jyMeWr2S4dC0OAIuDHuTt2OKe8tjNOPLph+Xh5xWUx/P5XP6zhXEYY70JduznbJzK6juxsV/2sejh9T/bjtQN1C4rjkxspUpGS9faOOq22ynZVb2fPHZdcfjpF2seyCsmj3bGkfNkY5j/VkyD9wBOnTe3Q/zWqfWoT1ss7rhVcWMrVXKOI1O6RtYRCTXYjDUy95LHzlsVL/1AzQN5efJYmkXzFYd5CGWLIztr/I9EZC3qFGK1m7OFYT7iOnarko+tVMm0uczjcPMIhio0E/wgpevJY/8zDjP9SM2Lec0tre5+Pp+nGod5+mIWYRr6zv/dQsWUYq90Hv2YeXVAPcw3pVx1OGrHVqrk3HCmdLVPLEVioWrNLLiXPGRtpII87PRjNS/kZcjjueHtljaHo5uMjGH+s0LXNz/dxK6aGaz9a5KdwwnW1UZhqWvFVqrk7zXl0rU/HK21DtsCbicPVRspKw8v/WjNc3k58jD9YqbJC2Ap/W/GVua4TngO3U6+4g1Be+gKT7pFAZpnT24DpT3yNrZQJQOla2Ac5VCFhtb33FMemjaSLw8//XjN/bwy8mhpHG/7wNWpzHJTuFwdLU+DX/dv6rHXg3rzuHz9eeyMw8w4d3X5cG0RW6iSfaB0jV5oCQy60Nzbouum8hC0kTx5OOn3vVhzL69LvccRQX3wqc6Z3qo2t1g8mKJxHBNbqxc59kP0gW+Rx2eNe3lVyePUX8eG5aHPJ8mtR/OfIAp9HxRbxTr+dJQh/xZ5HNR2lTxO/ll9JOYqWcytb5/Wnzj1Fg9Hj4hNPza8BkE9f488PsHPq1Ie3/L3OObN4QVX7AfG9sn7FFeg1d/juLI8PqGQ1wfyuIBxAMDdwDgAQAbjAAAZjAMAZDAOAJDBOABABuMAABmMAwBkMA4AkME4AEAG4wAAGYwDAGQwDgCQwTgAQAbjAACZHw5mHayMxGZCAAAAAElFTkSuQmCC" alt="" /></p>

<p>这样就可以定义任意集合X的上下近似</p>

<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAZwAAAAwCAIAAACqiltPAAAGIklEQVR4nO2dyYHDIAxFXRcFUUdKoBqacTGeg5MMYEkII+Ltv9skDiAhvlhsz7QAAMCNmI5uAAAAWAJRAwDcCogaAOBWQNQAIJgGcLRNTwGOBitzcNM0+Xh0OwDoBKIGvszBQdQeQ/TaJBb9NLkwD2+RFVcTtehbvTtmpOojYihz8IbBxruq5vaD5fAkvXEtIGpnYA6O6ITok12L99fpZz7OwZn2yRzckCG0LgC/JE1O7MkNYUWtKIv4Kf0jwiza7dRVQwK/3r/JddcStmMz9I9FTWGslXWXETVxaG37p+gH3cBUN2Tg4GFDLXriY2mmNgeX+GBVufXPXPH+3UQEVYvjDJ1cUO1f9rPTQjhLJd92ycNI1DTpUx0ZNtZdRdSiF43NlYZSfLMRN3ZGwPYqLV81UUuLqjd867eK26kqh7im3r+bi84M7yeNfBt52W6mxqfPHc01sO4aolY39D+g5+DoDmgcoGJNoyYE7Lhk1EsStcLearvfk4K++a2Rkzco+ndox5giOUkt392yZitqbPpsj4hu68aI2mdK6kJ4++P/kzmZU6/7Xf+zbcbPmknp+tPARbyyFA1ll6WrhTJLlfVn0IbS/Rk9+bEgatHng4OuUYJyWM1eycnZ8qq2YiF/XO3fK0zUKmNWId+LSfKwEzUhfe4TqKp1r9dL+NZe1FKTok/DNfo1LEsFe5sQ/eQ9ZY0uWvO6uCu4QdowzDK1SAvuD0I2ehhNE0StNKx9CEgKy9vLmNC/36Xr34HnN7/K0HX51pRSx0zUhPTJNLMnNS7L8mtRy+3PxsVqyfbL6CcXonDwoRoQ0hyJas1eSHUqTdvWrLrzolnT5NPPtajde4CC2wV7SScbHGsp+neArB2SoevyvVhkaCtRE9KnaGxrakyF7JeiVrYl/Xujvu8vo5+c99Kgr4vaHJwLsban0i1q/JiRRxN1QEQEFNs+VtNYUUuL2qtqktt5eykjujVN17+1pjVzTIZWybdBhjY8/eTSp0YNdanx9XodJGplPGk0TbG9W4mDr9TXiqLioHn5SY8ZOUCkdWm1aEnTWFHLitq59KuJGm2vvaip+9f49PWQDK2W77OImpg+W9atbKkfRUuR22spaoUJc/YwYWHA51pN30jXZHpRKax/X+dbTLmn5oO4C6BTNbp94tKV+bIoaZ/h4qkFay9Z1/5t7db+tVt8HpChG+TbIEPbiJqYPhWipkyNGi37Yi1qiWg759bd0xAL85ILVYEobDfmH4vBMOT0c/lMpD6lM9Oqhn3BYiRVpiaEqG29oNqlIZtDul2wl3PyHl3d0b/D5mnjM3SLfG/btwMTUZPTZ2VPrS01HiNq6d6Rj5+/XJg3u0qZtG+M3s5rymVFWlyaPWuZyULT/gfW9qBHjJJNHmXVr3JJ1hi/HfWEE5IjukZTkx9o7JWcLEwkig7b1b+K6U0DVhl6E8zcjTIN8s2U0oiBqFXTJ9/MXalRyW9uvtU38n2oFPx2ItvXh2bbLbtPE0dg+0D7lka3m+5pNWM7VTPI0HQwZ07aJd+LSYbuEzVl+txGRG9qVPAbUdPvdnySonOlDPYZajRNW6yHTiejRa3NcXZO3oXV/oJZNVwwnyND6wO5a6nbbmy3dT8RtcYdXG5bfXfQGg8223VOF+NFTe12ycnMPS3s8nMPRsdAuor00UwH8ykytNZjvWuTxub2Wzda1LJwNpjf4H1qh4D3qWV1GVR1ggy9PZfiKuxNF22T227rrvFAOwAn4HYZWqFXSuXT1KU5/TexDqIGwHMR7upfFCf65wSiBsCj+ZxXMnfyXk3RFogaAIC+h/AcZ2E7sBS12gHXHgybBwB4AlANAMCtgKgBAG4FRA0AQPO5h2V9Udxljg0gagAAls8TETFeQc5WIGoAPI73YxHcs/XF26+8p/7n7HmBqAHwRKJ3LnlwmL/hP15L0RaIGgDPJH8XQv7KgX8Rm4O72jwNogbAI4kh/18K5Bub1+mb8l9snAeIGgAP472jRryK+ztTS54Jvd7zUhA1AMCtgKgBAG4FRA0AcCsgagCAWwFRAwDcCogaAOBWQNQAALcCogYAuBUQNQDArYCoAQBuxR9JL1oPBwXx1AAAAABJRU5ErkJggg==" alt="" /></p>

<p>有了这种定义后，就可以像之前一样导出所需规则。</p>

<p>2.2.2优势关系属性的不完备<a href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFMAAAAkCAIAAAB695EuAAAB00lEQVRoge2Y27UDIQhFrYuCrIdqbMZicj/moSAPzc3ErKXnL6MjbFBkEl6rKsx2YJo2+Xra5Otpk6+nTb6efp48RcA8+lJGiMmZY5GnGAQpS9LJzaQyfIAk7ODJCII5Yukcrp/FdL5qh8zLeYqE47DAvOEPM8JNeE+4fx6jWgCLZGzZLW7DX8AlzwiChYZSTvH1NMXWJxe8eclyTFnQZA8heBueOsCZ+Hjl2DXQLJIxOnvdyderRs8IaoyM+Nnkgs/ADpe8MCE/j8NApfJP6ZUCNLDthUxyBk5PaHOamUE6dpYgd5OX13vOgx/OdtNessiPxAGUstmEoRe8PO1Jve6ua0ScJQbRILcjb0RcvAAGvO0gzwiAiRwpdeI4uW0/a2YJXUYUbkBvIzvkd0lTfWDeDJJ7gZeTTvPdll1h1bsLoVe+Eh6ypF8Qxs95bzh5wyLVNdYIEU/LTVy3qUpJlrsVZ3uotV0jEoqaINqz8rkpxsQmNe0fYBbqAr/Pa58uKz1+Wve5gfW8Sp6bLszp4bqk90NOA/e4qg0u9J//ZrcXmElOMq5dE+/Cu3GbSJ4ixAheMZnyff6s3kL6oGaRWx9Y39HP/xv1mDb5etrk62mTr6c/nE5I7YZQGGoAAAAASUVORK5CYII=">7</a></p>

<p>类似的，如果对于两个元素x,y有x在x的确定的属性上全部优于y，则x相似于y且x优于y。如果x在x的确定的属性上全部次于y，则x相似于y且x次于y。这样我们就定义了U上的两个关系如下：</p>

<p><img src="data:image/png;base64,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" alt="" /></p>

<p>通过这两个定义，对每一个属性x，我们就可以定义四种邻域，分别表示<a name="OLE_LINK27"></a><a name="OLE_LINK26"></a>相似于x并优于x，被x相似于并优于x，相似于x并次于x，被x相似于并次于x。</p>

<p><img src="data:image/png;base64,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" alt="" /></p>

<p>根据这四种邻域我们将可以定义四种近似为：</p>

<p><img src="data:image/png;base64,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" alt="" /></p>

<p>&nbsp;</p>

<p>根据四种近似，我们就可以像之前一样将(1)(2)分为一组，(3)(4)分为一组，分别按照原有方法导出两种规则求解一定属于<a href="http://images.cnitblog.com/blog/52809/201304/26002600-46654f4eb8d3425a812e8a058f7cb3a7.gif"><img style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image108[2]" src="http://images.cnitblog.com/blog/52809/201304/26002601-40b39254b4ed46c1baeef5e8a609aaa9.gif" alt="clip_image108[2]" width="39" height="25" border="0" /></a>的元素规则和可能属于<a href="http://images.cnitblog.com/blog/52809/201304/26002601-140c3b5a8e49427c95480bb2ea1d5435.gif"><img style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image108[3]" src="http://images.cnitblog.com/blog/52809/201304/26002601-16fef5ab6f624979a0615dc36637716d.gif" alt="clip_image108[3]" width="39" height="25" border="0" /></a>的元素规则。</p>

<p>2.3粗糙集的规约</p>

<p>由于在现实数据中，决策信息表中往往有很多的属性，而这些属性有些相互决定，有些队决策属性没有任何影响，故而原始属性中具有很大的冗余性。由于这些原因，出于简化的目的，引入了粗糙集的规约用于消减属性。</p>

<p>2.3.1<a name="OLE_LINK14"></a><a name="OLE_LINK10"></a> Pawlak粗糙集模型的属性规约[</p>

<p>归约即是在保持一定性质的情况下减少属性，一个最简规约即使满足该性质不变并不能继续减少属性同时仍然能满足该性质不变的属性集合。所有规约的交记为Core(AT).</p>

<p>对于Pawlak粗糙集，如果一个信息属性集C满足以下属性，我们称它为一个归约：</p>

<p><img src="data:image/png;base64,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" alt="" /></p>

<p>其中用于替代第一个条件的另一个常见等价定量定义是保持参数<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAJIAAAAoCAIAAACaSDTKAAACeUlEQVR4nO2ayZHEMAhFFZcCUjxEo2QIRnPwpr0BSzVNF/8yVW4LsJ/FYo9LJoVy/x2ASSLDplKGTaUMm0oZNpUybCpl2FTKsKmUYVMpw6ZShk2l+Nhi8IDrAkAIy8wh+BAX2fpu8bAheLf4xqzEdgQoe6picMKV773E4KZqbzkD2wZmaTW2JAwTwTu3ndvISwzZMQSfg+pfDh1bYXudlmOTgEPwznu/mdvQS4TsQIUtpRjk2PZstbQFG/sRO05H2MuN6KXB1lOFLYZiE8dwZtZJzRgkZirjEbZXZnkl7oJM5TYtRcP1VC9sbGcjdm/KGK71Q1PVEgTPfVy72F6bZTQYWR4hcJN2LnQvXGwIELO/eaIZBHvNAi+o9bAtMEu69uvMqh2Y7wRZpWB4kSTJlM4CGUO+tI8NEU8/x6nlGqJabCvMkrH1Et7sjsqocbwIsSFArOObpYZ7/BZRm9S2N2ap2Brj050gxcbyIsQWIYRmAwxNPRHJqA2wvTVLLEEd48dsNXApG4J4XmTYIvh+j9DLktnR64qeKeMcLj+0gB1sc7PNemh/oHWSfQhH2OPcwm1JuF5I/WyNbZSz2rmtMn9Byk96CvH4PtYOCWanYaWUSLviKTf5mcWjNkNHHAB4XmrD4z1XYpslb36CKNqn0fI34zZC8J0mc9urge9RNbdNL5cJruzbRzVKjg0hQOzMBpvewn2VHmyUUsh5+9BQoyVJqu5EU4a8l1lZrglJcpdubOTMQvzellNb/1HkmcirmvHjyfHSnq/bVW1diuyw7Y9XAh8q98/K/ilBpQybShk2lTJsKmXYVMqwqZRhUynDplKGTaUMm0r9AQ4zuNO2MHL6AAAAAElFTkSuQmCC" alt="" />的不变性。</p>

<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPUAAAAsCAIAAAAy4mnVAAAEOklEQVR4nO1b0bWkIAyduiiIOiyBavjaTijG/VBHCEkgCOuZbO7PO08whptrCOB8doNBLz5vO2AwLITp26AZpm+DZpi+DZph+jZohunboBmmb4NmmL4NmmH6NmiG6dugGaZvg2aYvg2aYfo2aIbp26AZpm+DZkzVd/QupHnmUvDTzKXgfHzfjeWYEQKWK54N0DqLunE70/SdgvuMKog0OVNYKbjPUOxJN6L/ICBIKDtXne7mw8cY5K7OCwHDFRsU2Ih2TsHlVGTPyThybTtdmKPvBeLeFyTOMTdZN6Iv1HpECDwDXjwCDOL6/fcMv9TP2SGg7HFsVG10Z8Bb0VBfflnf0Y9lxgYWFAYjKuAj6kCYQOAOteLp+rpa0TdQTC0IAc4Vw0bdRHYmJwj8jlf1vSZ574sKX7kQODeKzPu9kisXtl823d1QGREPfFEIMK5o35AWqnOdFvgb/oW+Qay+cWRqNbxA7Y4EM6pxy/IyvOEGUGaWrkl1A32foxnPv9SYHvKP2mVSct1AypWQ9x49ermt723b0Oud+j5nzO/jo78cZF7F4pYUnDSAzNv/wHKdckkhHKr7wxaRmamycq6q7HIEoO30YCgJ4yF4zj/KFR0UdCmJdsZCcDbgBKzWdwohZn/zeYvw9dqnekIvPqqnlunkIXLjsuScy18GIPZeed9XB9I4/sY+5x/lSlRBUBEUypuwk2v6Yf6+HAghgRUu7mxK6fDrXCihq+IW8JTw1PI0ffOGmOIE3WS5TYoVjmXZGfwL9C1RPckbKW/MzrZt0/WdQohwbU++jHt22DBGL1v4DlvG6B2qT7iRwwobNlwt18RYeiIcEZMPH/Hfr29R0XLXtvA66SO0s1WgRiDSdwze11tA9FohW2hBkvItfsFb27Rc3h9QGoUZUlpEZu11hzJ311WD2LudDAHPUlcIOutv0ZqTmvEl50Z7lb8pSPQdgyOmG8zd++pVrucv6B1ZekODmgp5y3k/JGyT9k/I9Ay61Mdz9aoSHA+NFHLVmDpYaoegc/9EtGW4Y2cCrU3bdv1NQaBvrg5F0vPt8JUqsk5F4qJGh1LZsnzf69AV1fP97zLz8cbKwqdeBPoIOpUc5Tdzsgch6GKpIwR9+9+iE5/MdOfYGo9ooFvf3JmaWDPlvEwVGeOjSsGHiO0YzD6/XIgUY4reR6LMAlgQAvH5JfaQH/m+qqULGb0Vt5L6pMs8kRaGTrFf+37wSCnMsqvA7BAQ9jTqu2dLTVDX5txy66mxUd07v/XSbe73g2txshS9j3UGj5HYXZwUAporhfruntR7Pj4GW3FTPwq6F3DXU75uP/j++xVcAsTWsdxZzYwQ/BpXHOz3O7+GFLz3HRW5Yd9N37+Gc+WsJr+uhun7d3DW1+IPDP5nmL4NmmH6NmiG6dugGaZvg2aYvg2aYfo2aIbp26AZpm+DZvwFy3tbrl02YbEAAAAASUVORK5CYII=" alt="" /></p>

<p>可以证明，在Pawlak粗糙集模型下，这一参数还与许多其他参数等价。如：coveragee(PRS)和generalitye(PRS)<a href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFEAAAAcCAIAAACWK8TTAAAB30lEQVRYhe1YUZbDIAjMuTgQ5+E0XsbDdD+SGIEBTXc36Xspf7U4zAgi7fJ6ni13E7jBvpqfYV/Nn2aFSerZTVWIS+YANBdevB0oVWhd0nTa8uoMQZYzCqrQ4rkr3O3rfo3LtjUJFeS5cE9wBVUECtuVdbELVYW0yo1bnoRjb+jnY2u6IwCs2R7UmsQOozARgTh9GE8EAIWqspKoQh1IUMuxaqy5sCZmT7aKFKfJxNbENFRe42mSDXYVCsGik4OatWRf2VVYqjsJ3XACyROZHtzGgxNLIjgBQppN/wG5khVJ6TI9FlV225Npjg4LcJw5GeADNOvjgf2rfTxQt9wPwk2QDXdajmO34Pi8ZudoWSp1e32D/gWTNc7PWHMVIin2VcCOc5pt/7KZNgndcLvcx8Gm2vZAc2ta7imEvlOaR5JfWl0bRlz/8nRQjlvvaOvZfVZdenzx5+6zYbsPV2oKc2EsNNCGx5EDrG+AQbvFc8egJAZ9ux8eYdvuHAzSUe545AyucGGSCnqkfZ97ZjuOZouFn3qfr7Ejt654BnPYlJ2dw66wrpzBhfm16gTgNs0qy9Hw8q7s/MTu0lyYmCm5jLvXNb+fr7C3xPyV3aI5+zF0gX32f0P/Y1/Nz7Anav4BBdfEmcOg3+gAAAAASUVORK5CYII=">8</a>。</p>

<p>2.3.2概率粗糙集模型的属性规约</p>

<p>在概率粗糙集模型中，虽然<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAJAAAAAdCAIAAADKCnLpAAACVElEQVRoge2a2bHDIAxFqYuCVI+qUTMqhvfhjVVPwjAJGe5PZhwjYQ5oiePC1lJyn57Alk0b2GLawBbTBraYNrDFtIEtpi5gBB553BwYYZg5Rg80yNZXygyM0bvBSzIS2DHBvv1E4DpHvvdC4ETdS24DNoFWGA0sdE6T0Ts3nVjLC0F0jdFHiNLHMQFLrI7TcGA9yBi9895PJtb0QhhdyICFQNADbM7xClOAmTfXcTvjXGJKLwWwSCUwguTIEpwRVMgNjQCspdsC9sqsLZVdeLXExJTTHK/1YgB2Fln3ESS4RjaNZEMYvXWLVoG9NmsoIaLYoSDWW5voveiBMSJFn3FYaUzzqvBf8KoBG2BWeurizizhy7u/Ly8YvNhCYghnCiSIB9WBMfPp4bg1HaNUCWyEWTWwWniT1rKPl8WLGRgjUj4zKRDcjXQXLyGHvTGrBVYYF3d/LzCTFzMwQoBi0zeNPHPp49UA9tasMtVUjB+9UsNlX2tj82IFRujrVUAtJkZXr2d5uoazTfynvKsAk80W47H8Qlcl1pf/mHY7nliLDqsX6fRVgLUiVNmHZYYvPPFNT6ptr2DuUGFWnFYIQXUSnrQS35lsMgmasqy3eckNF09WAJOCtD0cJKVRa/ibxpkRfKWAnNbkf1xlHyY+qBFZWo23clE/MEZAqlT8k35D+wYlwDSFleUXhIKXLiRqdYeVdMpzaaVpWRESBysGpo4jyvdhMa/xry6e3jrLDb8ZCi9Ne+OcZc+hsA7b/mjuxQL097T/IrCYNrDFtIEtpg1sMf0BQdNLNkrMoE0AAAAASUVORK5CYII=" alt="" />的等价已经不能再保证条件(1)的等价以及其他一些参数，但是<a name="OLE_LINK20"></a><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAZCAIAAACO+YilAAAAc0lEQVQ4je3PwQ3AIAwDwMyVgTyPp/EyGYZ+kIBCoJ9KfTQfhHIyxsrjsZ9+jApm5oz+Cs006FApQl0KzY00SHWn0MUnXUVGEfrAhAapWuVERQDDyxkVfQlnGkzgnS47rmjQp28vadBtJxs9RE5dt/MOvQDVL+KYFhnNIwAAAABJRU5ErkJggg==" alt="" />仍然常被用于代替条件(1)成为归约的两个条件之一。</p>

<p>另一方面由于条件2也需要进行修正，概率粗糙集模型中归约的要求变更为：</p>

<p><img src="data:image/png;base64,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" alt="" /></p>

<p>其中e是一个满足一定条件<a href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFEAAAAcCAIAAACWK8TTAAAB30lEQVRYhe1YUZbDIAjMuTgQ5+E0XsbDdD+SGIEBTXc36Xspf7U4zAgi7fJ6ni13E7jBvpqfYV/Nn2aFSerZTVWIS+YANBdevB0oVWhd0nTa8uoMQZYzCqrQ4rkr3O3rfo3LtjUJFeS5cE9wBVUECtuVdbELVYW0yo1bnoRjb+jnY2u6IwCs2R7UmsQOozARgTh9GE8EAIWqspKoQh1IUMuxaqy5sCZmT7aKFKfJxNbENFRe42mSDXYVCsGik4OatWRf2VVYqjsJ3XACyROZHtzGgxNLIjgBQppN/wG5khVJ6TI9FlV225Npjg4LcJw5GeADNOvjgf2rfTxQt9wPwk2QDXdajmO34Pi8ZudoWSp1e32D/gWTNc7PWHMVIin2VcCOc5pt/7KZNgndcLvcx8Gm2vZAc2ta7imEvlOaR5JfWl0bRlz/8nRQjlvvaOvZfVZdenzx5+6zYbsPV2oKc2EsNNCGx5EDrG+AQbvFc8egJAZ9ux8eYdvuHAzSUe545AyucGGSCnqkfZ97ZjuOZouFn3qfr7Ejt654BnPYlJ2dw66wrpzBhfm16gTgNs0qy9Hw8q7s/MTu0lyYmCm5jLvXNb+fr7C3xPyV3aI5+zF0gX32f0P/Y1/Nz7Anav4BBdfEmcOg3+gAAAAASUVORK5CYII=">8</a>的测量参数，如<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAZCAIAAACO+YilAAAAc0lEQVQ4je3PwQ3AIAwDwMyVgTyPp/EyGYZ+kIBCoJ9KfTQfhHIyxsrjsZ9+jApm5oz+Cs006FApQl0KzY00SHWn0MUnXUVGEfrAhAapWuVERQDDyxkVfQlnGkzgnS47rmjQp28vadBtJxs9RE5dt/MOvQDVL+KYFhnNIwAAAABJRU5ErkJggg==" alt="" /><a name="OLE_LINK31"></a><a name="OLE_LINK30"></a>。另外，<a href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAUMAAAAqCAIAAACm3a52AAAFIUlEQVR4nO2b24G0KhCEjYtITgTGQzQkYzCcB0eFvtB4aWeWv+pt1YHmswuwdacMQdDf1/TtACAIekBwMgSNIDgZgkYQnAxBIwhOhqARBCdD0AiCkyFoBMHJEDSC4GQIGkFwMgSNIDgZgkYQnAxBIwhOhqARBCdD0AiCkyFoBA3q5DSHuJz6xRLDnJyi+eM6DzN385ymaZoGTUJRbjBViGmeBCnt1Rezi47T6yhSPD+Yfi0x0BCq+D7nymNz+vzuAuW2RIxHdEsMJRh2eL1YvhePxypJgElHdYXnfuX5aAxcDTXycju9xNmRqhPMVU2Uaa7GvzYvmoTmZtFpmos/P8z9Vj8Z1h5odaqKzPj1HdX9CBR5aOvBIrglhjrYz7123Uc0cTzAs3QyN576MxMXD4TQFPMwza7ToztMo+9myq085KluO0oQOm9jWW91x0WwShgOXqbTKaOW5hCCcN/KOITk1PA/phbM/ARP4mTtFAvLwMXzNue8xJj2BpQ5MM1+NP1htjsnvVOPynNYtX6wRhw3MIYND1pLDCpWA/l5pblOGzr/LjEmhoncSzE5fZcRe067ylNcfrudbOOqgNN0Y3tG2rSL/GDuajhZ8GCxBjSSqN4JrjPgGw915rPE6qHYINXTyknVRubrwSfV2JMMW8aFTHBclXsw3OV5ZU22cVXAaYHJeQut6BWYzZbpg9qOqD2z0XNvPNPp6V6o6z5KG9nrItUqYV39lP+q8EkCaiH5ObkDZr7HkzwM9zrZxEXLg28+Cyvyh5kbTl4X1lAUBZmte418HHWFaDuwFTa56il31JOoWO0q1o8tOLIlVEfml5hd09ktnqSy1elkE1fVG33eFGc+c669LX+YWXdyO50bGaSWEzpDvS6D1xJDiImWgOULH7ufrC1KrvLstmUUql1iQI4rTNe0eJ1n+Wx85jnZxEU6I+879eR0XaydYa7SnNzunL0TqU5sZ1gBQU3JR9QKea8iqJFX12qwTn/DQKtdNJfI4vvpulh4GvG4lq57psUbPLl7u5xs4+rIW6Vq/aXMzI8l56W+lSmsTlNeg6tbPf86at8Hhfk/Hp06yCoQe8Vtjv2cmS0j59qz4kOIcnvJHXgNZr7PU9xRT0xiUwYu5d4dM4CcuGQQd2DGhVXZXGHuUvYwfXMD/QBEqnORsq1uc0sH3jSHuAj1eKmwJ79gN2bIxmk1yZSWJnKbJitjaMBC6rEC4lswhfBu8Ty5Jpu4xFDoQeFdCn22vgcz85dFr8AULj3UHlJdKuAemhO5SHvJcuSm/t5ty7ijGX5jq1+XI9k66xmd+T65x8l1RwKB4gI2gVfrhyS21XGHmV149pBknSu4VFh14vGxkFb5d9EWTw4zM55vwBSPeqvCtQ+6tRoevyhnQOMTxwuyX+H/nH4XZjZ49jv5NVEj2zwlmJnz9Id5r+2Lqt//7QWy1rct5RZKXUfyXWKPf+D1gn4W5hMNvC22v7F4ijDpH58rXWF+y8nlN5/bLjyEmGhNY7uomPeKjZD6tusSsj+Xdqt+E2b+mzxrDDZPGSZrKG+X+MH80vammMmO+k25eagGneYwz4E+PrQqjP/U/yebMHPJ8w2YRoO/rHqwVnLKMHNj+O//f7KzOiqES0pb5Ud8sXC2xDiu+lisPAHT0G2Y3W08qy+WHJoTzcFCpHJpZhtZ1qz9oQiYPboDM3+L588VDyEIuiA4GYJGEJwMQSMIToagEQQnQ9AIgpMhaATByRA0gv4HcFPRS3/biycAAAAASUVORK5CYII=">12</a>中对变精度粗糙集中精度参数对归约的影响作了非常细致的讨论。</p>

<p>2.3.3分辨矩阵归约法[7][9]</p>

<p>一般来说，由于属性种类较多，规约算法很难找到最优规约，采用的都是启发式算法不断选择可能最好的属性加入已有属性集以求得规约，除此之外，还有一种基于差别矩阵和布尔运算的规约方法。</p>

<p>这种方法是通过一个nxn的矩阵，列出每两个元素之间的差别属性，根据这些差别属性和布尔推理的方法寻找规约</p>

<p>差别属性定义为所有导致两个元素决策属性不一致的信息属性集，元素x与元素y的差别属性为：<img src="data:image/png;base64,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" alt="" /></p>

<p>于是定义差别矩阵为：<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAARcAAAA6CAIAAAAV9IrfAAAE1klEQVR4nO2d24HjIAxFU5cr2QqowyVQDc1QDPvhOAGMQCAwOHPP3yS2kASXl3Hm5QAAMl6zHQDg8UBFAEiBigCQAhUBIAUqAkAKVASAFKgIAClQEQBSoCIApEBFAEiBipbGaqXtbCd+FaOU6WMJKloXq7cNGhqJUa8uQkqqyKiXx201GRbbq594Kr1qGOTo01PRKprXDR5q+ttNyKiJFfCn6KEjqGhFrN7+dPy3YvUmbexQ0YIY9afDvxurN2G+f1VFVm9dF1nhmm1scoyamf1GVt0K4fglltFPq2hICOMsv3meiOSd+UgYFSYNACpax/KBUc+aznZYVoyn1DMJkw4VrWPZOTc997U8QkPOlYYbYZODitax/LH+jHbpHqQh5/LOCtMOFa1j2bmH7U8+bAWXG45keX+MiqJNtzTfex6qoneUz1BRaTER1aMwtg7WMu36sN5arc0qGnhO8paxqNn/G1TEsX7bOVWyoFwr8fu8TVv/g4Z67WXtuC15yxwVjRyu7lBRu/9DVcSuzHr/OYN5wiBZUKZJXsIxXR4mya3RLUs2ULapyKjXa9tGPSQYryKJ/yuoaGz+eQWxdPxunJ3SJbZGK/9+FZ2bHaMeto1eF8n8n6+i0fnnFcQbDTkjVp1DEmvrqMhP6ZidzrFjkdT/2Soan39eQbxa6rtzL7W2jIqik5KMzU6j39+nhxNirjBKRbT//jeZ86CTdxfq8x+YzuNbKhXEGheM1qZfvsTWSuuikuF935OfV6qI6JPy253nDecbuv4BQWOutw5UUb3/XMt9KHWJJf+D7yVHwxmJKk/pjgr3NsStMd8OtTaHtLXoMjpqem+etyDtoqJ07JnpudXbtm3XFc7HiLVEHoaoqNp/tuVuZGPv4j8HXkFEmzxHLa/TPK4zKpO2c6hMLb/qrWXKyD0vSmXRV04HFUUvB+RmA6fTStvri8/FV6EHqajkv/oXdOPZdaE3CXx7+s1ZFN/nz+TFSevpr8r590qQaJ1d0enp5EUPlw9SFfwtNPy8bC2+mIw6390n077ve2cVVXL0FdfXO8q/JzDjBJCfxvwcObJs1HZ2Fd/IfOWEikpcHCLLvWfV6ngS0J/mYZBuBMIf5slEXT5HF925X6BKHaWi1BrotF1K06RzdP74wxyLDl1odQ4w3j3p/pa4OHKjOfibReRadwnJRiD9catM1NlVIpX0vHg+jFFRMCcInGOIaJaKgk0Ppor8tW7YXySCoC8OaD/jeb+IXNN4lGoEPSqdjrog9lwMk1TkhxK3Fo6IHqQi77Ig0uSMjrr4QquMQhEN2wC5UplsViNo9IN6uMF+BNdEbxVde+ToT4az3VREjIf0LbSKohX3ZwGV0AWxu5C+OEmbjKaJ6CyeWeS9IuKkQvJIwDnXV0VnSws2sM5G7DXrkuUug3stp7efMaQcfyS7fGS1F7edqUhvEy6F+DAcSWvUrMrO8pj3i253YV78zglHk5VFNI7GqK2W//YffmGYcmV2O6zX0fuOGdO5iQij7lLT+LX7kNwzvdupfTzPO8byawii7tXhQEVLg/+8MpCGM0QEUBEAUqAiAKRARQBIgYoAkAIVASAFKgJAClQEgBSoCAApUBEAUqAiAKRARQBIgYoAkAIVASAFKgJAClQEgJT/tO4d6LG70A0AAAAASUVORK5CYII=" alt="" /></p>

<p>于是可以用<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAALgAAAA4CAIAAADB4aVIAAADnklEQVR4nO2b27WEIAxFrcuCqIdqaIZivB8+RjAkERC5eM7nLDEh2UJ4zLRAkELT2w5A/0MABVIJoEAqARRIJYACqQRQIJUACqQSQIFUAiiQSnVA8XaerX/i4Q+qcXyU5spBcWaaJuNutwEshHKCWceqlI5CUPIz7u38Qki61pufj5iOIlCcKcp1YfPB9Ho0eAcKQCn/ADCqHOphMmbTkQ1KlSR7O78fnw7UyRfDpSMXFGcmNsXeztEDzkzTpVJbH3s/REp5O4tcZyS9UjAFn6LHqdAz6cgEZXWU9nPzajp15fRTFA/uRT1KRCWj1KgWTOULzlYjs2lXBFCcIVtdEU96aNziTPrR9JuCHiaUO2uVTHlsNcFi8ngwGa0ExC2diX5J+8KCkhzgdOPA1lz+AlsPKbtjmVaTNLDDTYtgpkUScOGEcYYBZZ1sDfUBKbMrzb03XlVRe8jz7dJlCItJm2BKzQMr3s43qE2C8gsGMdZqs6voXGtQjjGYKvDUIlDhZp1WwZQ8PlkhMckA5dyha1TufARdTT3BCKwpDtg3nZp6O7PFSZtgCv4GXtAGb4IScx/3ThVib60Tl79Ni9mLMbrEU+oUJLE4aRNM0d2ttbcmYe1eMUtNwVFv5a9gcybonLMXD1oOKJStIvv7bCMu6xoFU3R2WzelobyzPE5tGIW9S0yY+0M/Z47OkYvDhhtuqRiUoHKMenJxcjVaJZj6Bdw2WMyJOSd8/1UxKOclAan9LfRWBOH3HkzSfLMjDgaH2lVtbPTRYP5MKIsc9jEmHd84FBTKgKKqto5Kg+mMBhT+mWcOBTfT/+GagYKDTlDJjgZXd+xPaLb0HrlmsCy6U7J0y4aYKHc+X0UlO5giJuJg8vDFJZ0JQg1v/Olr1R7OJ+8Gk6k+j7pHpkSTjsEvV99Lfg+oVIvPUebKY0mby9Ud6/Z00kGp0qsGBiWr6ihaK4+sgUGBagqgQCoBFEglgAKpBFCW4EwmOH15fQuuIwGUVcTFo/StjS8KoKy6bl+Ck0BDghJuhgRbj8HJ/w8NcCJpSFCWJZxL9pPT5G41cRxy9wLZ6BoWlFPyvbUbJ4lBApzIGhqUdfg4cn65cLbfPsW8I2t4UPbhZEmnn/hjJTiJNS4o3s6zdUHKEzVKtDSW7298UUODwlxYjlY95z8RgRJKI4NikfF6Gg8UZ9Y/FmPvvaqGAwWX1J7RcKBAzwigQCoBFEglgAKpBFAglf4AeaeJ7dukhsoAAAAASUVORK5CYII=" alt="" />表示元素x的分辨函数，并用函数<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMUAAAAzCAIAAACokVujAAAD0klEQVR4nO2cy4GEIAxArYuCqIdqaMZiZg8qyycJgWEkYt5tXVHEZwiIs30UZRzb7AooS6E+KSNRn5SRqE/KSNQnZSTqkzIS9UkZifr0bHZnjNvlnE59ei7ebttm/YSz4k6pTw+Fvq2/ZXcGE1l9eiTeTohMnAqoTw9kZmy6QGKU+vQ4iN7m9moUVqtPP2N3phpFOtzwdsOj0+5M9l9vt60hbT8OkO5+bCuOAG5Wn35I1aiONOjwAyh0mrBF+kSbGN0jcID4lOU5oaqwfPIWvuqkBghT+3k4Jt8ImengNmENDgUgcIfN+o+3XZd+WJKX9LY8FlQXhk+NEVMQZ82nVh2VBg9eVIOj4ako3vscgcZCOoGVqfp09PBWwIiilatdJxsFp0i4TXSDM3yiM6w65Sl2Z7hyV3z6bwwJY9QWQtiGMsx7AYwioxbV4ByfvhQqz7Mxmzp8iq9JyDCVRxK0qznHLdWJzr87gydOdIOz41P/BafNhdvU7FP+hBQXKDUfLwSCc8w7idqSTpzIBuc8G7tzHhnhN9T1LL07W0v9ufk49Hg8o9ODnmFWP/FTri4OHXbxGrxyIacAiVDetd2ycAo4CyergvmE9W7yjcIafLpRIZpXEqeUosGh5Oja6V+AIFQ89cAc755xx+AdXXqKGNineGgEIjaPIqwRmZiftDQ4MKkGiHLZC0xMVhuB9+iBoWWt+fFKdjE/MR/Dt52Et1Wfqk/dC94HM3RZyajuQFtNixhHXn+9CrM7mz/UGwPnbTMIbRMnNL1iPR0/3Z6emI+idUYQm0UICRlLJnqV8SI+tTmyjFFjvkcIaTorMr3ge4TmPmyVNEoeC/jUlRHNnzxYkwV8UgShPikjUZ+UkahPykhk+TTka3zeQaI3ZldSHl7YMt6qdxR8BYJ8wleZNcNbig+ckFzv833B9RHjE2tuduzxyl2YVnQXXB8hPuVPfDzhiLxNT2eQyk4u2ZKsB7mWmdFWZP+O/lSdcGT4BHZ1uzPGeWL5clqueC0eOj04oQICWL6QMeyS7Mso+F5k+ATnO4xX6P/3dncuu8mXbHDwYFpRvupTnSgk+8TIgUJB4JZePhVrH8+NrD6r8Ek7OxLJPnlnaiO+s2AZnD6V+FSsAoL2gvo7VsH3IsMnKH/y1voj8wFtCQWN8/AdJfOn7IxQJwbn4/WCr0aGT+lditZ9ZWvvi287iB+8qI7v4q8Hm5zoLvgChPjEnYL8ZIk3Hro0cExBjE+s+fEw4vP2+GUCRMHOn6pRvkaQT59P9dOLC3J95c0/ya3ECPNJeTjqkzKSP/ZJ5Qn+bIksAAAAAElFTkSuQmCC" alt="" />表示整个信息系统的分辨函数，写出函数的主析取范式，则该范式中每一个极小合取项都是一个极小的保持区分能力的属性子集即属性归约。</p>

<p>这种方法同样可以处理优势关系，[7][9]详细论述了这种方法在不完备优势关系下的应用，并考虑了面对不一致信息表时通过使用差别矩阵计算近似分布归约的方法。</p>

<p>2.4度量方法</p>

<p>为了测量我们得出的规则的准确性等一系列属性，很多统计量被提出用于量化规则或决策表的精确程度与预测能力。在度量中，很多时候可以将数据中的概率分布近似类比于实际概率分布(如先验分布，条件分布等)，参照一些以有的不确定性度量工具(如贝叶斯和<a name="OLE_LINK33"></a><a name="OLE_LINK32"></a>信息熵理论)找出有效的度量方法。</p>

<p>2.4.1度量参数</p>

<p>对于规则<a name="OLE_LINK21" href="http://images.cnitblog.com/blog/52809/201304/26002605-6ab3bf1a8a5647b1bf3a1d83d678eb56.gif"><img style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image069[1]" src="http://images.cnitblog.com/blog/52809/201304/26002605-1298d5b9590448c6930643e315c01404.gif" alt="clip_image069[1]" width="48" height="21" border="0" /></a>，定义以下三测量分别表示规则的强度，确定度和覆盖度：</p>

<p><img src="data:image/png;base64,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" alt="" /></p>

<p>有可定义<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHgAAAAnCAIAAABL3hunAAACVElEQVRoge2Z2XXEIAxFqYuCqIdqaIZiyEfsGZanBXusnCR6nx7QchEge0JzmSj8dAD/RQ7aSA7aSA7aSA7aSA7aSA7aSA7aSA7aSA7aSA56VgiPMHkGdEkxV35IzTGV+55qTpKnzYkhhBtmSRcYdEmBlsCn5kgOqTm+V6DmGMT1kKQgMjgVJp7lvP5ac+whdBY7WKMfBehz/hwgB1ExYElZtCdKBo05b4NurR1MUcAlgcc60Ljeas4cl5K4GkUp30UtgiY4XwJN7kFquAJ0zbFfO9WZJUAjUuYXR/bJB0ZxRhO7axCanZiIQahAl9TZXI7W91HdbSb6zB3OtznSe0c1DZp1egU0ybmVBB9rQC+34WjpqMKSQkpnQRJxnByPxQJVjy4D5jZmLpwNpxdAoziPH/A+VnYdQw2PDkoKMZepP4NxvDbGaQPUL10pClFEJKfLxLF9Bma3OStAz6mXvHBOaY4EBPJO8LVWw5GEvW0J92Gy023QZJQkZxm0kHnNEa3tClqd8uru+tGhdLoNGhppHGcZNLlJXpkgl+tz1RaW3AlaiCidThTm124MGrW7TNMjgCYKds0ETRzmKa4kNG1LZEXzTvdBH11Mb0tqTGnQ42smNkJyRn3096LFyNj7fB+tcXoB9BEr2YlJLvixm0LQ4NtpF8wjb4a803HiQpk2eyO2T3+9W1DzKd8r50YRkTn/etDzmculfJtyI4goOP8B0K1136PplD/0PRp7159GiPIj8n9YjOSgjeSgjeSgjeSgjeSgjeSgjeSgjeSgjeSgjfQFjsN681s/254AAAAASUVORK5CYII=" alt="" />表示表达式<a href="http://images.cnitblog.com/blog/52809/201304/26002606-3a82c939a58a4578b5a0d5872d5345c0.gif"><img style="background-image: none; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; padding-top: 0px; border: 0px;" title="clip_image071[2]" src="http://images.cnitblog.com/blog/52809/201304/26002606-4e1a53e01a5348de9f03c72e628c6c97.gif" alt="clip_image071[2]" width="13" height="21" border="0" /></a>的对 U的覆盖强度，<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAK0AAAAhCAIAAAAkv7y3AAADCElEQVR4nO2a0ZXEIAhFrcuCrMdqbCbFsB+JE1RAxEx2zx7eZ8aRJ94oOhPA5QIIv23A9SfkHLgAnAPXKefABeAcuE45By4A58B1yjlwATgHf1YhvDo1TwcrKeZDbHHkNGnBfC2mYjS1GfqbYi2FEB4yrOqk56CkwGsyEUeObJMjxwsQ89iOHMMMslkPmtC31RdEW6qLwfjpkSOeEWQUzVxr38RB7bHPhDTHigYotzuMT13Mvq4I/SoGyxwAwDXlVB5KIh5bOaDfuyNnaQJKkt5VnNu9tW6LBE3odzEwccAujFxzEwdHjhg27TskzU6T2909TyZOlCL0yxhQllCFSBruJkjsS3jcBR2elISidDMYUZmAFid+5262s9q4sXVua2i1uANeO1435I0yQcwIYZUUufZiwwtjsXDAYgAlkY9tHAyFYtv39TaWFFKqLybjrE7YlY66Zgy28G6HTgXSJjiAIJS3qCmbEcYqoWvgIgkLYzFwQA3/+oB2ZT4vNCtAG7KkEHPpjnCks8+yUvu4c536LonUHTkywxVeiJmEsou0SoUWOVkey2CpvTYgDC9jYOKgz3HJAwYp9d0S1u5MflCq2e5s4STdqeNfoMc5EKyOLe9DD1VGrI9lmQN28CwGFg4mKWbAHjmQckvUB2Tq2BqAMmnfF9QYdFNPkbA+lmUOGEQFDCwczDzTlIzPpZW2tYXQ+qROdjH7WBC33Wo2hbE8HJ4YxtJaCv1dMs0BdagXC+BFDqR9rHpgip0udVLdRe0L534RU1HM8sPnBV2JSB8S+qfLY1nn4DrW4LCzg/QKB+11Jd0tiwF1f3AyFePYH8245sT2af3s/QFvFYXkjw9DIb0wFgMHQ5BpFPO9skXU7NDpYydDVfp96T5RuBSwhNH/JHZbGiAA5RTqQwh67vdG6tVQ33ppU7exGHChr25/B4N/yEG/c3O5ZYo1Rer2IGBC68MrtdbZf+QAAP3/YCUdmrZP/P9gI/yXO6MgeFX+fyQXgHPgOuUcuACcA9cp58AF4By4Tv0AkX5k5OtxXH8AAAAASUVORK5CYII=" alt="" />表示规则<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADYAAAAjCAIAAABQPG6iAAABCUlEQVRYhe3WyxGFIAwF0NSVgqgn1dBMivEtBAQNHyWjvJncpQqeBGSEbfnA14B+jKgRI2rEiBoxokYAYHVlj8iESPyWRkyHuICwQ1xB2CZOCBWLqxCZEFKcfzIzE9aGegcAkErIy9lvFeMEIhMCEseRTDiDBLGZ3h0OJozz55frRO/CQ7G2KH6U0JTzeFnIhFJFJ+LhSd1P5iLFThhKNkduOYRiCy/EYeFohK0VropCcbVKou4q752urEDqxH6/Cqx1cfpL2ZrVpY89CBu+CzFWiCju8nvA5uiwA0ZONelc9G5i991Idtq0IpzbiwkF4lvC4fd8tsrj71n9f3Yzok6MqBEjauQPiD+gq7yFg2wZ+gAAAABJRU5ErkJggg==" alt="" />对U的覆盖强度。</p>

<p>可以看出<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYoAAAAmCAIAAABVtUtmAAAFUklEQVR4nO2c0ZmsIAyFqcuCqMdqbMZiuA+rEiABAriTuXv+p/0chCSGA8TZcQEAAEziPm0AAADwQJ4AAEaBPAEAjAJ5AgAYBfIEADAK5AkAYBTIEwDAKJAnAIBRIE8AAKNAnsAIziFzwOusS7LDb/tZb3Lumz+WDaijw7xhFvl17v41E0eo2eOcW2StNa9vviBh3ufTQYjydHgn0+jn3Dexyblv0cVz39x7DmcuPAN1mzfMEr86JuoaazsR7XHOCZ+e+8Y+geTZpB5YlKcvSZh3+WwQrlxJrh0+T566lR0NCkea/Q2SiPHPNNn2U23ezPiTfrUn6q+q04g8hRAuJeJCcXjmsjl5+p6EeREjQUjkiVezc99rQTx8bRngHHnnuQgh05s3Y8GUX82J+rvqNCpP4prI32FNnr4oYd7DShBc1tDRHUhH3jQiPKQZwxw+PzqMmTdjwER/rYD/sjoJ9tw7bsnaLIta3RmTp69KmLewEwSXNotWFSWjWIIim3f59JhUIXJfXzt5XxWOu+9B84oOaRXr+fsai94855c8UXutDcIBihrc68ugPInqFA7PXl4qTzFQZUWBhG91Pt9oI7xyIhAD0x6Zqh91Jjp+tzAUBCJPRW087eXSuMM772+5E3LxHu+yjBFjrsg1w217zL3nrxHziq6vz0l9iy+wcH5V3jn0FIlV1l5Pp5o5vb6MyZP4ZAV1WidPdO9M5wTNAjITluZzakR3hJdNBNJNTP+QzfyfRCSfFGurP4KtIDihTbGBO7zb9iN7F8j2+2zC7j4YdZTXWD1loO7eh83LmpehPveNjeiUX9xEVVnbyhydL5w9Lr5L4WVFrU6L5CkNPDkHJEcCYt3afKZtFRFeNBEyg6IXifMhVfB86Oc7BJaC4KQmx16ok/d5IjGeRLMfhcuDVDVIC9N5TZ76zMu6iusSyXmhvrJUnlTWkhWFrw4ofRmRJ9F/UZ3WyJOkijFaZ3yXe32wMp9JY02EF00EyaBy4PRKuueimxwrQXDNFsWQmbflIb/DkYpBqq8js/08Ngybx3qYhrp/HRg/3GmszRSJEyilLyPyJE+UygJQO0L2UVMntlSxOp/L+7siLE6Ehe5X5CmOTr9+aSYIIcpT/Qws3V9e79wEVodTPBtOk7MVc8S81MHnycRKqnTLVCmhmKgKa8uKeHFF60thT/pcRHkq+6tukOpfX+iifM7nyZeSri/JLM9ncrsmwtWyS/8s4OpI+8Fdz1Xlsninq4epIORdivdLa3b5Jr9dQKuLws9qJ9lSdJSVzGjHavOS6uEzgD+eULdlfLzQKe6eWjUlRpy4qzpfhuSJnxHVkNTkqTcNipoKLRM/o8f4LcrnyWzhxhty/9kmFpuWdH5woyWhsxeEk74rlJfm2rGRW6S3rdJfM2XVGyjJfqV5dzCS68kA9TJB068qzETtCaYgTqw9Cl/G5KkYRD0KRbmBYnKApjctPK3I59lsCa2EUR3xyMBiBIRyKVcdsRGE+X8J5jqXJ0wInPcvojeveC0Q2GdYMuuX/Kp+abS6fCnsKabKqi8E2Ppa5kDCDGZL+OWJoMJKEFb8YgG3Rlcsm9ti6FGaF5h/4ukK9bRf4qv6z6jTH5UnZcKMZgs3jiVsBGHND6qkp8eaIx95JCrz+EJ+K9Qr/JKKzUvVSdHfX5Wn7oQZzpZgXJtCCDaC8MLvPcmW9S/c6+kwT761cceLfn1QnQiqIsh/wmjC9DT/5ERQ8ekg/L20AwB8CZAnAIBRIE8AAKNAngAARoE8AQCMAnkCABgF8gQAMArkCQBgFMgTAMAokCcAgFH+AWBk33rWqkMOAAAAAElFTkSuQmCC" alt="" />可以很好的类比于一些先验和后验概率分布，并与这些先验/后验概率分布函数有着类似的属性。基于这种思想，文章<a href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAeCAIAAACqmwlGAAAAfUlEQVQ4je2SyRXAIAgFf10WRD1WQzMUEw8YgkpicvC9HPTkMiOL4vg4sIUtLBCYACBl0aXkZHM9AnEXgUl3K19nzTbmvOTk4nrBn1y8vyWoIeTt+lZwAYzv8SAlYuNHui/a2oezieMIHs7185XwzI8CU5zKnTDj//691wgFBK4w0rbwGEAAAAAASUVORK5CYII=">23</a>中提出了很多其他的测量函数。</p>

<p>2.4.2贝叶斯方法与不确定度量</p>

<p>基于贝叶斯思想，我们可以得出<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAATQAAABBCAIAAADQe88OAAAFsElEQVR4nO2c25msIBCEjcuAiIdoSMZgeh+8NdAgjoCNW//T+c6OCFVbzWV0JwIAqGR6uwMAABmEEwClIJwAKAXhBEApCCcASkE4AVAKwgmAUhBOAJSCcAKgFIQTAKUgnAAoBeEEQCkIJwBKQTgBUArCCYBSEE4AlIJwAqAUhBMApSCcACgF4QRAKQgnAEoZPpzOTLeY7fJ2l0Ep/9zcBuF05lKjxc7G1brfYufNm4s2Fzu/6F+BLL9RVUyf3laKzb9tbjPj6Eo9IZzZclUgUeoji53PUS52rijl0eWrJlsKnaFYlt+bF9sY0MqY5uYGKvFGGhtHefUSM6czsRa5jhZ8IBrLZXt3KK2wznYP501Zat9kOCvl3rQy15u71hvtY+tiXO4+cjjlOC/W5rRxJlfbpLHU9bS4wvblviy/kRBzSCvFHrUxN21AL+NIVm+aJjGci515kVqsue7GhTuJseQFuEvxBqUfv8nyG5KYo1op96qNuc4Ioe9pHCXUE8PpDFMg2l+c+jhz/DO9dD5FFXQ9Lsvtju6YUbnCnp2P13Gsd7Vl8UdzNMCt2AbKr5Ru9oKV7Wg2fW4Ns2a7Gpe6nxTOKCh+Q1vInZmM2fMeFOjwllvnhGok7YieUa3C8oLK1eVjZZpWlcXvxHmz/WP8v/0P+2K+bWWm5v7keuXpc+/eWWCZrx2NI1m9xGmtV2Ajv2frgiNgMWNH1d7bEMpDQoVnVKiwfr/Y/ONNRWzYdWXxRhJZnPraIBJzfCtjak2fcbLYADobR4J60yTsOcNPBUdgzkyzMeHORRjM2fPjl8L7xfbvVmtZy5t94GBqQj9H4B/s1ZaFD+OcvFl9EC8IrXvHyuY8NZdI1jwfzpbGkaxeFM4LiRPZjwdTOJZ2jj45P8xlUywZtWWJr/ctLqq+Cqysvazl93rwWyMqw+fBzsYluhSFM78JTPkd/3/hGqD+nvPoUK01LRHRssjbse0rieqysMuP34jMgos1zn72EStjHplLJE9h4dFZT+MSPw7CmVkUxyMIL/SuK9s7Nzric+bZbOwdrrM++vKcY6okyzrPSOvSzeLruAWnseNbGfPUXIr2JELfuxon9oB4OM+DsPSiIzORJ/bX8zznFjEtvhx7XFe3RkQpuEp8w1lDlr1t7z+9hWH+l9J5B65fsFLsW527eLomDtd6GUd3vuf8Dan9fJV7uHNI9aLHoUQ5t2WJH0JbSh4urymmDitjuprbyzhKqlf1rZRoOHkx69faanW1KrdkER6sK7K4spivWxnT39wuxkn32aj8ypi/dM6NpYGdZXX1hUffS2WRdyYFw2q0O3jPSvEmL5jb2jjKqtfyfc5050pLyg0K62qDOxdSIEviuouPNxzSO1aKN3nP3GbG0VWPh/9LCCtlui38CS0wCv/W3C+E0z+cvELhphSk+c/mDh/Oe+Z9rbZ+nH9u7vDhBOCrIJwAKAXhBEApnwzn/uTUbBdn9m2IcGq9WOvopT/IB36nyN/9oYCB/f1eONlDo+e7BeIXZad9Hzvl+zSF/rIHdob1d4xwHg9qbH+gynsWkR3pGSc/pRhXz/WlIWOC93rAK6T99cyl1FOogb++uTSsv2OEc1d39c4rk4Ev4hQZZtOZyThnjKN9VaTucfl/RsLfuKhe+xubS6P6O0Y4j5forAvKoP9NWGLm9D1er9/si15XBy+Q8Dc0lxIzpwvnSN9cGtXfMcK5Fr7Vu2gJc/FG+2wXv246sx8knNeOWVk/Q8rfyFy68lcyl0b1d4xwRlsPDnurNdqniMsjZ1Y8jwf07kMk/Y3MpQt/Y3NpWH8HCSeJ78vduXgO4+lc4ofgFar565tLA/s7TDgfebc2wP6yb7jKfdQyqEA1f8Ol8MD+DhNOAP4bCCcASkE4AVAKwgmAUhBOAJSCcAKgFIQTAKUgnAAoBeEEQCkIJwBK+QPmlMkXGr9UlwAAAABJRU5ErkJggg==" alt="" />等多种公式，这些公式和度量函数可以很好的描述信息表即导出规则的各种属性。<a href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABcAAAAfCAIAAACDG8GaAAAAlUlEQVRIie3SwQ3EIAwEwK2LglwP1bgZinEedyQo8dpwukce+AcSw7IC9o/BVrYyTKsFfUR/UVotQKnNzMxUXAdACLVaTqKTjpIHyZFEUcGIqIyrWaUjKrzYVLklMRUGBcodoa1EygNxdlLFR0gzTPkUejE8R6B8D10/nwtm7O/GN09mCRqYV5YRR1l9DcuyPlt5v3IAOP7MKTnaHTcAAAAASUVORK5CYII=">5</a></p>

<p>另一种不确定测量方式是以信息熵理论为基础的，通过将这些参数类比于信息熵理论中的概率分布，引入了类似于信息熵，互信息熵计算的各种公式，用以完成对规则和整个信息系统的的度量。<a href="data:image/png;base64,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">10</a></p>

<p>2.4.3度量的改进</p>

<p>为了测量整个信息系统的有效性，还有一些由规则度量参数组合出的整表度量参数，但是这些参数往往有着一定的局限性，在一定的条件下会退化为常数0，故而不能很好的地起到测量的作用。</p>

<p>针对这一问题<a href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACwAAAAbCAIAAACImfpDAAAA30lEQVRIie3UwRGEIAwF0NRFQb8eqkkzFPM9LFmEoKOu4h7IkYHwQgDhH4S8DSAnosREWEyExVhEikEsoC8gUgwiISaSpGLNGIVIMXwFJhqN2DW0CIW1LC+pDvFyKKokijql9GemGATain81WIltRkO47RQBuIXQngMVTVrZGM+v6QaCM/iCZcNQvyFbesXkDH5ELH81qpDudfw09RSlb6hTiJuZ+wBASSqaLbd8O4b1fG9iuZjlbeY5+Yf1VZ96MXnP8l13+c9+Vt26ByN898cjjhoeRBxsxbOIEzERFgtAyO1vipj9nAAAAABJRU5ErkJggg==">11</a>中提出了三种新的整表测量函数：certainty, consistency and support分别测量决策信息表的确定性，一致性和支撑度。按照文中的理论，这些参数同以前的参数一样很好的起到了测量的作用并避免了函数退化的后果。</p>

<p>三、结论</p>

<p>粗糙集作为一种模型有着非常广泛的用途，本文以决策粗糙集为入手点，详细讨论了粗糙集在的一些模型，算法，规则度量等问题，这些问题在现实中都有较多的使用，因而也有较高的实际意义。另一方面，粗糙集模型本身还有很多具有理论意义的属性如粗糙函数，粗糙拓扑等等。通过这些理论研究，可以帮助我们更好的理解粗糙集模型，进而更好地找到粗糙集的实际意义。决策粗糙集的核心在于目标决策类的确定、子集上下近似的求解以及属性的规约，前两者决定了规则的实用意义与价值，后者的简化能力则是使其成为一种具有实际应用价值的模型的关键所在，最后还有一些测量方法可以帮助我们更好的构建这三者，以达到更好的辅助我们进行决策。</p>

<p>参考文献：</p>

<p><a href="data:image/png;base64,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">1</a>Yao, Y. (1997). &#8220;A review of rough set models.&#8221;</p>

<p><a href="data:image/png;base64,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">2</a>Beynon, M. J. and M. J. Peel (2001). &#8220;Variable precision rough set theory and data discretisation: an application to corporate failure prediction.&#8221; <span style="text-decoration: underline;">Omega-International Journal of Management Science</span> <strong>29</strong>(6): 561-576.</p>

<p>[3<a name="OLE_LINK28"></a>]Yao, Y. (2003). &#8220;Probabilistic approaches to rough sets.&#8221; <span style="text-decoration: underline;">Expert Systems</span> <strong>20</strong>(5): 287-297.</p>

<p><a href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHEAAAAaCAIAAAAPLyQeAAACbUlEQVRoge1Y27XEIAi0LguiHqqhGYvJ/VCjvLLGNZu9ezJ/+xBhGEAN24PVCHc78IN4OF2Ph9P1+FecEkRM7xhIGIFWeeNCcZowhhBCCNz9/etjKI8J5M8JYYaYhFFbnzMzmxgeS2eGgNl0dEpgENQvJZCsS8slC8wIgUrWEBYROm/McjxhDAGIQFqzOSWIMRpS3RcXe9JZpN2Aqdpt0x4MQGTrbZxk1d8+oWJpczhNiKSUyHoRQceYrOasUNuNjvdRLBVpwYksuSooNhJGYcritHAk6r8fEIxSOTlmC9yB1wFFd3M7+rFRx0ozZc9Flmc5+SxOCbMVVuCSUjeOCyjVRJUwCPIvWiuvYMwDb3tr7koVsc8Gp9VRtnNf3yxMuWkufOGHSMKZSraCrzHMU+qkyvyfCs8g+QWnrDvW+j+YT1XV/QrT2zkBG5ymVMsobzMz92oQp2rf6cJyf+N8ygbOfmDg88mnxtRpXTY38+3d9mCnjhKjOm2p87bRylWc9uztm4sDrhVky4Wtx/Eghta1CK1Y+Q3FK5rRmnFlsolpXSA4dVpy2948kckvc0FFQ+9DMSiXrNN2bBksA1z2vdgmrZnhM4cpNMJ2qQ7iL0Gx0SR41HuMC4C8zGqOx6aWKC6RwGpIVddhGxw+n/ZVIEPynL7pDSURJQKgsTvA6XsUPwio7nDFLaLDbe9SucvI7u3hHKuKUnUpWXrVlbhLpzlqAqCqVDUM1YpRJnpK1Sy6mtDtJk5r0Lw1Zs0eKXfk/dR9kCsb3/F+ehsSIn0m5qvxNZwmRDDOev8RX8JpbXsf6HbX40s4/Sk8nK7HH1sU7gL5/NBzAAAAAElFTkSuQmCC">4</a>苗夺谦,李道国(2008) 《粗糙集理论、算法与应用》</p>

<p><a href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABcAAAAfCAIAAACDG8GaAAAAlUlEQVRIie3SwQ3EIAwEwK2LglwP1bgZinEedyQo8dpwukce+AcSw7IC9o/BVrYyTKsFfUR/UVotQKnNzMxUXAdACLVaTqKTjpIHyZFEUcGIqIyrWaUjKrzYVLklMRUGBcodoa1EygNxdlLFR0gzTPkUejE8R6B8D10/nwtm7O/GN09mCRqYV5YRR1l9DcuyPlt5v3IAOP7MKTnaHTcAAAAASUVORK5CYII=">5</a>Slowinski, R. and D. Vanderpooten (2000). &#8220;A generalized definition of rough approximations based on similarity.&#8221; <span style="text-decoration: underline;">Ieee Transactions on Knowledge and Data Engineering</span> <strong>12</strong>(2): 331-336.</p>

<p><a href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAOAAAAAhCAIAAABP+zCnAAADOklEQVR4nO1aybXDIAx0XRREPVTD6XdCMfkH44RFG2ADydPcEiyYkcYYsI+XQrExjtUEFAoKalDF1lCDKraGGlSxNdSgiq2hBlVsDTWoYmuoQRVbQw2q2Bpq0Inw9khg/Wo+34ABg3prXOgNDs5mwcGZd+X4btNKk3UOzvT6oGQ4huBMIczbSupDSchGoETVrZPKRIxYGjS/ydHegzPln1lkbMMZgspbvSQJCs4IUgkG0gZt0estzLP4/7EkJBcTooDGaWVCR4RmUG+z/J5ZL/IIj1dExn8gf8xUjvOlo/gZVKaXGt/bpGmtQaG2LQ1a95fXwVt8SspjiQfsXOU9FhU94kV6MxNSjUsNCjZtadB6EkgNytT6QyY4QzxaZyun7iqsc8kaVKCXTsQuBoVbdjRo5c9zYZz4k6z0aWZHFgXgAYu41nTJ4Cm5BuXtS1HhJonXO2RQJgNwEA5UFNIgKNPDDCuDFv6M27are8FYwO5UwIPoODIC6tyiHFocwjvCuEX9E+7iWb3jMyieASII4QKLkv4/n2Fp0PM4xJi0VMXZCDc1VneQhAcl4vTRoPLmh5NwBuX13vCIRzNABcFcRBMl2jCf4VE2030xBg3OGOerIz8BD3Jg7JRmuUFFeu9Yg2IZIIPAiyUrTbxlPsPCoNwMSbW/C1EfSvM8WINCjaMGHXvES/XeZVBE6bhBG7b28xnmBmWf4OhYWRUEjJrWoNbBW5zRNSgJ7qWLWO8da1AsA+zg1cX8WSfVNp/hkbVJZr6aRl17vqeGxY31n2HPX2BQ8hYO8fJdu/hGvaMGpTJQBtFJAEU1vVyaz/Cowvglf5HRIkjWFa88Pz8oThPAoMsJ0MH4PeegXXq7DSrIABiEJgES1fZ2fj7Djo9F2msN4IkT4HjrAvyYtwsiht2Ye1CPJ+G8uE3U3DJBI3Z9zXSDRR9Qfm15ampdfO/9mkk45INJiBcvN2gjw87P7dqXdAyPceXeHtYDs1Xv3fSVBsWS8Ll4tUFbGa76HrQEtLqjhv6s+qLy+KgspIf+70EX4KEkfDXDn/ii/kqbceElfJP1e9g/CV0Mf8Kgit+FGlSxNdSgiq2hBlVsjX9sY9kgdo3PogAAAABJRU5ErkJggg==">6</a>Greco, S., B. Matarazzo, et al. (2002). &#8220;Rough sets methodology for sorting problems in presence of multiple attributes and criteria.&#8221; <span style="text-decoration: underline;">European Journal of Operational Research</span> <strong>138</strong>(2): 247-259.</p>

<p><a href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFMAAAAkCAIAAAB695EuAAAB00lEQVRoge2Y27UDIQhFrYuCrIdqbMZicj/moSAPzc3ErKXnL6MjbFBkEl6rKsx2YJo2+Xra5Otpk6+nTb6efp48RcA8+lJGiMmZY5GnGAQpS9LJzaQyfIAk7ODJCII5Yukcrp/FdL5qh8zLeYqE47DAvOEPM8JNeE+4fx6jWgCLZGzZLW7DX8AlzwiChYZSTvH1NMXWJxe8eclyTFnQZA8heBueOsCZ+Hjl2DXQLJIxOnvdyderRs8IaoyM+Nnkgs/ADpe8MCE/j8NApfJP6ZUCNLDthUxyBk5PaHOamUE6dpYgd5OX13vOgx/OdtNessiPxAGUstmEoRe8PO1Jve6ua0ScJQbRILcjb0RcvAAGvO0gzwiAiRwpdeI4uW0/a2YJXUYUbkBvIzvkd0lTfWDeDJJ7gZeTTvPdll1h1bsLoVe+Eh6ypF8Qxs95bzh5wyLVNdYIEU/LTVy3qUpJlrsVZ3uotV0jEoqaINqz8rkpxsQmNe0fYBbqAr/Pa58uKz1+Wve5gfW8Sp6bLszp4bqk90NOA/e4qg0u9J//ZrcXmElOMq5dE+/Cu3GbSJ4ixAheMZnyff6s3kL6oGaRWx9Y39HP/xv1mDb5etrk62mTr6c/nE5I7YZQGGoAAAAASUVORK5CYII=">7</a>Yang, X. B., J. Y. Yang, et al. (2008). &#8220;Dominance-based rough set approach and knowledge reductions in incomplete ordered information system.&#8221; <span style="text-decoration: underline;">Information Sciences</span> <strong>178</strong>(4): 1219-1234.</p>

<p><a href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFEAAAAcCAIAAACWK8TTAAAB30lEQVRYhe1YUZbDIAjMuTgQ5+E0XsbDdD+SGIEBTXc36Xspf7U4zAgi7fJ6ni13E7jBvpqfYV/Nn2aFSerZTVWIS+YANBdevB0oVWhd0nTa8uoMQZYzCqrQ4rkr3O3rfo3LtjUJFeS5cE9wBVUECtuVdbELVYW0yo1bnoRjb+jnY2u6IwCs2R7UmsQOozARgTh9GE8EAIWqspKoQh1IUMuxaqy5sCZmT7aKFKfJxNbENFRe42mSDXYVCsGik4OatWRf2VVYqjsJ3XACyROZHtzGgxNLIjgBQppN/wG5khVJ6TI9FlV225Npjg4LcJw5GeADNOvjgf2rfTxQt9wPwk2QDXdajmO34Pi8ZudoWSp1e32D/gWTNc7PWHMVIin2VcCOc5pt/7KZNgndcLvcx8Gm2vZAc2ta7imEvlOaR5JfWl0bRlz/8nRQjlvvaOvZfVZdenzx5+6zYbsPV2oKc2EsNNCGx5EDrG+AQbvFc8egJAZ9ux8eYdvuHAzSUe545AyucGGSCnqkfZ97ZjuOZouFn3qfr7Ejt654BnPYlJ2dw66wrpzBhfm16gTgNs0qy9Hw8q7s/MTu0lyYmCm5jLvXNb+fr7C3xPyV3aI5+zF0gX32f0P/Y1/Nz7Anav4BBdfEmcOg3+gAAAAASUVORK5CYII=">8</a>Yao, Y. Y. and Y. Zhao (2008). &#8220;Attribute reduction in decision-theoretic rough set models.&#8221; <span style="text-decoration: underline;">Information Sciences</span> <strong>178</strong>(17): 3356-3373.</p>

<p><a href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFAAAAAcCAIAAAB56a/tAAAB60lEQVRYhe2Y2ZnEIAiAqYuCqIdqaMZi3IdEBcUjuxN3vpnwOJHj54oZiF8m8N8B7JYH+NPlAf50eUtgIeRwSSMwkiydTMCBEQAAwLrKP4+lcSZUPw5MSxCBsTZnjJ3P9G8kp95KmmyFhZzohYoloTol5nHMKTJGhJpM+uLQdiNrQ+lrKzHAQojomMlWAmObkMAs2YBb7xiF5qE0uau8aNedFl5A1sCBWZrEGdNCxik57e9HrJLSlUm0hTgwdvMyylmM0QCfAFXz6AVieOvNsty3HZkO4REYD2hXrChg4eOgaZ6at7uqXsE7acclF86WMQLqJOlRPJR025qQ6iE6+nm0Xic4s0DHI1OdGniCclBNZGrrwcJK/aA1XEeLpZ8AB0Zk4Walegf7wABQ3sNmA51qquqTiNwKJ7XFDd01n7dUmBP3gQ/YBKzRCgDYAXZclUT5lez4z82eFbqBmp08n/R+4jSw91ozmm5q6x8PCnQ6pUHI9yXLUnvwLxeT1h88BgBQl8fqYCpevZyHi6i9izbuhZCDM/PmPaztJAvWto915T28SUpVm76aRjuTizetLaK62BmkvyGvaO8GNvX1olv96nEs/+Jr6XYRQiIczGA6dfv38B65TvJy2Qk8+srZJm/5F8+d8gB/uvwAaPuG9PA2Px0AAAAASUVORK5CYII=">9</a>Shao, M. W. and W. X. Zhang (2005). &#8220;Dominance relation and rules in an incomplete ordered information system.&#8221; <span style="text-decoration: underline;">International Journal of Intelligent Systems</span> <strong>20</strong>(1): 13-27.</p>

<p><a href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAkQAAABjCAIAAAD1tIiqAAAMrUlEQVR4nO2d2aGjMAxFUxcFUceUQDU0QzGZj4TFtmTLICDmnfM3L2BbQtL1QjKvNwAAQOO87h4AAADAURAzAABoHsQMAACaBzEDAIDmQcwAAKB5EDMAAGgexAwAAJoHMQMAgOZBzAAAoHkQMwAAaB7EDAAAmgcxAwCA5kHMAACgeRAzAABoHsQMAACa56+K2dh3w1R70zR0/eg9jtfrZW10Gvr6QScd7jA8M4Bp6F4zhZbHfrmyaPIJrs6N6qK+7uLPRvvP4pqGFTn4rkjD63Lw7ZOGN4jZ1plFt4YXJxetH38e4jgYQmQaOqG7oKfvx8lzn4bOEC5GpqGre35qehtdKhhusjo3gGojrHe4ujrsPLHtFEETH8rayTKSTi1M/ag82Rq/PC3afZ+VHA87uSsN63PQeNM5Ofg+Kw1vWplFw/48N/EBx9m/8e3Yb/75dU/RFXJuy8OK+yg3UMGOCMzOVUsu1cdtsVodwGlipg559wOYhm41S3DXCWkbNiuEuZi/Y78dSzDstRmTD54V7WsJdBGzXDzs5o40PE3MsuPdy3lpeI+YpY6MjPqErbwQm/8apvzbtixObsoNTGnQ5/nuyJ6cmJVcmjPcZLUygDPFTHe1OPspNxVLRBRw7psq8cw2Ceux77pOEJDtSKQEV/Ij5onR7vWk8vFwpNXL0/BMMfOWszPT8B4xS/MzliltShKJenBReZO9/FxWb05Dp4ZdoUiYSCbcllt0A/MuLRhus/oGMcu7+iNpNh8aksh/ZTb2oaVxSZ+GYUyeXFTFFHepORLe+bxod1SdvVqWcdYtaXiumFUGQGnoJ6bhLWImyNBmoplJ09DYmlq23F66/BN7Q/aJ+Owlx5Vt3iPfBL5drfMuLY7XZLVVzAqG1KVe2dWCo1Ii/8Tpec7CLNSydDX5dWey1ZIs5oSRlddmD412n0dViIfcbblYuycNZZf4paExAAz1+Nw0vEPMIovC065caUo/qzg+sLrKMOWVt37k49+X+oDjafu2YXl6o4tZ1qUWw01W16zMdEMqI9a4jZ6f1M2NRAkeXuAtZlFACKur7+tKgUei99z0c5OCmD012l3ErBgP4h3F625Kw0zDPmlYykHrrv/JaXiDmH3KTteJ0V+nZetfrTMHQ6AY5vkOGaXNBXPTG1XMsi61GG6zumqbUTWk0nfFy6OSIRE7QMoZdzkL57Piyx/bo5TvtZGL1UdXLHtPjXYPMbPEQzRG6+nSHWmYc4lLGurXVh1en52G14tZ3omZHNX9ZowBUzB1w2jYuD2WUcXcUT7UxKw0moLhZqvrzsw0Q/zEzPjclc0fZTnpJWhJH3FoB86cd+Gm9OUPfapQs6Mjj7DBaJcGU7lMrIqHuh3xW9Iw27FHGorXVr/Tc3oaXi9m+Ueq7hYFhWsaBiGaS/ZbgmnKjSEazaGMUh9YxhRNzCy7ANrnNVbXi5l62nNQzKqOS+VDeWmF77kySx5wNBmLfPk1c7Nae+uuKh+YPTfaXZaJhngI+jP1eFsaFsXsaBqq19qdc0UaXi5mpu3X5IKwEKQ7wEKrS7Ytf889vqDJ8nM2HuRkUU4R+kE9bs18jTQ7mFwsVp0IV52ZaYYEd3yzISNN4nzu0IRQ8rz7JmNJy96hbInb5Uphk1Lk70T7YTEzxYN418F93dPSMHtm5pGGtjOzfIhckIYXi5l1Ghi98hJ5Kq0L8exg3a3Znqcrb+Wkbi4N0/h6Tx5hyvQpcHPrcbmT09s2lUvHW291hZjlDInumDN57NW53yFXx+EjJqbLWwVxe1GBekVWa69DhCNP8z+dCf+haD/+qEzxYL05GtZNaZg5t3ZJQ2MAZCXtijS8Tsw24m9Scf3a70PZXpQIfDdMwhlbPKnfjmnuxTJO7Ty7hiBmw+W6tnjP/SZb3qWB4XuttoiZwZDojvVpir2mfw+HGqDX7vUmsRdLKTKiDU9yf2LZ7F51E0+eN/+JaH9Hbtk3Jls8FI1JFtCmYZ2UhqkG+KZhVQCk22bfJs5Pw0f+0PA6P00mwF6JeXwWX31+qs5Vrd0dL9YnfGl6rk/aVtNBV1vn3d5Lswsh2ivH4TNp2d2/fxruCl5zGnoEwDVp+EQx2+y1CLs5h8PJJR53Pbdj6e0wbn8xG/tXP8qTubfPs7INzmUr7RaI9grcj0Z3DcE7DY+LWSYNPQLgojR8oJgFM1Vte3uvx5xyexlHVWtH0/twxXYXs+8OvfigHFxtTaK75+sHINor+AEte5+QhofFTE1DnwC4Kg2fJ2Zj3/V9V9q+bvJ/ePLp0LdqSzv/atfBCdJ8ZzdM7+StHw9X23Lj8ifgCtFe1/uvTFlc07AiB98VaegUANel4ePEzLtYA/wuRDvAzMPETD19AXgcRDvAysPEDAAA/iKIGQAANA9iBgAAzYOYAQBA8yBmAADQPIgZAAA0D2IGAADNg5gBAEDzIGYAANA8iBkAADQPYgYAAM2DmAEAQPMgZgAA0DyIGQAANA9iBgAAzYOYAQBA8yBmAADQPIgZAAA0D2IGAADNg5gBAEDzIGYAANA8iBkAADQPYgYAAM2DmAEAQPMgZgAA0DyIGQAANA9iBgAAzYOYwW8z9t0wVd0xDV0/eg/i9XpZG52GvnLEUoe1VucHMA3da6bQ8tgvVxZNPsHV51D1AKFNEDNIWCpfWPa2BTFDUjK21fHzsbXcT0MXNxc09v0sKb/T0JVKtp1p6OrqYM660BeyywSr4zs1w9UBVBthvcPJ1b5is43UtVEE7eEgZqAg5v7Yr6Vr7JNZ/vbj91JUgkbGvrw4WG6WS086snQo+t111KtAUaqj4X8Uaf53dtwWw+UBnCZmpSFLV2tzJBehmYZudYngardJDvwaiBnIjH3XdYJELKVBrHbTMIxLA0qBGntL2Yp0Mepl27Wy1+UjZzum8wUxS/226SNndXKvtsl3sZhZXf1RLdm8HXMGtY9ND1GzXr3AT4KYgcg0DGMykw2q59gHdbUXptta4RpMhS9TddaqlEz0NxSUwUQw0bfekhWzdHmwiFlZFEyGXy5mJVd/5jV2ld6NQctYmT0WxAwkvvUw2aZZS0GgZfH7Cua9RLX7wknMZ2BDRsksrViIl2bzOdX3T4Jq58Us0bJPC7OWlcZrMdwmZgVD6uRFGbq0z6zef1zMIt/GCmvv5N+/fweHAteDmIHEOHyqQJD/sZap7zB4aFmh6pi6kM5I5FcwXurSIRDtqGF5dZQVs2hI22pvq7UGwytWZrohlfIia7Q5BlzEbB5DJNPhBYjZY0HMQGDsN4uuuSZta2RQfOKzm3WtETSZeYEv6b5cr/VtzOiqQyVS2z7LbZzlxOxT4rtOUlDT6wkWw2u2GVVDKn0nX37pyiz2nyRdGTnbChhi1iKIGaQE1XDeZ8u8/DGv47Z36KWzPF0vlPVp6LphNMz8j5XI7Dw+82FGzLIDMkm4xfCqMzPNEBcx2/SRb0y6vXINLa8NldVo/Od///4hZq2DmEFCVAy/RWGzWivUXXFlNt9mfJNRbX7ZETPsYx0vkapmZUzJiFnWbxYJNxleLWbSJ55itunptLcZ5fdqpM3TpJt/CQfGAbeBmEHCVrbe72WzqLghthZReQWmVKxFXpYb1NIWnO2UC6DH94qUM7N+UN/W0MXMMAdQV3sVhledmWmGxBvJ2YPFCldr54wHxUzWMmEiI3eChj0AxAwipG8vBaVCXBnEfxSm4coX0+betq+XSC/HyV+MLqxl/N9mfM9iP7ceS78qZoYVlTjeasPNYpYzJH2tvfu+36ptSh5x9VExi8NN+TJ5rhPErHUQM1jRJ+Bzfcxs0olCVdrIG/tumIQjlWA7aNvO3ELYtlxH3b9nFr7PoL3dUPhpxIwMxZtgOw0vi5nBkPhY9KN0mRdikohRf/ws/dkYg2+yrC9l5v3C98yeDGIGN7KuxpL14GElKn8D2YL/L4CUujtebU/40vQsOPqJ150/rGHd43T6ajb8JogZ3MdmZ1HY3DxW2F1kYVf9O/ar+Q7j9hezsX/1o/qbI06u3o3562Mu+87wqyBmcBvBukwqMruLj2d5rd6cOvpfwBwuue5i9j0oE5/S3Upm1zJ+ZvjhIGZwF2Pf9X1XOilp7/8z8+nQt+xKp29q18Ep6HxnN0zpN7ZPcHUtNom6/AHC9SBmcBPe9RoA/jKIGdyCegADALADxAwAAJoHMQMAgOZBzAAAoHkQMwAAaB7EDAAAmgcxAwCA5kHMAACgeRAzAABoHsQMAACaBzEDAIDmQcwAAKB5EDMAAGgexAwAAJoHMQMAgOZBzAAAoHkQMwAAaB7EDAAAmgcxAwCA5vkPMjGf4zVPTZ0AAAAASUVORK5CYII=">10</a>Duntsch, I. and G. Gediga (1998). &#8220;Uncertainty measures of rough set prediction.&#8221; <span style="text-decoration: underline;">Artificial Intelligence</span> <strong>106</strong>(1): 109-137.</p>

<p><a href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACwAAAAbCAIAAACImfpDAAAA30lEQVRIie3UwRGEIAwF0NRFQb8eqkkzFPM9LFmEoKOu4h7IkYHwQgDhH4S8DSAnosREWEyExVhEikEsoC8gUgwiISaSpGLNGIVIMXwFJhqN2DW0CIW1LC+pDvFyKKokijql9GemGATain81WIltRkO47RQBuIXQngMVTVrZGM+v6QaCM/iCZcNQvyFbesXkDH5ELH81qpDudfw09RSlb6hTiJuZ+wBASSqaLbd8O4b1fG9iuZjlbeY5+Yf1VZ96MXnP8l13+c9+Vt26ByN898cjjhoeRBxsxbOIEzERFgtAyO1vipj9nAAAAABJRU5ErkJggg==">11</a>Qian, Y. H., J. Y. Liang, et al. (2008). &#8220;Measures for evaluating the decision performance of a decision table in rough set theory.&#8221; <span style="text-decoration: underline;">Information Sciences</span> <strong>178</strong>(1): 181-202.</p>

<p><a href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAUMAAAAqCAIAAACm3a52AAAFIUlEQVR4nO2b24G0KhCEjYtITgTGQzQkYzCcB0eFvtB4aWeWv+pt1YHmswuwdacMQdDf1/TtACAIekBwMgSNIDgZgkYQnAxBIwhOhqARBCdD0AiCkyFoBMHJEDSC4GQIGkFwMgSNIDgZgkYQnAxBIwhOhqARBCdD0AiCkyFoBA3q5DSHuJz6xRLDnJyi+eM6DzN385ymaZoGTUJRbjBViGmeBCnt1Rezi47T6yhSPD+Yfi0x0BCq+D7nymNz+vzuAuW2RIxHdEsMJRh2eL1YvhePxypJgElHdYXnfuX5aAxcDTXycju9xNmRqhPMVU2Uaa7GvzYvmoTmZtFpmos/P8z9Vj8Z1h5odaqKzPj1HdX9CBR5aOvBIrglhjrYz7123Uc0cTzAs3QyN576MxMXD4TQFPMwza7ToztMo+9myq085KluO0oQOm9jWW91x0WwShgOXqbTKaOW5hCCcN/KOITk1PA/phbM/ARP4mTtFAvLwMXzNue8xJj2BpQ5MM1+NP1htjsnvVOPynNYtX6wRhw3MIYND1pLDCpWA/l5pblOGzr/LjEmhoncSzE5fZcRe067ylNcfrudbOOqgNN0Y3tG2rSL/GDuajhZ8GCxBjSSqN4JrjPgGw915rPE6qHYINXTyknVRubrwSfV2JMMW8aFTHBclXsw3OV5ZU22cVXAaYHJeQut6BWYzZbpg9qOqD2z0XNvPNPp6V6o6z5KG9nrItUqYV39lP+q8EkCaiH5ObkDZr7HkzwM9zrZxEXLg28+Cyvyh5kbTl4X1lAUBZmte418HHWFaDuwFTa56il31JOoWO0q1o8tOLIlVEfml5hd09ktnqSy1elkE1fVG33eFGc+c669LX+YWXdyO50bGaSWEzpDvS6D1xJDiImWgOULH7ufrC1KrvLstmUUql1iQI4rTNe0eJ1n+Wx85jnZxEU6I+879eR0XaydYa7SnNzunL0TqU5sZ1gBQU3JR9QKea8iqJFX12qwTn/DQKtdNJfI4vvpulh4GvG4lq57psUbPLl7u5xs4+rIW6Vq/aXMzI8l56W+lSmsTlNeg6tbPf86at8Hhfk/Hp06yCoQe8Vtjv2cmS0j59qz4kOIcnvJHXgNZr7PU9xRT0xiUwYu5d4dM4CcuGQQd2DGhVXZXGHuUvYwfXMD/QBEqnORsq1uc0sH3jSHuAj1eKmwJ79gN2bIxmk1yZSWJnKbJitjaMBC6rEC4lswhfBu8Ty5Jpu4xFDoQeFdCn22vgcz85dFr8AULj3UHlJdKuAemhO5SHvJcuSm/t5ty7ijGX5jq1+XI9k66xmd+T65x8l1RwKB4gI2gVfrhyS21XGHmV149pBknSu4VFh14vGxkFb5d9EWTw4zM55vwBSPeqvCtQ+6tRoevyhnQOMTxwuyX+H/nH4XZjZ49jv5NVEj2zwlmJnz9Id5r+2Lqt//7QWy1rct5RZKXUfyXWKPf+D1gn4W5hMNvC22v7F4ijDpH58rXWF+y8nlN5/bLjyEmGhNY7uomPeKjZD6tusSsj+Xdqt+E2b+mzxrDDZPGSZrKG+X+MH80vammMmO+k25eagGneYwz4E+PrQqjP/U/yebMHPJ8w2YRoO/rHqwVnLKMHNj+O//f7KzOiqES0pb5Ud8sXC2xDiu+lisPAHT0G2Y3W08qy+WHJoTzcFCpHJpZhtZ1qz9oQiYPboDM3+L588VDyEIuiA4GYJGEJwMQSMIToagEQQnQ9AIgpMhaATByRA0gv4HcFPRS3/biycAAAAASUVORK5CYII=">12</a>Beynon, M. (2001). &#8220;Reducts within the variable precision rough sets model: A further investigation.&#8221; <span style="text-decoration: underline;">European Journal of Operational Research</span> <strong>134</strong>(3): 592-605.</p>

<p>[<a name="OLE_LINK46"></a><a name="OLE_LINK45"></a>13]Greco, S., B. Matarazzo, et al. (1999). &#8220;Rough approximation of a preference relation by dominance relations.&#8221; <span style="text-decoration: underline;">European Journal of Operational Research</span> <strong>117</strong>(1): 63-83.</p>

<p><a href="data:image/png;base64,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">14</a>Pawlak, Z. (1997). &#8220;Rough set approach to knowledge-based decision support.&#8221; <span style="text-decoration: underline;">European Journal of Operational Research</span> <strong>99</strong>(1): 48-57.</p>

<p><a href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAfYAAAAhCAIAAACkxR7IAAAHJklEQVR4nO1d3bmkIAy1LgqijimBamzGYtyHQQXyQ4jBu+OX87YzCidwOITonV12h8PhcLwUy18TcDgcDscsuMU7HA7Ha+EW73A4HK+FW7zD4XC8Fj9q8WtcliWu8OOQtptNbymAhrcUYbtrXL4Q9MkSw3oU4n/g8N+DEMvvAAvAQuo7Mu+3pS7gphWbJY1pgj9IzhacWNWjFr+lsGB4cAVtKWD9bSkYsdhSaEQEdb/G3NmWQkdyAmKwRwke5rClwHx/kpmFNWIxnquewMFpis1ji8HEeNs+GuJ2Ut/BvN+SupibQvDmNOYJXrec29YRtI2KVK3K4ptBznSecXnc4E1FD9trdS/vTnzlcATPc2Akz68GA2Q3BZ2ssfis0UYdDr5FmPA6m/2yNOwFUbu11Jsm9VIfvHgsjjk05gjewOGPZqp2MJ8VqFpXqGkbNpc23zWYlmqh26Ca/Vb3axTuaCPEBtfuX3CgMpfpZZ4thSUEJHtbUyvDksgaa8O3T0Pa5Wx8WoDNTZD6Xs67Wurj3EYEP4vGDMGPcGWAuffXaKvks6tqG4vPG8wTeTxyTJuQ1+x7pZRG91K3GCU2qs3nOZB1kelFmpC27gmdGxPR8V7LbFovbXuTpL5fgSilruMmFvxEGuaCN3J4IuQ1Lu2x8ZEs/r7DczXVul2Q2IBiYihuJItIxWXHzfnay9fPdgvdN0R7jjNE7LyhMxomHPpRE+0hxRLkONlZB7COzedS2X54QXct3twdq+WcQxJ0olX7LKkXTeukruT2vSeZqZ2lMUvwVT8hrWx7YtlTeq3zeImqDSz+0VI83CSxKIutjjlS1Rti/qS4+IpSldooiA3Ui9Uc5FHjaPVdxVHezNQshk70RVrW8Xh2TIySK9DmgP0oe6j3kClS38+p02bxOm5Swd+hMVXwZ5/5GthZzUSsEIpVU6oRqFpv8YKdaALgKOFjkYc98a9vNfc2k3nJRaV7BbHB86iSgzRqus16gTTLpZthoO/lkajSKN7jO9TNTf5KACe9l9mofZ7U93PwtBav4zZSbtTTmCj4tnGmsSHZk/sO2EO6qr6dxRuJW3J0xYNhB6O3aVaWgWzX9hbPEjsaFoyGwTbTi5pCmcYQ7x6fAZBHTXKWqZYEybJgTCxtvuxubBko1T5P6vski+9xI7SgVDvZ2zzBN/2xDj8ge1JO+CmBUPXn89lNCjWTHmTRPaMHTHDllmII5BhWty9xxY6SkyyeIfZMFr8Lo+b6Po/fbevXYxmmmihXC6gncGrrULd+VllpcaDGpuxhptT3aRbPc3smi9+nCR6ZIEacYn3ICvHXZxj7z+djZvF/bPL4cOTNVpJcfYNJ8PWoCbX4DrEnavFVV2zUDL5RgOUCt368UCMWO3B4XOblV4/V4sHx/09q8TZSP78zrcX3uT1Ri6+6shV8fesaQ2AetcplT/gptoHQ+fsJiz99OrvnwkvFiUtw5qYB5AIfiZcz0ZzRsLPRlxN6cs0f6nQ/QIy6gW9cxaFqgI2aGK7jqxjBcinn5rTidZUX18BlyFUE8Z1cGtd3hhYP+2pXYC11Zde12scUhUwfP3ZfF5NKvYl3WO3oPQTu0KjasBV8QWuNS1zXuCwxkTV3uexxe4XMmHFRZ/GNRQNBkUS+H2YBnckZsvwlBKAztqels8ISCqbHv7BaFlrkPy4sdD+ycMXEYI/9MdBxaALsRE0M1/ElUfQ84krcq1agHI0lVzANqEJH1cdo0CjLroe/zOKazq+8bWTz5liPKAqfPnTS92veB6TepKWjat+Fgr9Ho4nRWvDVnNMbKLwej4d8SMMlLmSHdwo1Q9hSDKCCpc6n0DOf1Bvz1am5FqtNVkrpPQzPGWvEXvcZKsDdSzNxGhSHbtTH/e1w/Sas03hRj5X/Kzweqn24nXr60DI8koT1WYUY28LDILe7gh+l8UbBC1Q93eK3FNMK9ll9OkXEJFfXWTOqKCK7c5U8cbo/rkXrYmJiOg8Q0UCb7kedL2uH60ehTaTvdFgfMxR2hql9SCjN9BFCxg+sOK50H1nFI9zuCX6cxisFL1D1ZIs/D1mFTG85/NEmXiPotYsWw8ofMjkva0tBtO6vcIhVLCR20354GpCDIOpJTxD/BM+HAhxe1z2mduFuBWOGkw6odSz+zISpFFzO7c50KGi8UfAivlMt/niHtHqX9K7D55bRstzIj2hju0/+fCTdOsLhT0zTf7paQGONIf/Oy/2ofwqSd03MUcr8rnNgAVhIfVernR/SWb8Xr6HxWsGLVT3L4q83bI4nCNfziN4jid9Cji/E+OCbo/8tDce+g6dmL5qO4yFqevzJxv9I4yfwo//rk8PhcDj6cIt3OByO18It3uFwOF4Lt3iHw+F4LdziHQ6H47Vwi3c4HI7Xwi3e4XA4Xgu3eIfD4Xgt3OIdDofjtXCLdzgcjtfiH7O7zQ423bftAAAAAElFTkSuQmCC">15</a>Swiniarski, R. W. and A. Skowron (2003). &#8220;Rough set methods in feature selection and recognition.&#8221; <span style="text-decoration: underline;">Pattern Recognition Letters</span> <strong>24</strong>(6): 833-849.</p>

<p><a href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAJwAAAAiCAIAAAAlGicfAAAClElEQVRoge1ayZXDIAx1XRSkeqiGZijGczCYxRJIONjPjP5pJnG0fW2QbLtiOWxvG6D4PZTUBaGkLggldUEoqQtCSV0QSuqCUFIXhJxUB8b6CZbs+757a8BNkv2PICPVW7PNjbq3ZpuXNB04iM452Cg8YV2pPhjlraleoSAgdT6jz+pB1EbCHJx/emuyIM5sU4g9dQY56BK67xJSM0dn4wVajzIIDqaKrUPr7GNdpMymwyxmVLikPhznBzMoqANAq8DBMw0XtSnXLCGASWpz1MVmb6zlhCAOjPNBpNEg+vpasqHDGj2ZQeBwDx2IxHT94ttZFqq3RpBaPFKvraB45+xa7D2i7mqXwizzlKFltLZjuNCSpP2mpbX9YtuZ28PuuwE8UqkmhISeqb1ORKik5+8ztFwF8HBWACEVL7W2wJZfbDszOVJK75FavyqaP2UmXqxOTnG0XBoar/3WB5f6+ZGB2vSLb+c5DUb27Ruk1vu1LARphiGUZqSytMhGTpKUBGNiJQO1MJz0i29nsGfsCDU+U5HtLD3TvxoKIqkHo/SmlkKauE3mH8AcFA/U/FOEX1w7j8ZvBu/XxrffPI8dbMYEZyx6LMB7G1naWfdhapH0iesZHinKTp3iTvX84top2DkR3DinltdW4T9jfZ3i6SxSJ0UzZOFxUgv6od6syodavk0XL9aTjzxxUGt4p776drZOkKFZQWOLnnKjhPYewWXMSxeFA3jwhikohNTByBBJLvS5tGKcYm35rp7XIXHqRwpN6i902su/penG+8Kp9KjzCUbfuD+MnPZWuAnfp94Y8vp9ahthGhuAeCviHBIv/eXDl0EUmJL6ZRB7mpL6YVD7h5K6IJTUBaGkLggldUEoqQviD0AoRYNKApd8AAAAAElFTkSuQmCC">16</a>Pawlak, Z. (2002). &#8220;Rough sets and intelligent data analysis.&#8221; <span style="text-decoration: underline;">Information Sciences</span> <strong>147</strong>(1-4): 1-12.</p>

<p><a href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIkAAAAlCAIAAAD5mF0LAAACfUlEQVRoge1Z3dXsIAi0LguiHquxGYvJ96Ax/oGQ9e5yz2EeNwkzYRA06y6DVrhfCzCgMG/0wrzRC/NGL8wbvTBv9MK80QvzRi/MG73geRPBh4Rec8455yC+FpGCZzx9gOj/wt6bFPwuHSl4h5vHATPC50TV4R4fBn0voGQ2BT/8cm29YRhzJGM8qjNEORFtnJKu7y3ISUER0SugvYnAycUc9R227hwiijAvlFy433InBT+QRZjJKW9Yi+acNdeuFg4RzYmp0b/V24bqQBJNeEN2kLtB+hCZjebus/XexcJeUHKJmo5NbxkQa4iVw1EuktFLSMGvY+HeYO/QS5NV2/BS8zLpC4pNxOu9K4pBG+0opVwio5WwamYFuDfYOyzSx280Y8XAqu2X62yiOQwB7LV2VbZTLpDRhCKckXuz6JSiGdCXzPTkE49PNLURqqdFoBoXVfUb5QIZtXNTx8ZL7M0wjuXz85koq/d7LBAQof0aoZcNG65ygYyS2Y0z0nnT+xXB+3487w/4JSp2402wIxpjMrOCDHFWiW2U82VkEZ7IVNEj26eNnTKCcxCQPpu3N6OC/Cu+BPIlERExRBbc/X3LY+cL5QIZjErINkvPN/WLA8S7E9w0w0J7Nr/jTowsmGb/ghFhj1KNfv2pZh30jXKmjGtzNMm+AXgf0pHvAg3r4kgX2AGYZ91vQaD8ECHUpuFD2n/rFLizsiaFwE62rBD+NSTKDxGW9NUS5X2H5uRssoY5BOrNeowRKT+Ee7E0m/zP/7957pHup1tdinrZj3DvSkId2/a/p1ZEMG+0IlLnG8MvEcGZN3ph3uiFeaMX5o1emDd6Yd7ohXmjF398uo8Q2Re48gAAAABJRU5ErkJggg==">17</a>Pawlak, Z. (2002). &#8220;Rough sets, decision algorithms and Bayes&#8217; theorem.&#8221; <span style="text-decoration: underline;">European Journal of Operational Research</span> <strong>136</strong>(1): 181-189.</p>

<p><a href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAhCAIAAABWXBxEAAAAkklEQVQ4je3UzQ3AIAgFYOZ6AzkP07AMw9iD1SYFlf4cmkbOfj6ERMoPihb+EVYGWO/hvp3jgZ3ikR1gZVCrJHGsDAJrzVWGyz0saY+qPde7DCY6+eNke2+7bZZ8wVoc7nmUbGYlycTbN5cdAWVR/SV7ya35c4yXHLTKsFNzsROSszIi2LVR7JYkO75Pf0MLv4Y3qPIxo0q+Q44AAAAASUVORK5CYII=">18</a>Kryszkiewicz, M. (1999). &#8220;Rules in incomplete information systems.&#8221; <span style="text-decoration: underline;">Information Sciences</span> <strong>113</strong>(3-4): 271-292.</p>

<p><a href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIsAAAAmCAIAAAB7+f+YAAABsElEQVRoge2Zy6HCIBREqYuCqIdqaIZieItnPgYI3BtIRp1ZRj0MnpAQNYnBjnm6ANMIDaGHhtBDQ+ihIfTQEHpoCD00hB4aQs9lQ9Fb6yMCZDb2oZJXDVHQbOxFQxQ0HXvNEAXNx2oNRW/NGhfugwTXfOeQbiJavVRwpqygu6TGUPTWWB+XEyB6q/gedJDgjHNnjoZ0U9DKjipLRFRSbii4l/Nl+GW8+ZDmjIZ009EKpSp+hCVNOiy4ctaxN9o6/jpid3SQ3YTLcx/STU87lqouKxm2Zw3thnpO0GH+BUcPC0rvN53GBa4fKzRUXaEdN/A9TwzJX8qOtK8es0tuI1T3aPKSyjV08yah/K0cjj61Scg+5kLdohwrNPS6aVn7f+fa5EtOTymkey9bwa7vlV3ylDON3p6OIy2peh7KSrZaTYN0YPd8MR2gpMZQiS+e/hBIH1YPRyipMFTkS3sPgXRiF7b4wQiipOqJNecHV7iozoZ0YlNKAwXdXvLr/8GL3m1bJ9SclfwBQ3bID6hTc1by6w19fGgIPTSEHhpCDw2hh4bQQ0PooSH00BB6aAg9fx1epYKxOiUQAAAAAElFTkSuQmCC">19</a>Greco, S., B. Matarazzo, et al. (2001). &#8220;Rough sets theory for multicriteria decision analysis.&#8221; <span style="text-decoration: underline;">European Journal of Operational Research</span> <strong>129</strong>(1): 1-47.</p>

<p><a href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABgAAAAfCAIAAAByEJoXAAAAlklEQVRIie3UyRGAIAwF0F8XBaWeVJNmKEYPjGExkBw84AyclOXxI4y4Pmo40IF2hYQAIHEur5mTPpchkAQTCdXZmdOzru22FaCDbCdzanJGErUrquPGeUNCE8eN00NNIHWijFEaiTqWImSVOX5sPWZ4h71OVIPNCTuRCa0cLT4ATbd0thkhx4lDThPC5D7s/Rs50F+gG9s7LIQF46mPAAAAAElFTkSuQmCC">20</a>Pawlak, Z. and A. Skowron (2007). &#8220;Rudiments of rough sets.&#8221; <span style="text-decoration: underline;">Information Sciences</span> <strong>177</strong>(1): 3-27.</p>

<p><a href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADUAAAAcCAIAAABOJ2DZAAAA+0lEQVRYhe3W7RGDIAwG4MyVgZgn07BMhrE/+DBRgiiejXe+P2tDnwTkCovvwL8BB/l8c3mvjwmR+EFKM6bPB8/0OeFZvgnevZ3tfEwINSFeWZMJrdIYAACqX/aSHm3rlI8JAYlLGRPOCKE5xhhWBBOW9eXHhi+G/I3SVeFeSh7Htr7NY0KjnepbMXXoFayiDsBQxBoSsvKs4QnfMG807eMUg8Gz9glE4X2bm2ZszL6OIT3v6fbzm341lm5r9dXOvD5uke9H6g2xeazP6brVeeMHLzB9/8UwceJORFwsB1E+fzzle4p35nf0/eyO9+L/pz7y+eby+ebi3fcDVcgo4aUgmNkAAAAASUVORK5CYII=">21</a>Pawlak, Z. and A. Skowron (2007). &#8220;Rough sets: Some extensions.&#8221; <span style="text-decoration: underline;">Information Sciences</span> <strong>177</strong>(1): 28-40.</p>

<p><a href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA8AAAAgCAIAAABCTrX+AAAAfElEQVQ4je3TsRHAIAgFUOb6AzkP07gMw5jCoEbBkM4itD7+IZ5UvhT9+gQtDLAEtYNt7WFTu3jSwqBWKW+0MAgsmiyM1avO6Q7TMbTZ0P2ozdzaFx3FVcfGmLN3FxxvKQwioO7PWXZ57DsnJ9HSAdx1BI+v847P/2nH6wv5pzEE+KJs/AAAAABJRU5ErkJggg==">22</a>Greco, S., B. Matarazzo, et al. (1999). Handling missing values in rough set analysis of multi-attribute and multi-criteria decision problems. <span style="text-decoration: underline;">New Directions in Rough Sets, Data ining, and Granular-Soft Computing</span>. N. S. A. O. S. Zhong. Berlin, Springer-Verlag Berlin. <strong>1711:</strong> 146-157.</p>

<p><a href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAeCAIAAACqmwlGAAAAfUlEQVQ4je2SyRXAIAgFf10WRD1WQzMUEw8YgkpicvC9HPTkMiOL4vg4sIUtLBCYACBl0aXkZHM9AnEXgUl3K19nzTbmvOTk4nrBn1y8vyWoIeTt+lZwAYzv8SAlYuNHui/a2oezieMIHs7185XwzI8CU5zKnTDj//691wgFBK4w0rbwGEAAAAAASUVORK5CYII=">23</a>Greco, S., Z. Pawlak, et al. (2004). &#8220;Can Bayesian confirmation measures be useful for rough set decision rules?&#8221; <span style="text-decoration: underline;">Engineering Applications of Artificial Intelligence</span> <strong>17</strong>(4): 345-361.</p>

<p style="margin:0;padding:0;height:1px;overflow:hidden;">
  <a href="http://www.wumii.com/widget/relatedItems" style="border:0;"><img src="http://static.wumii.cn/images/pixel.png" alt="无觅相关文章插件，快速提升流量" style="border:0;padding:0;margin:0;" /></a>
</p>

<p>{{ template &ldquo;_internal/disqus.html&rdquo; . }}</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://luosha865.github.io/archives/11">
        R语言系列—-区间估计
      </a>
    </h1>

    <span class="post-date">Sat, Jun 30, 2012</span>

    <p>这一篇讲的是区间估计…..因为这不是一个关于统计学的系列，所以对文中出现的公式不会给予任何证明…..就是这样。</p>

<p>就从一个最简单的正态分布的方差已知时，求均值的置信区间开始吧。</p>

<p>书上的公式告诉我们这个区间是 $$\overline{x}\pm(\sigma/\sqrt{n})z_{(1-\sigma/2)}$$ ,其中Z<sub>p</sub>表示的是正态分布N(0,1)下侧的p分位数。</p>

<p>我们用R来实现求得这一结果的过程。下面设x里存储了给出的样本，sigma表示已知的方差，n表示样本的个数， alpha则是(1-置信水平)</p>

<pre class="lang:r decode:true">mean&lt;-mean(x)
ans&lt;-c(mean-sigma*qnorm(1-alpha / 2)/sqrt(n) , mean+sigma*qnorm(1-alpha / 2)/sqrt(n))
</pre>

<p>这样,ans就存储了要求的置信区间。</p>

<p>来解释一下吧，先用mean(x)求出样本的平均值，然后用qnorm(1-alpha / 2)求出Z<sub>1-a/2</sub>，（还记得么？前缀q是分位数函数，）剩下的就是套公式的加减法了。</p>

<p>这里的qnorm(1-alpha / 2)其实省略了很多参数，完整一些的写法是</p>

<pre class="lang:r decode:true">qnorm(1-alpha/2,mean=0,sd=1,lower.tail=TRUE)</pre>

<p>第一个参数就不用解释了，第二,三个参数mean=0,sd=1，表示这是一个标准正态分布(不同于前面，这里增加了mean=和sd=，这种做法的好处是可以改变参数的顺序，但是结果是一样的)，最后一个参数lower.tail这个参数的意思就比较有意思了，官方解释如下：</p>

<p>if TRUE (default), probabilities are $P[X &lt;= x]$, otherwise, $P[X &gt; x]$.</p>

<p>明白了么?等于真的话，得出的就是X&lt;=x的分位数，为假的话就是从X&gt;x的方法寻找这个值。一般我们用默认的真就可以了。</p>

<p>接下来我们把它整理成一个函数，方便使用</p>

<pre class="lang:r decode:true">z.test&lt;-function(x,n,sigma,alpha){
mean&lt;-mean(x)
ans&lt;-c(
  mean-sigma*qnorm(1-alpha/2,mean=0,sd=1,lower.tail=TRUE)/sqrt(n),mean+sigma*qnorm(1-alpha/2,mean=0,sd=1,lower.tail=TRUE)/sqrt(n))
ans
}</pre>

<p>这样我们就可以直接使用z.test()完成对u的置信区间的计算。</p>

<p>比如，有10个样本，分别是175,176,173,175,174,173,173,176,173,179。标准差为1.5，求均值95%的置信区间：</p>

<pre class="lang:r decode:true  ">x&lt;-c(175,176,173,175,174,173,173,176,173,179)
z.test(x,10,1.5,0.05)</pre>

<p>则返回置信区间：</p>

<p>[1]173.7703 175.6297</p>

<p>{{ template &ldquo;_internal/disqus.html&rdquo; . }}</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://luosha865.github.io/archives/10">
        R语言系列—-数据描述
      </a>
    </h1>

    <span class="post-date">Sat, Jun 30, 2012</span>

    <p>简单来说，R语言是一种主要用于统计分析、绘图的语言和操作环境。的源代码可自由下载使用，亦有已编译的执行档版本可以下载，可在多种平台下运行，包括UNIX（也包括FreeBSD和Linux）、Windows和MacOS。R主要是以命令行操作，同时有人开发了几种图形用户界面。</p>

<div>
  <p>
           为什么我会使用R语言呢？毕竟我们还有SPSS,SAS，S等其他工具。就我个人而言(其实对很多人也是这样)有两个原因&#8212;-R的开源与其极高的自由度。
  </p>
  
  <p>
    R是开源的，是属于GNU系统的一个自由、免费、源代码开放的软件因此在使用它时我们不用担心使用的资格问题。（当然对人一般人来说其他软件也可以使用盗版…起码国内是这样）另外作为一种语言，R拥有极高的自由度&#8212;-对于，很多新的统计学模型，也许SPSS等软件根本无法处理&#8212;你只能使用系统提供的有限选项。但是在R语言中，你可以自己去实现它。这也是学术界对R如此关注的原因。
  </p>
  
  <p>
    敲了这么多废话，进入正题。
  </p>
  
  <p>
    这一篇的内容是数据描述，就冲R中内嵌的一些简单分布开始吧。
  </p>
  
  <p>
    R语言中提供了四类有关统计分布的函数（密度函数，累计分布函数，分位函数，随机数函数）。分别在代表该分布的R函数前加上相应前缀获得(d，p，q，r)。如正态分布的函数是norm，命令dnorm(0)就可以获得正态分布的密度函数在0处的值(0.3989)(默认为标准正态分布)。同理pnorm(0)是0.5就是正态分布的累计密度函数在0处的值。而qnorm(0.5)则得到的是0，即标准正态分布在0.5处的分位数是0（在来个比较常用的：qnorm(0.975)就是那个估计中经常用到的1.96了）。最后一个rnorm(n)则是按正态分布随机产生n个数据。上面正态分布的参数平均值和方差都是默认的0和１，你可以通过在函数里显示指定这些参数对其进行更改。如dnorm(0,1,2)则得出的是均值为1，标准差为2的正态分布在0处的概率值。要注意的是()内的顺序不能颠倒。
  </p>
  
  <p align="left">
           接下来我们用R来生成一个二项分布分布的图形吧。
  </p>
  
  <p align="left">
           binom是二项分布。
  </p>
  
  <pre class="lang:r decode:true ">n&lt;-20
p&lt;-0.2
k&lt;-seq(0,n)
plot(k,dbinom(k,n,p))</pre>
  
  <p>
    R语言中用<-给变量赋值，我们先让n=20，p=0.2然后用函数seq生成一个向量(1,2,3&#8230;20)并将其赋于k。然后用polt函数画图。
  </p>
  
  <p align="left">
           在这里，我们用dbinom(k,n,p)生成了参数为n，p的二项分布在1….20处的概率值，然后以k的各个值为横坐标，dbinom(k,n,p)的各个值为纵坐标，绘图。
  </p>
  
  <p>
    然后我们来看一些R对数据性质的描述。
  </p>
  
  <p>
    <strong>绘制直方图：</strong>hist(x),横轴表示变量取值，纵轴表示频率。
  </p>
  
  <pre class="lang:r decode:true">x&lt;-c(1,2,3,4,5)
hist(x)</pre>
  
  <p>
    (R语言中的向量前要求加c进行说明，故第一步是让x为一个值为(1,2,3,4,5)的向量，当然也可以看成一个值为1,2,3,4,5的样本)
  </p>
  
  <p>
    我们来画二项分布的直方图吧
  </p>
  
  <pre class="lang:r decode:true ">N&lt;-10000
n&lt;-100
p&lt;-0.9
x&lt;-rbinom(x,n,p)
hist(x)</pre>
  
  <p>
    思考一下,上面的代码是怎样运作的?
  </p>
  
  <p>
    <strong>绘制茎叶图</strong>： stem(x)
  </p>
  
  <pre class="lang:r decode:true">x&lt;-c(11,12,13,21,22,23)
stem(x)</pre>
  
  <p>
    结果如下：
  </p>
  
  <p align="left">
    The decimal point is 1 digit(s) to the right of the |
  </p>
  
  <p align="left">
      1 | 123
  </p>
  
  <p align="left">
      1 |
  </p>
  
  <p align="left">
    2 | 123
  </p>
  
  <p align="left">
    另外还有
  </p>
  
  <p align="left">
    <strong>盒图：</strong>boxplot(x)
  </p>
  
  <p align="left">
    在各种图形之后，就是对数据的数值型描述了，包括
  </p>
  
  <p align="left">
    最大值max(x)，最小值min(x),中位数median(x)，五个分位数fivenum(x)，平均数mean(x),样本方差var(x)，样本标准差sd(x)，样本偏度系数skewness(x)，峰度系数kurtosis(x)等等。
  </p>
  
  <pre class="lang:r decode:true ">N&lt;-10000
n&lt;-100
p&lt;-0.9
x&lt;-rbinom(x,n,p)
max(x)
min(x)
median(x)
fivenum(x)
mean(x)
var(x)
sd(x)
library(fBasics)
skewness(x)
kurtosis(x)</pre>
  
  <p>
    就可以得到生成的随机数据的各种描述。
  </p>
  
  <p align="left">
    注意：skewness函数和kurtosis函数属于一个并非默认的fBasics的包，所以需要先用library(fBasics)引入该包才能使用这两个函数。
  </p>
  
  <p align="left">
     基本的就是这些了，当然还可以更加复杂，比如多组数据的图形与数值描述等等。即使是我们在上面使用的函数其实也是非常强大的，只是我们在上面使用了很多的默认的参数而简化了它们的调用而已。
  </p>
</div>

<p>{{ template &ldquo;_internal/disqus.html&rdquo; . }}</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://luosha865.github.io/archives/12">
        R语言系列—回归分析
      </a>
    </h1>

    <span class="post-date">Sat, Jun 30, 2012</span>

    <p><strong>         </strong>一元线形回归模型：有变量x,y。假设有关系y=c+bx+e,其中c+bx 是y随x变化的部分，e是随机误差。</p>

<p>可以很容易的用函数lm()求出回归参数b,c并作相应的假设检验，如：</p>

<pre class="lang:r decode:true ">x&lt;-c(0.10, 0.11, 0.12, 0.13, 0.14, 0.15,0.16, 0.17, 0.18, 0.20, 0.21, 0.23)
y&lt;-c(42.0, 43.5, 45.0, 45.5, 45.0, 47.5,49.0, 53.0, 50.0, 55.0, 55.0, 60.0)
lm.sol&lt;-lm(y ~ 1+x)
summary(lm.sol)
</pre>

<p>仅列出部分返回结果：</p>

<p align="left">
  Residuals:
</p>

<p align="left">
    Min       1Q   Median    3Q     Max
</p>

<p align="left">
  -2.0431  -0.7056  0.1694  0.6633  2.2653
</p>

<p align="left">
  Coefficients:
</p>

<p align="left">
              Estimate Std. Error      t value   Pr(>|t|)
</p>

<p align="left">
  (Intercept)   28.493      1.580   18.04    5.88e-09 ***
</p>

<p align="left">
  x            130.835      9.683   13.51 9.50e-08 ***
</p>

<p align="left">
  在我们的输入中，关键是lm.sol<-lm(y ~ 1+x)的调用，这里可以看到，lm使用了参数y~1+x,即表示我们使用的是模型y=c+bx+e (1表示常数项)
</p>

<p align="left">
  然后我们使用summary查看了lm返回的结果。在Residuals:中，我们可以看到的是一些关于残差的信息：最小最大值，4分位数等。Coefficients:中则是最为关键的对c和b的相关估计。其中Estimate是与b,c值的估计，Std. Error 则是回归参数b和c的标准差：sd(b), sd(c)。剩下的两个参数则是对回归参数的假设检验： t value是对b,c进行假设检验的t值，以及P-值(用来与显著性水平比较决定是否接受该阿假设检验)Pr(>|t|)。最后我们还可以看到3个* 号，这表明x和y有非常显著的线性关系(*可以有0—3个，越多则线性关系越显著)。
</p>

<p align="left">
  多元线形回归的计算也是这样，我们只要在加入一行数据x2，然后把lm的参数改为y ~ 1+x+x2，就可以得到模型y=d+cx2+bx+e的计算结果。其中返回值的意义和上面基本一致。
</p>

<p align="left">
  至此，我们就可以用R建立起一个简单的线形模型，接下来，我们就要用这个模型去对新的x进行预测，预测y的值与置信区间。
</p>

<p align="left">
  接着上面的程序，我们先建立要预测的数据集，然后用函数predict进行预测：
</p>

<pre class="lang:r decode:true">point&lt;-data.frame(x=0.24)
predict(lm.sol,point,interval="prediction",level=0.95)</pre>

<p align="left">
  返回结果
</p>

<p align="left">
         fit      lwr      upr
</p>

<p align="left">
  1 59.89318 56.36215 63.42421
</p>

<p align="left">
  分别表示了y的预测值和上下界。
</p>

<p align="left">
  在函数predict中，参数lm.sol是之前建立的线形模型，point是要预测的点，参数interval=&#8221;prediction&#8221;表示要求给出预测的区间(上下界)，level则是该区间的预测水平。
</p>

<p align="left">
  下面给出一个多元线形回归的完整程序：（不显示结果）
</p>

<pre class="lang:r decode:true ">y&lt;-c(162,120,223,131,67,167,81,192,116,55,252,232,144,103,212)
x1&lt;-c(274,180,375,205,86,265,98,330,195,53,430,372,236,157,370)
x2&lt;-c(2450,3250,3802,2838,2347,3782,3008,2450,2137,2560,4020,4427,2660,2088,2605)
lm.sol&lt;-lm(y~1+x1+x2)
ex&lt;-data.frame(x1=200,x2=3000)
predict(lm.sol,ex,interval="prediction",level=0.95)</pre>

<p>&nbsp;</p>

<p>{{ template &ldquo;_internal/disqus.html&rdquo; . }}</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://luosha865.github.io/archives/124">
        简单讲一下使用MS3D为opengl建模
      </a>
    </h1>

    <span class="post-date">Wed, Mar 16, 2011</span>

    <p>做毕设的时候写的东西，贴上来吧…………</p>

<p>由于在OPENGL只能通过程序语言绘制模型，远不能达到可见既可得的目的。因此，比起3DMAX、MAYA等可视化3D建模工具，OPENGL模型的建立就相当的困难，为了简化这一问题的处理，可以使用简单小巧的MS3D来完成可见即可得的绘制过程。</p>

<p>MS3D的文件有着非常简单良好的文件结构，可从该文件中完美读取在可视工具中绘制的3D图形模型包含的点、线、面等各项基本结构的参数与位置，并在OPENGL根据读取结果即可进行绘制重现该模型。</p>

<p>MS3D全名为MilkShape3D，是一款简单小巧的3D可视化图形建模工具，可以简单的使用各种点、线面等基本图形元素组合建立模型，并进行贴图，分组。进一步的，该工具还支持简单的骨骼动画制作，是一款非常好用的3D图形构建工具。</p>

<p>[<img class="alignnone  wp-image-125" src="http://blog.sword865.com/wp-content/uploads/2015/02/ms3d-300x164.jpg" alt="ms3d" width="428" height="234" />][1]</p>

<p>在建立了MS3D中完成模型建立后可保存为.ms3d的文件格式，通过对该文件格式进行分析，就可以了解文件结构，以在程序中通过读取该文件重现所见模型。</p>

<p>该文件依次包括6段信息，除第一段文件头外，其它每段的开始位置都记录了该段中元素的数目，可用于计算该段的具体大小。</p>

<ul>
<li><p>文件头:大小固定为14字节。前10个字节为固定的标志 MS3D000000&lt;-其中后6个字节就是字符0（即值为48）后4个字节为该模型格式的版本号，这4个字节为一个有符号整数，目前该版本号的值为3或4，两种版本的格式细节不同。</p></li>

<li><p>点数据：紧接着文件头的就是模型的顶点数据部分，顶点部分的头两个字节为一个无符号整数，表示有多少个顶点。之后便是一个接一个的顶点的具体数据，包括可见性，x,y,z的坐标和绑定骨骼的ID编号(未绑定骨骼则为-1)。</p></li>

<li><p>多边形数据: 紧接着顶点数据的是多边形数据（三角形），多边形部分头两个字节是一个无符号整数，表示有多少个三角形。之后便是一个接一个的三角形数据。主要记录了每个三角形结构，包括顶点索引，顶点法线（用于光照计算），纹理坐标和组信息。</p></li>

<li><p>组信息：即网格信息，出于灵活性的考虑，模型的一个个三角形被按照网格或是组来划分。网格部分头两个字节是一个无符号整数，表示有得多少个网格。之后便是一个接一个的网格数据，每个网格结构的大小可能不同（因为他们拥有的三角形数不同）。主要包括网格的名字（字符串），三角形数量、三角形索引和材质索引（无材质则为-1）。</p></li>

<li><p>材质信息：贴图、颜色等材质部分。头两个字节是一个无符号整数，表示有多少个材质。之后便是一个接一个的材质信息。包括材质名、环境光、漫射光、高光、自发光、发光值、透明度、贴图文件名、透明贴图文件名。</p></li>

<li><p>骨骼信息： 动画、动作等。该结构是MS3D中的动态结构，仅当建立动态动画时存在，包括一种名为关键帧的结构，记录时间与对应的坐标系变换。骨骼信息，一开始是两个字节的无符号整数，表示一共有多少个骨骼，之后便是一个个的骨骼，骨骼的大小不是固定的。主要包括了骨骼名字，父骨骼名字，初始旋转与初始平移、以及之后的各个旋转与平移关键帧。</p></li>
</ul>

<p>在分析了解了MS3D的文件格式后，就可以通过编写程序读取MS3D文件并根据该文件建立模型了，对应于MS3D的不同分段，可以依次建立6种结构体分别对应每段内容：</p>

<p>MS3DHeader     /*包含ms3d文件的版本信息*</p>

<p>MS3DVertex     /*顶点信息*/</p>

<p>MS3DMaterial   /*材质(纹理贴图等)信息*/</p>

<p>MS3DTriangle   /*绘制三角形信息*/</p>

<p>MS3DJoint      /*节点(骨骼)信息*/</p>

<p>MS3DKeyframe   /*关键窗口*/</p>

<p>如：</p>

<pre class="lang:c++ decode:true" title="点结构">struct MS3DVertex
{
  unsigned char m_ucFlags;   //编辑器用标志
  CVector3 m_vVert;        //x,y,z的坐标
  char m_cBone;        //Bone ID （-1 ,没有骨头）
  unsigned char m_mcUnused;      //保留，未使用
};</pre>

<p>&nbsp;</p>

<p>(1)第一个成员表示了该顶点在编辑器中的状态（引擎中不是必须）其各个值的含义如下：</p>

<p>0：顶点可见，未选中状态</p>

<p>1：顶点可见，选中状态</p>

<p>2：顶点不可见，未选中状态</p>

<p>3：顶点不可见，选中状态</p>

<p>(2)第二个成员为顶点的坐标，CVector3为三个float型组成，总共12字节</p>

<p>(3)第三个成员为该顶点所绑定的骨骼的ID号，如果该值为-1 则代表没有绑定任何骨骼（静态）</p>

<p>(4)第四个成员不包含任何信息，直接略过。</p>

<p>将MS3D各段内容分别导入对应的结构体，将其读入内存。</p>

<p>多边形（三角形）结构读取示范：</p>

<pre class="lang:c++ decode:true">//内存空间分配
// pPtr为文件读取偏移指针
int nTriangles = *( word* )pPtr;
m_numTriangles = nTriangles;
m_pTriangles = new Triangle[nTriangles];
pPtr += sizeof( word );
//读取每个三角型
for ( i = 0; i &lt; nTriangles; i++ )
{
  MS3DTriangle *pTriangle = ( MS3DTriangle* )pPtr;
  int vertexIndices[3] = { pTriangle-&gt;m_vertexIndices[0], pTriangle-&gt;m_vertexIndices[1], pTriangle-&gt;m_vertexIndices[2] };
  float t[3] = { 1.0f-pTriangle-&gt;m_t[0], 1.0f-pTriangle-&gt;m_t[1], 1.0f-pTriangle-&gt;m_t[2] };
  //数据读取
  memcpy( m_pTriangles[i].m_vertexNormals, pTriangle-&gt;m_vertexNormals, sizeof( float )*3*3 );
  memcpy( m_pTriangles[i].m_s, pTriangle-&gt;m_s, sizeof( float )*3 );
  memcpy( m_pTriangles[i].m_t, t, sizeof( float )*3 );
  memcpy( m_pTriangles[i].m_vertexIndices, vertexIndices, sizeof( int )*3 );
  //文件读取指针前进
  pPtr += sizeof( MS3DTriangle );
}
</pre>

<p>&nbsp;</p>

<p>要注意得是，因为MS3D使用窗口坐标系而OpenGL使用笛卡儿坐标系，所以需要反转每个顶点Y方向的纹理坐标</p>

<p>除了读取模型信息外，还需要根据材质信息段中各种材质的贴图文件路径，读入对应的贴图文件，用以完成贴图。</p>

<p>通过对上一步中得到的各种结构体进行解析，可以得到以下以一些简单的基础结构：</p>

<p>Mesh   /*网格*/</p>

<p>Material  /*材质*/</p>

<p>Triangle  /*三角形*/</p>

<p>Vertex   /*定点*/</p>

<p>不同于以上结构体严格对应了MS3D各段存储结构，这些结构体仅仅包含了简单的图形信息，非常方便之后的绘制操作。</p>

<p>在读入MS3D文件后，可以使用OPENGL函数根据读入的数据与模型的信息，按网格分组，分别绘制每一组的数据。</p>

<pre class="lang:c++ decode:true ">//按网格分组绘制
for ( int i = 0; i &lt; m_numMeshes; i++ )
{
  //材质，贴图等
  ………………………
  //开始绘制多边形（三角形）
  glBegin( GL_TRIANGLES );
  {
    for ( int j = 0; j &lt; m_pMeshes[i].m_numTriangles; j++ ){
    ……………………….
    //三角形所有顶点绘制
    for ( int k = 0; k &lt; 3; k++ )
    {
      //单个点的绘制
      ………………….
    }
  }
  glEnd();
}</pre>

<p>&nbsp;</p>

<p>通过这种方法，就可以在程序中绘制一个个的具体模型：</p>

<p><img class="alignnone  wp-image-127" src="http://blog.sword865.com/wp-content/uploads/2015/02/ballfight-300x168.jpg" alt="ballfight" width="352" height="197" /></p>

<p>&nbsp;</p>

<p>[1]<a href="http://blog.sina.com.cn/s/blog_62d98a550100g5hh.html">http://blog.sina.com.cn/s/blog_62d98a550100g5hh.html</a></p>

<p>[2]<a href="http://www.yakergong.net/nehe/course/tutorial_31.html">http://www.yakergong.net/nehe/course/tutorial_31.html</a></p>

<p>{{ template &ldquo;_internal/disqus.html&rdquo; . }}</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://luosha865.github.io/archives/13">
        算法总结9—优化
      </a>
    </h1>

    <span class="post-date">Wed, Sep 30, 2009</span>

    <p>不同于之前的分类和聚类算法，优化的目的是尝试找到一个使成本函数输出最小化的值。这里主要包括两个算法：模拟退火算法和遗传算法。</p>

<p><strong>成本函数</strong>**:<br />
** 接受一个经推测的题解，并返回一个数值结果，该值越大代表成本越高（题解表现越差），该值越小就表示题解越好。</p>

<p>&nbsp;</p>

<p><strong>模拟退火算法：</strong></p>

<p>优化算法的目标可以看为寻找x使函数f(x)最小。</p>

<p>但是严格的最小值往往是很难达到的，我们不得不把眼光投入到寻找一个尽可能好的次优解去。</p>

<p>最简单的方法被称为随机法，即成千上万次的对x进行猜测，然后把这些x中使f(x)最小的一个作为答案。虽然这样很简单，但是效果很差。于是出现了爬山法。</p>

<p>爬山法从一个随机解出发，然后不断向该解附近的使f(x)的值更小的x移动，直到当前x附近的解都比x差为止。为了使效果更好，我们可以从多个随机解出发重复着一个过程，将最好的一个作为答案。很容易就能认识到，这样找到的解是一个极值点，是一个局部最小值。</p>

<p>爬山法虽然好，但是在其寻找最优解的过程中，前进的方向是固定的（使f(x)更小的方向），但是有时向其他方法前进也是必要的，因为f(x)可能先增大在变小成为最优的。</p>

<p>于是就有了模拟退火法。</p>

<p>该算法这源于固体的退火过程，即先将温度加到很高(大量原子被激发)，再缓慢降温(即退火)，则能使达到能量最低点。如果急速降温(即为淬火)则不能达到最低点。</p>

<p>模拟退火法同样是从一个随机解出发。但是它在寻找最优解时并不一定是向更好的x移动，也有一定的概率向更差的x移动，这个概率开始较大，但是会随时间而渐渐变小，直到稳定。一般该概率可以定义为：p=e ^ (-&nbsp; (highcost &ndash; lowcost ) / temperature )，其中temperature是随时间增大而变小的温度，开始温度很高时p -&gt; 1，后来会渐渐变小使p-&gt;0。</p>

<p>&nbsp;</p>

<p><strong>遗传算法：</strong></p>

<p>遗传算法的思想来自生物的遗传和变异，算法以种群为单位（一个种群为一组既多个解），其算法的运行过程如下：</p>

<ol>
<li>随机生成一组初始解（初始种群）。</li>
<li>计算种群中各个解的成本，然后进行排序。</li>
<li>我们将种群中靠前（成本低）的解保留下来，删除其他解，这一过程称为精英选拔。</li>
<li>对已有解进行微小的改变，将改变后的结果作为新的元素加入种群，这一过程称为变异。</li>
<li>选择一些优秀的解两两组合，然后将他们按某种方式进行结合（如求平均），将得到的结果作为新的元素加入种群，这一过程称为交叉（配对）。</li>
<li>不断重复2&mdash;5步，直到达到指定迭代次数或成本函数连续数代都没有更好的改善。</li>
<li>得到一组解，该组解为算法输出。</li>
</ol>

<p>&nbsp;</p>

<p>该系列结束，恩，也许以后学了更多，有了更好的了解后会回来改一改，谁知道呢？</p>

<p>{{ template &ldquo;_internal/disqus.html&rdquo; . }}</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://luosha865.github.io/archives/14">
        算法总结8—非负矩阵因式分解
      </a>
    </h1>

    <span class="post-date">Fri, Sep 25, 2009</span>

    <p><strong>数学基础:</strong></p>

<p>线性代数的矩阵乘法运算。</p>

<p>&nbsp;</p>

<p>&nbsp;&nbsp; 非负矩阵分解是一种特征提取的算法，它尝试从数据集中寻找新的数据行，将这些新找到的数据行加以组合，就可以重新构造出数据集。</p>

<p>算法要求输入多个样本数据，每个样本数据都是一个m维数值向量，首先把我们的数据集用矩阵的形式写出来，每一列是一个数据，而每一行是这些数据对应维度的数值。于是我们就有了一个大小为m*n的输入矩阵。而算法的目标就是将这个矩阵分解为另外两个非负矩阵的积。</p>

<p>　<img src="http://sword865.com/blog/wp-content/ql-cache/quicklatex.com-cad804e086b2306a9bd31889dd0dbb72_l3.png" class="ql-img-inline-formula quicklatex-auto-format" alt="&#77;&#95;&#123;&#109;&#42;&#110;&#125;&#61;&#65;&#95;&#123;&#109;&#42;&#114;&#125;&#66;&#95;&#123;&#114;&#42;&#110;&#125;" title="Rendered by QuickLaTeX.com" height="15" width="144" style="vertical-align: -3px;" /></p>

<p>&nbsp;&nbsp; 我们将分解矩阵后新得出的一个维度称为特征，那么在前一个m*r的矩阵中，第i行第j列的值就代表属性i对第j种特征的贡献值，而后一个矩阵的第i行第j列则代表第i种特征对第j个样本的贡献值。这样我们就找出了输入样本的r种特征。</p>

<p>&nbsp;&nbsp; r的大小应该依照需要进行选择，比如如果是希望找到某些共性特征，则就要选择较小的r。当我们确定了一个较为合适的r值后，就要想办法确定后面两个矩阵具体的值了。</p>

<p>&nbsp;&nbsp; 书中给出的算法大致如下：</p>

<ol>
<li>定义一个函数计算用来两个矩阵的差异程度（每个对应元素相减后平方的和）</li>
<li>随机生成2个矩阵(m*r维和r*n维)记为A（权重矩阵）,B（特征矩阵）</li>
<li>计算A*B与输入的m*n的数据矩阵的差异，足够小则停止，否则继续</li>
<li>按一定规则调整A，B的值后转3.</li>
</ol>

<p>对于调整的方法，可以用模拟退火（下一篇文章中会提到）等多种算法，书里使用的是乘法更新法则，该法则我没有认真去看&hellip;.感兴趣的可以去看论文&hellip;.英文的&hellip;</p>

<p><a href="http://hebb.mit.edu/people/seung/papers/nmfconverge.pdf">http://hebb.mit.edu/people/seung/papers/nmfconverge.pdf</a>.</p>

<p>&nbsp;</p>

<p>算法如下：</p>

<p>hn 转置后的权重矩阵和数据矩阵相乘的结果</p>

<p>hd 转置后的权重矩阵和原权重矩阵相乘再乘特征矩阵的结果</p>

<p>wn数据矩阵与转置后的特征矩阵相乘的结果</p>

<p>wd权重矩阵与特征矩阵相乘，再与转置后的特诊矩阵相乘得到的矩阵</p>

<p>为了更新特征矩阵和权重矩阵，我们先把上面所有矩阵变为数组．然后把特征矩阵中每一个值与hn中对应值相乘，并除以hd中对应的值．类似的，我们再将权重矩阵中每一个值与wn中的对应值相乘，并除以wd中对应的值．</p>

<p>&nbsp;</p>

<p>最近的算法都很好理解的样子&hellip;不过写起来还是挺麻烦的&hellip;.还有最后一篇优化了，内容挺多，包括模拟退火和遗传算法&hellip;.恩</p>

<div>
  <embed id="lingoes_plugin_object" width="0" height="0" type="application/lingoes-npruntime-capture-word-plugin" hidden="true" />
</div>

<p>{{ template &ldquo;_internal/disqus.html&rdquo; . }}</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://luosha865.github.io/archives/15">
        算法总结7—多维缩放
      </a>
    </h1>

    <span class="post-date">Sun, Sep 20, 2009</span>

    <p>一直没有时间写…..唉</p>

<p>这个东西好像是属于数据可视化？反正就是把多维的数据降到低维空间但是仍然尽可能的保持原来数据之间的距离关系(就是在原来维度下离的远的点仍然离得远，接近的点仍然接近) 。最常见的应该就是降到2维以方便打印和屏幕输出。</p>

<p>算法的输入是所有数据在高维情况下两两之间的距离（记i与j的距离为Dij）。现在以降到2维为例说明这个算法。</p>

<p>首先我们把所有数据点随机绘制在一张二维图像上，然后计算它们两两之间的距离dij，然后我们计算出它与高维距离Dij的误差，根据这些误差，我们将每对数据点按比例移近或移远，然后重新计算所有dij，不断重复到我们没法减少误差为止。</p>

<p>还是来具体说明一下吧，假设有n个点</p>

<ol>
<li>输入每一对点之间的距离Dij。</li>
<li>随机在2维平面生成n个点，点i坐标记为x[i]、y[i]，计算它们两之间的距离，记为dij.</li>
<li>对所有i 和j计算：eij=(dij-Dij) / Dij，每个点用一个二维的值grad[k]来表示它要移动的距离的比例因子(初始为0，0)。在计算出每个eij后，计算 ((x[i] &#8211; x[j]) / dij)* eij，然后把它加到grad[i][x]上，同样把((y[i] &#8211; y[j]) / dij)* eij加到grad[i][y]上。</li>
<li>把所有eij的绝对值相加，为总误差，与前一次的总误差比较(初始化为无穷大)，大于前一次的话就停止。否则把它作为上一次总误差，继续。</li>
<li>对每个点，新的坐标为x[i] &#8211; = rate * grad[i][x]  y[i] &#8211; = rate*grad[i][y]，其中rate是开始时自己定义的一个常数参数，该参数影响了点的移动速度。重新计算各个dij，回到3。</li>
</ol>

<p>伪码：</p>

<pre class="lang:vim decode:true ">for m = 1 to 1000{
  for i=1 to n
    for  j = 1 to n
      dij=sqrt((x[i] – x[j])^2+(y[i]-y[j])^2)
  for i=1 to n
    gradi=0
  totale=0
  for i= 1 to n
    for j= 1 to n{
       if(j==i) continue
         eij=(dij-Dij) / Dij
         grad[i][0]+= ((x[i] - x[j]) / dij)* eij
         grad[i][1]+=((y[i] - y[j]) / dij)* eij
         totale+=abs(eij)
       }
  if (laste &lt; totale) break;
  laste=totale
  for i=1 to n{
    x[i] -= rate * grad[i][x]
    y[i] - = rate* grad[i][y]
  }
}</pre>

<p>&nbsp;</p>

<p>恩，就是这样….最近这几个算法都不是很难恩………..</p>

<p>{{ template &ldquo;_internal/disqus.html&rdquo; . }}</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://luosha865.github.io/archives/16">
        算法总结5&amp;6—-k-最近邻与聚类
      </a>
    </h1>

    <span class="post-date">Mon, Sep 14, 2009</span>

    <p>因为这两个算法比较简单，又有些相似，所以这里放在一起。</p>

<p><strong>K-</strong><strong>最近邻</strong><strong>:</strong></p>

<p>k-最近邻也是一种用来进行预测的算法。</p>

<p><strong>工作原理：</strong></p>

<p>接受一个用以进行数值预测的新数据项，然后将它与一组已经赋过值的数据项进行比较。算法会从中找出与待预测数据最为接近的k项，并这k项其求均值以得到最终的结果。</p>

<p>&nbsp;</p>

<p>总计来说这是一个很简单的算法，只要我们做好距离的定义并选择一个适合的k值，我们就可以很容易的实现它。</p>

<p>&nbsp;</p>

<p>由于我们计算2组数据的距离的通常方法是将他们中对应的每一项目的差值的绝对值(或平方)相加，所以就会出现不同数据范围不同导致的误差。比如每组数据有2个分量，一个取值为0&#8212;10,另一个是0&#8212;-999999，那么第二的值就会几乎完全决定我们最后的结果。所以我们要对每一组数据进行缩放。</p>

<p>&nbsp;</p>

<p>对数据的缩放取决于具体的应用，我们可以通过交叉验证尝试多组缩放因子然后比较它们的优劣。交叉验证的做法是先数据的一部分去除，然后用剩余数据去推测这组数据，我们就可以根据预测的结果对缩放因子进行评估。</p>

<p><strong>&nbsp;</strong></p>

<p><strong>优点：</strong></p>

<p>能利用复杂函数进行数值预测，又简单易懂，并且我们可以很容易的在算法中实现查看用哪些近邻进行预测。</p>

<p><strong>缺点：</strong></p>

<p>每次进行预测，它都会使用所有样本，这会导致效率的低下。</p>

<p>寻找缩放因子是一项很乏味的工作.</p>

<p>&nbsp;</p>

<p><strong>聚类：</strong></p>

<p>聚类算法可以用于任何具有一个或多个数值属性的数据集合，通过这些数值属性，我们将其所有数据映射到一个n维空间中，并定义该空间中的距离，然后我们可以通过各个数据间的距离对其实现聚类。</p>

<p><strong>分级聚类:</strong></p>

<p>分级聚类的算法是不断找出所有数据中距离最小的两个数据A、B，然后将它们合并成一个新的节点，该节点在n维空间中的坐标是原来两数据点的均值，通过不断进行这一操作，我们最终可以得到一个树形的层级结构。</p>

<p align="center">
  &nbsp;
</p>

<p><strong>K-</strong><strong>均值聚类:</strong></p>

<p>不同于分级聚类，K-均值聚类的目的是将数据拆成K个不同的群组，其具体算法如下：</p>

<ol>
<li>在n维空间中随机生成K个中心点</li>
<li>将每个数据项分配给与其距离最近的中心点。</li>
<li>将中心点位置移动到所有分配给它的数据项的中心。如果中心点位置没有改变，则结束算法，否则回到第二步。</li>
</ol>

<p align="center">
  &nbsp;
</p>

<p>具体选择哪种聚类算法取决于要处理的问题，当要将数据拆分到不同的群组时，k均值聚类往往是很有价值的，而如果我们更想了解哪些群组间更为接近，分级聚类更好。当然，我们也可以同时使用２种算法得到更加详细的信息。</p>

<div>
  <embed id="lingoes_plugin_object" width="0" height="0" type="application/lingoes-npruntime-capture-word-plugin" hidden="true" />
</div>

<p>{{ template &ldquo;_internal/disqus.html&rdquo; . }}</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://luosha865.github.io/archives/17">
        统计,逻辑与智能
      </a>
    </h1>

    <span class="post-date">Thu, Sep 10, 2009</span>

    <p>&nbsp; &nbsp;&nbsp;&nbsp; 今天上了开学的第一节统计学，开了很久的小差，想了不少东西。</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;以前虽然自学过概率论与数理统计，但是也只是了解了一些公式与原理，一直对于统计学的一些应用不甚理解(或者说不能接受)，尤其是基于统计的机器学习，一直不能接受它作为一种实现的人工智能的手段。因为我心中的人工智能是绝对理性，严谨，逻辑的。虽然我可以接受统计学的理论，却不能把它作为一种严谨的逻辑。</p>

<p>　 但是，今天突然想到了感性，是的，人是理性的，但是人的思维中也充满了感性的，当然，这是早已熟知的事实。</p>

<p>　 先给感性下一个定义吧。</p>

<p>　 感性：作用于人的感觉器官而产生的感觉，知觉和表象等直观认识，相对与&lsquo;理性&rsquo;&rdquo;</p>

<p>　 是的，感性一种直观的认识，那么这种认识从哪里来呢？过去的经验。人们的感性是在经验的基础上建立的，是一种仅仅由经验得出而没有任何逻辑背景的判断。</p>

<p>　 统计学不也是这样么？将大量的样本作为过去的经验，仅仅由这些经验而不带任何逻辑推断的去快速做出一种&ldquo;感性&rdquo;的判断。只是这种感性比人的感性更加严谨，不会受到类似&ldquo;小概率事件经常发生&rdquo;这种错觉的影响，但也可以算是一种理性的感性了。</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对应的，我又想起了逻辑学，如果统计是根据经验快速简单的做出判断的话，那么逻辑学就是通过严谨的逻辑推理去寻找正确的答案，这个过程会很繁琐，但是它使绝对严谨理性的，比我们的大脑更加严谨，理性&#8212;&#8212;那何不把它看成一种是理性的理性呢？</p>

<p>&nbsp; &nbsp;&nbsp; 但是仅仅有统计与逻辑，我们无法建立一个系统，因此也许还需要一个驱动吧？在完成一个任务、解决一个问题时，这个驱动不断的让感性提供可能解，然后让理性验证它&#8212;&#8212;突然我发现，这不就是&ldquo;启发式搜索&rdquo;所作的事情么？</p>

<p>&nbsp;&nbsp;&nbsp; &nbsp;以前翻过一些人工智能的书，总是觉的虽然那些方法可以达到目的，但是却没有触及到智能的本质，因此总是有些失望的，可是现在，我释然了。什么是智能的本质？好像是在《与众不同的心理学》这本书上，我看到过类似问题(也许问得是别的什么，不过差不多)。书里说，这是不可验证的，如果我们甚至不能解释，验证它，我们为什么可以凭借自己的主观推断去确定一个机器是否拥有智能？我们凭什么可以认为，这些机器，当他们把现在这些技术发挥到一定程度后就不可以拥有智能？也许我们自己的自我认知也只是一种数学的算法对自身产生的作用呢？（是不是有谁说过，这个宇宙，连同我们的存在，都只是一种错觉？记不清了&hellip;..不过看来这句话还是很有意思的。）</p>

<p>　 想到了这些之后，我对&ldquo;人工智能最难的是处理常识&rdquo;第一次有了很深的认同，以前总是不能充分认识常识的作用，但是如果直觉，经验在智能中占了如此重要的一部分，那么我们就必须去处理常识――其中的困难自然不用多说了。</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp; 最后，把我上课时写在书上的话记录下来吧：</p>

<p>&nbsp;&nbsp;&nbsp; &nbsp;统计学&#8212;以理性研究感性，我们的直觉从过去的经验去推导未来，这种推断不能解释结果的原因。（因为它在历史上倾向于如此，所以它很可能如此。）统计学将这种感性理性化，并出除了一些直觉上的错误（如：小概率事件经常发生），但其根本上还是一种感性的判断，因此解释这种感性推断背后的原因，事物呈现这种状态的原因，就是人的工作了。所以统计学也可以用来在没有线索时，作为一种&ldquo;事后诸葛亮&rdquo;式的推断的第一步（即先找出最可能答案，在设法解释它，不过这种方法具有不可证伪性，所以不是科学严谨的――毕竟是直觉么）。同时，统计的机器学习可以就可用来模拟人的直觉学习了（而且是一种没有错误的直觉）。</p>

<p>{{ template &ldquo;_internal/disqus.html&rdquo; . }}</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://luosha865.github.io/archives/18">
        算法总结4—支持向量机
      </a>
    </h1>

    <span class="post-date">Tue, Sep 8, 2009</span>

    <p>支持向量机&hellip;&hellip;复杂的东西，书里讲得也不怎么详细，起码具体算法没有说&hellip;&hellip;所以又去查了些资料&hellip;&hellip;</p>

<p>支持向量机是用来对数据进行分类的。</p>

<p>首先从最简单的情况开始吧：</p>

<p>如果有一条直线，我们把它看成一条数轴，上面有一些样本点，其中坐标大于某个值的点都属于一类，坐标小于某个值的点都属于一类，那么我们就可以用这个值来做分分界点，它点把直线上的点分为了两类。因为样本点是有限可数的。所以这个分类点的取法不唯一。选好后，随便给我们一个点，我们就可以根据这个随机给出的点是在分界点的左侧还是右侧来判断这个点的类别。</p>

<p>同样，一个平面上有很多样本点，这些点也分为2类，如果我们在平面上可以找到这样一条直线满足这两类样本点分别分布在直线的两侧，那么我们就可以用这个平面作分界面，来对之后随机给出的点进行分类。</p>

<p>仍然用同样的方法，我们可以用一个平面给分布在一个3维立体空间中的点分类。</p>

<p>总结起来就是说：在n维空间中有很多样本点，如果我们能找到一个n-1维的超平面，这个平面恰好把空间中的样本点分在它的两侧，那么我们就可以用这个n-1维的超平面来对之后随机给出点分类。</p>

<p>这种方法有两个问题：</p>

<p>1）&nbsp; 因为那个n-1维的超平面选法往往是不唯一的，我们要选哪一个?</p>

<p>2）&nbsp; 更多情况下，我们找不到这样一个n-1维超平面，你可以想象更多情况下，我们要分类的数据是&ldquo;混合&rdquo;在一起的，很难简单的用一个点，一条线，或者一个更高纬度的线性分类器把它分开。</p>

<p>接下来我们就要来解决这个问题。</p>

<p><strong>最优超平面的确定:</strong></p>

<p>如果选择合适的分界超平面呢？直观的来说，我们因该选择一个距离两组数据&ldquo;最远&rdquo;的超平面。首先每个点都和这个超平面有一个距离（该距离可以通过把n维空间放入一个n维坐标系后用代数的方法计算出来，具体计算过程此处就不说了。不过1维２维３维的情况你应该能自己算出来吧～～～，理解就好）我们选择的超平面要让所有这些距离中最小的一个值最大。</p>

<p>我们在n维空间空建立一个n维坐标系</p>

<p>在这个n维坐标系中，每个n-1维超平面都可一个用一个方程表示出来，这里设为。</p>

<div>$$H(x)=a_{0}+\sum_{i=1}^{n}(a_{i}*x_{i})$$</div>

<p>我们用一个变量Y表示一个点相对超平面的关系，在一侧为1.另一侧为-1.</p>

<p>可以证明:（证明过程略）</p>

<p>该平面在满足下面的约束时：</p>

<div>$Y_{i}H_(x_{i})\geq 1$</div>

<p>极小化函数</p>

<div>$\frac{1}{2}\sum_{j=1}^{n}(a_{j}^{2})$</div>

<p>这是一个二次规划问题，我们对它求解就可以得到最优平面。</p>

<p>有时我们找不到这样一个超平面，这时，我们可以把超平面的约束条件放的宽松一点，也就是在超平面附近允许两种分类的点的重叠，可以同过把改为（e&gt;0）来实现这一目的。</p>

<p>（具体证明与求解参考《统计学完全教程》 科学出版社 P290的支持向量机一节）</p>

<p>&nbsp;</p>

<p><strong>第二个问题的解决&#8212;</strong><strong>核方法</strong></p>

<p>很多时候，我们是找不到一个简单的超平面对样本进行划分的，这个时候，我们可以通过坐标变换，把样本点映射到一个可以线形划分的空间中。</p>

<p>这个映射可以是同维度的，即映射前后样本空间的纬度相同，比如：</p>

<p>&nbsp;</p>

<p><img src="http://pic002.cnblogs.com/images/2012/52809/2012063021394557.jpg" alt="" /></p>

<p align="center">
  &nbsp;
</p>

<p>就可以通过一个简单的<strong>求平方</strong>运算，把数据从线性不可划分变为线性可分&#8212;我们可以很容易的找到一条直线把后者的样本点分成两个部分。</p>

<p>但是很多时候，问题没有这么简单，我们就需要用另外一种映射，即把样本点映射到更高纬度的空间去。</p>

<p>比如上面的左图还可以做这么一种变换：</p>

<p>z1=x1*x1, z2=sqrt(2)x1*x2&nbsp; (sqrt(2)是指2的平方根)　,z3=x2*x2　　</p>

<p>这样我们就可以在新的样本空间中很简单的找到一个平面把这些点分开了．仔细分析，你可以发现，这个平面其实是左图中的一个椭圆的经过上述变换后得到的．</p>

<p><strong>较高维空间的线性分类器对应于原空间的一个非线性分类器．</strong></p>

<p>这就是<strong>核方法</strong>的核心。</p>

<p>通过找到一个合适的映射，我们就可以前面的问题(2)了</p>

<p>这种映射称为核函数，核函数的选择是很有技巧的，它也有一些常见的模型，很多时候我们只要选择合适的模型并计算适当的参数就可以了。具体方法这里不说了，有兴趣的可以参见《<a href="http://download.csdn.net/source/1353188">RBF核函数的支持向量机参数选择</a>》一文。</p>

<p>找到核函数后，我们就完全解决上述问题了。</p>

<p>（其实这里还有一些简化计算的技巧，这些技巧与其它更具体的东西还是可以去看《统计学完全教程》 科学出版社，真是一本非常强大的书。）</p>

<p>&nbsp;</p>

<p><strong>优点:</strong></p>

<p>可以很快的判断一个样本的种类。</p>

<p><strong>缺点:</strong></p>

<p>由于对每个数据集的最佳核变换及相应参数都不一样，所以对每个数据集都要重新学习确定函数与参数。</p>

<p>一般而言，支持向量机更适合包含大量数据的问题，而其他方法如决策树，更适合小规模的数据集。</p>

<p>支持向量机也是一种黑盒技术，由于存在像高维空间的判断，我们很难解释分类的具体标准与原因。</p>

<div>
  <embed id="lingoes_plugin_object" width="0" height="0" type="application/lingoes-npruntime-capture-word-plugin" hidden="true" />
</div>

<p style="margin:0;padding:0;height:1px;overflow:hidden;">
  <a href="http://www.wumii.com/widget/relatedItems" style="border:0;"><img src="http://static.wumii.cn/images/pixel.png" alt="无觅相关文章插件，快速提升流量" style="border:0;padding:0;margin:0;" /></a>
</p>

<p>{{ template &ldquo;_internal/disqus.html&rdquo; . }}</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://luosha865.github.io/archives/19">
        算法总结3—神经网络
      </a>
    </h1>

    <span class="post-date">Mon, Sep 7, 2009</span>

    <p><strong>生物神经网络：</strong></p>

<p><strong>&nbsp;&nbsp;&nbsp;&nbsp;</strong> 在生物的神经网络中的基本单位是神经元，神经元与神经元之间是由突触的相互联系来传递信息的，在静止息状态时，神经元的膜的内外电压保持一种稳定状态（膜内电压低于膜外电压），当神经元受到刺激后，在被刺激的部分周围，这种平衡状态会被打破，电压改变，与没有受到刺激的部分形成电流传递信息，电流的强弱取决于受刺激部位电压的改变量。</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp; 前一个神经元的轴突末梢作用于下一个神经元的胞体、树突或轴突等处组成突触。不同的轴突末梢可以释放不同的化学物质对下一个神经元产生不同的影响。也就是说会使下一个神经元的受刺激部分产生不同的电压，也就导致了不同程度的电流，最终也就传递了完全不同的信息。</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp; 一个神经元可以通过轴突作用于成千上万的神经元，也可以通过树突从成千上万的神经元接受信息。当多个神经元同时对一个神经元产生作用时，结果这些神经元的作用强度共同决定。</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp; 神经系统按功能可大致分为传入神经（感觉神经）、中间神经（脑：延脑、脑桥、小脑、中脑、间脑、大脑脊髓）与传出神经（运动神经）三类。</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp; 感受神经的作用是接受外界信息（输入），中间神经则起到了信息传递与计算分析的作用，最用，传出神经会负责对外界信息作出相应的反应（输出）。</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp; 模仿这一过程，我们就可以建立人工神经网络。</p>

<p><strong>&nbsp;</strong></p>

<p><strong>人工神经网络：</strong></p>

<p><strong>&nbsp;&nbsp;&nbsp;&nbsp;</strong> 人工神经网络的基本单位是人工神经元（以下简称神经元）。一个神经元可以有多个输入，每个输入有一个相应权值。</p>

<p>图示如下：</p>

<p><img class="alignnone  wp-image-125" src="http://upload.wikimedia.org/wikipedia/commons/9/97/Ncell.png" alt="nn" /></p>

<p>a1~an为神经元的输入值</p>

<p>w1~wn为神经元各个的输入所拥有的权值</p>

<p>b为偏移量</p>

<p>sum对各个输入与其权值的积求和(含偏移量)。</p>

<p>f为传递函数，接受sum的输出，通过一个函数变换，输出t</p>

<p>t为神经元输出</p>

<p>数学表示 t=f(WA&#8217;+b)</p>

<p>W为权向量</p>

<p>A为输入向量，A&#8217;为A向量的转置</p>

<p>b为偏移量</p>

<p>f为传递函数</p>

<p>&nbsp;</p>

<p>在人工神经网络中，神经元之间相互连接，在连接点将前者的输出作为后者的输出，形成错综复杂的网状结构，进行信息的传递与计算。</p>

<p>&nbsp;</p>

<p>我们这里要介绍的是其中比较简单的一种模型，称为&ldquo;多层感知机（MLP）&rdquo;网络。</p>

<p>为了简化模型，我们假设偏移量b=0.</p>

<p>多层感知机网络由3部分组成：</p>

<p>输入层：功能类似感受神经，每个节点接受外界的直接输入。这里的模型中，每个节点接受单一输入，权值为1。</p>

<p>输出层：功能类似运动神经，该层输出就是神经网络的输出。</p>

<p>隐藏层：是输入层和输出层之间的多层神经网络，可以有1或多层。</p>

<p>因此，MLP网络中至少有3个层次。</p>

<p><img class="alignnone  wp-image-125" src="http://pic002.cnblogs.com/images/2012/52809/2012063021381464.jpg" alt="mlp" /></p>

<p align="center">
  &nbsp;
</p>

<p>&nbsp;</p>

<p>这些层次中，每层的每个神经元的输出都会作为下一层的每个神经元的输入，因此当我们对输入层进行输入后，该信息会一层层传递下去，最终从输出层输出。</p>

<p>&nbsp;</p>

<p>神经网络建立后，我们需要设法确定每个神经元的各个输入的权重w，并选择合适的函数f对输入进行变换，只有完成以上工作后，我们才能使用神经网络完成相应的工作。</p>

<p>&nbsp;</p>

<p>我们一般会选择过关于源点对称的S形函数作为函数f，该种函数特点是:输入接近0时，函数对输入的变化有敏感的反应，这一敏感度将随输入绝对值的增大而下降，最终趋于0。</p>

<p align="center">
  &nbsp;
</p>

<p><strong>权重的获取：</strong></p>

<p>选择合适的函数后，我们就要去确定各权重w了，权重的选择取决于我们想要神经网络完成的任务，我们首先会给每个输入一个初始化的默认值，该值可任意选取。</p>

<p>完成初始化后，我们就要开始训练神经网络了，即给神经网络大量的已知的正确的输入及其对应的输出，神经网络会将自己得到到的输出与正确输出向比较，然后根据某一算法调整自身的权重，使自身输出更接近正确答案。</p>

<p>我们这里要介绍的调整算法称为<strong>反向传播法</strong>，因为该算法是沿网络反向调整权值的。</p>

<p>这一算法中，我们会分析输出与正确答案，并将将输出向正确答案推进，为了了解如何推进，我们需要一个函数来计算函数f的斜率，设该函数为g。根据该函数，我们可以计算sum因改变的值。</p>

<p>整个算法如下：</p>

<p>从后向前对输出层和所有隐含层：</p>

<p>1）&nbsp; 计算节点当前输出与期望结果的差值d。(期望结果t &ndash; 实际输出 y)</p>

<p>对输出层: t在输入训练数据时一同输入。</p>

<p>对隐含层: t = sum ( 前一层的每个节点的差值di * 这两个节点间连线的权值 )</p>

<p>2）&nbsp; 利用函数g确定函数f在节点输出值y处的改变速率v。v=g(y)</p>

<p>3）&nbsp; 改变每个输入链接的权值，其改变量与链接的当前输入强度与学习速率rate（自己定义的属于(0,1)的常量）成正比。</p>

<p>（每个wi的改变量为（v*d*rate*输入ai））</p>

<p>这样一层层的从后向前反推，最终完成对一个训练样本的学习。</p>

<p>&nbsp;</p>

<p>当对所有样本完成训练后，我们就可以使用这个神经网络了。</p>

<p>比如，我们想用神经网络模拟一个数学函数，我们先向网络提供大量的正确的输入输出进行训练，然后就可以用神经网络作模拟这个函数进行计算了。</p>

<p>&nbsp;</p>

<p><strong>优点：</strong></p>

<p>神经网络可以处理复杂的非线性函数，发现不同输入的隐含关系。</p>

<p>神经网络也允许增量式训练，并且不需要大量的空间保存数据模型。</p>

<p><strong>缺点：</strong></p>

<p>神经网络只能接受数值输入输出，因此我们在处理非数值数据时，必须以一种方法把其每个取值映射到一个数值上。</p>

<p>神经网络是一种黑盒方法，这使得我们无法得知其处理输入和输出的方法与原因，尤其是较大的神经网络有数百的节点和上千的连接，更是如此。</p>

<p>在训练神经网络时，在选择训练数据的比例及与问题相适应的网络规模方面，没有明确的 规则。如果训练数据比率太大，可能导致网络对噪音数据产生过度归纳，而训练比率太低，网络就不够精准。</p>

<p>{{ template &ldquo;_internal/disqus.html&rdquo; . }}</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://luosha865.github.io/archives/20">
        算法总结2—决策树分类器
      </a>
    </h1>

    <span class="post-date">Sun, Sep 6, 2009</span>

    <p><strong>数学基础：</strong></p>

<p>树：树是一种数据结构，它是由n（n&gt;=1）个有限结点组成一个具有层次关系的集合。把它叫做&ldquo;树&rdquo;是因为它看起来像一棵倒挂的树，也就是说它是根朝上，而叶朝下的。它具有以下的特点：</p>

<p>每个结点有零个或多个子结点；</p>

<p>每一个子结点只有一个父结点；</p>

<p>没有前驱的结点为根结点；</p>

<p>除了根结点外，每个子结点可以分为m个不相交的子树；</p>

<p>没有子节点的节点称为叶节点。</p>

<p>&nbsp;</p>

<p><strong>决策树分类器原理：</strong></p>

<p>决策树是一颗树，要分类的样本从树根进入，在树的每个节点通过对样本的某种属性的判断选择不同的路径逐步下降到底,得出其所属类别。</p>

<p>例图:</p>

<p><img src="http://pic002.cnblogs.com/images/2012/52809/2012063021362216.jpg" alt="" /></p>

<p align="center">
  &nbsp;
</p>

<p>为了建立一棵决策树,我们首先应向程序输入大量训练数据(包含所属类别的数据)，程序将根据训练数据按某一算法自动生成决策树。</p>

<p><strong>&nbsp;</strong></p>

<p><strong>决策树生成算法:</strong></p>

<p>&nbsp;&nbsp; 为了构造决策树，算法首先创建一个根节点，然后通过分析训练数据，逐步选出适合的变量对数据进行拆分(即逐步构造上图中的非叶子节点。)</p>

<p>&nbsp;&nbsp; 为了选择适合的变量对数据进行拆分，我们需要一个方法来评估一种拆分方案的好坏，<strong>其评估方法包括：</strong></p>

<p><strong>1)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</strong> <strong>基尼不纯度：</strong></p>

<p>定义：基尼不存度是指来自集合的某种结果随机应用于集合中某一数据的预期误差。（如果集合中所有结果属于同一类，则误差为0）</p>

<p>使用：利用这一思想，我们可以将集合中每种类别的数据出现的次数除以数据总数计算相应概率，再将这些概率的乘积相加（所有概率两两相乘后在相加），这样就会得到某一数据被随机分配到错误结果的总概率。</p>

<p>伪代码：</p>

<p>imp=0</p>

<p>for &nbsp;k1 in kinds</p>

<p>p1=count(k1) / total</p>

<p>for k2 in counts</p>

<p>&nbsp;&nbsp; if (k1==k2)continue</p>

<p>&nbsp; &nbsp;p2=count(k2) / total</p>

<p>&nbsp;&nbsp; imp+=p1*p2</p>

<p>&nbsp;&nbsp;&nbsp; ans=imp</p>

<p align="left">
  &nbsp;&nbsp; (p1*p2是一个p1类别的数据被当作p2的概率)
</p>

<p>2)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>熵：</strong>在信息论中，熵代表的是集合的无序程度&#8212;&#8211;基本上就相当于我们在此处所说的集合的混杂程度。</p>

<p>熵的值是遍历所有结果后得到的pi*log2(pi)的和的绝对值</p>

<p>伪代码：</p>

<p>ent=0.0</p>

<p>for k in kinds</p>

<p>p=count(k) / total</p>

<p>ent=ent &ndash; p*log2(p)&nbsp;&nbsp;&nbsp;&nbsp; // 因为0&lt;p&lt;=1，所以必有log2(p)&lt;=0</p>

<p>ans=ent</p>

<p>&nbsp;</p>

<p>有了上述评估方法后，我们就可以不断尝试各种拆分方法，然后选出最好的拆分方法构造树中的节点了。我们将计算拆分前的熵（基尼不存度）值，与拆分后的熵（基尼不存度）的值的加权平均，将其差值作为<strong>信息增益</strong>。最终对能得到最大信息增益的属性进行拆分。然后再分别对拆分后得集合选择属性进行拆分，直到最大信息增益为非正时停止拆分，这时决策树就构建完毕了。</p>

<p>&nbsp;</p>

<p><strong>优化：</strong></p>

<p>为了防止决策树变的过度拟合（过度针对训练数据），我们可以在信息增益小于某个值后就停止拆分。但是我们可能遇到这样的数据―――某次拆分信息增益很小，但下一次就会很大。为了防止这一状况，我们可以在用先前的方法构造整棵树后，在尝试消除多余的节点。这个过程就是<strong>剪枝</strong>。</p>

<p>剪枝的过程就是对具有相同父节点的节点进行检查，判断将其合并后，信息增益是否会小于某个指定发值。若是，则合并这些节点。合并后节点包括所有可能的结果值。</p>

<p><strong>在处理数值型数据时，熵和基尼不存度并不是一个好的选择，因为有些数值相差很近，有些相差很远，不能简单用是否为同一类别进行判断。所以我们可以用方差代替它们。</strong></p>

<p>&nbsp;</p>

<p><strong>决策树对缺失数据的处理：</strong></p>

<p>当我们要判断类别的样本缺少某些决策树作判断时必须的数据时，我们可以选择同时走两个分支，不过我们不是平均统计各分支的结果值，而是进行加权统计。为了达到这一目标，决策树中每个节点都有一个值为１的权重，即观测数据对于数据向是否属于某个特定分类的概率具有１００％的影响，而如果走多个分支，我们将给每个分支一个权重，其值等于所有位于该分支的其他数据所占的比重。</p>

<p>&nbsp;</p>

<p><strong>优点：</strong></p>

<p>决策树最大的优势是它可以轻易对一个受训模型给予解释。（解释分类原理）</p>

<p>决策树可以同时接受分类型和数值型数据。</p>

<p>比起贝叶斯分类器（参考<strong>[&lt;集体智慧编程&gt;算法总结1&mdash;贝叶斯分类器][2]</strong>）决策树可以更好的处理变量间的相互影响。</p>

<p><strong>缺点：</strong></p>

<p>决策树无法单独对某一数据进行训练。</p>

<p>面对有大量可能结果的数据集时，决策树不够有效。当可能的分类结果较多时，决策树就会过度复杂，预测效果也会较差。</p>

<p>另外，决策树不适合处理大量的数值型输入输出，因为它只能创建一些简单的&gt; ，&lt;，＝等节点，但数值之间可能存在更多更复杂的关系。</p>

<p>&nbsp;</p>

<p>呼&hellip;.这个写的不怎么累了&hellip;.很多都是书上的原话哈，不像昨天那个几乎都是自己写的&hellip;&hellip;</p>

<p style="margin:0;padding:0;height:1px;overflow:hidden;">
  <a href="http://www.wumii.com/widget/relatedItems" style="border:0;"><img src="http://static.wumii.cn/images/pixel.png" alt="无觅相关文章插件，快速提升流量" style="border:0;padding:0;margin:0;" /></a>
</p>

<p>{{ template &ldquo;_internal/disqus.html&rdquo; . }}</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://luosha865.github.io/archives/21">
        算法总结1—贝叶斯分类器
      </a>
    </h1>

    <span class="post-date">Sat, Sep 5, 2009</span>

    <p>&nbsp;这几天以很快的速度翻完了&lt;集体智慧编程&gt;,因为只是对里面的算法感兴趣,对那些web2.0的应用没什么感觉,所以很多地方都是一扫而过,现在按最后一章的顺序来对所有相关的算法作一个详细的复习&hellip;.</p>

<p>这个是第一篇&hellip;&hellip;贝叶斯分类器</p>

<p><strong>数学基础：</strong>**</p>

<p><strong>条件概率</strong>**</p>

<p>定义：设A, B是两个事件，且P(A)&gt;0 称P(B∣A)=P(AB)/P(A)为在条件 A下发生的条件事件B发生的条件概率。</p>

<p><strong>乘法公式</strong></p>

<p>设P(A)&gt;0，则有P(AB)=P(B∣A)P(A)</p>

<p><strong>全概率公式和贝叶斯公式</strong></p>

<p>定义 设S为试验E的样本空间，B1, B2, &hellip;Bn为E的一组事件，若BiBj=Ф, i&ne;j, i, j=1,</p>

<p>2, &hellip;,n; B1&cup;B2&cup;&hellip;&cup;Bn=S则称B1, B2, &hellip;, Bn为样本空间的一个划分。</p>

<p><strong>定理</strong></p>

<p>设试验E的样本空间为，A为E的事件，B1, B2, &hellip;,Bn为的一个划分，且P(Bi)&gt;0</p>

<p>(i=1, 2, &hellip;n)，则P(A)=P(A∣B1)P(B1)+P(A∣B2)+ &hellip;+P(A∣Bn)P(Bn)称为全概率公式。</p>

<p><strong>定理</strong></p>

<p>设试验E的样本空间为S，A为E的事件，B1, B2, &hellip;,Bn为的一个划分，则P(Bi∣A)=P(A∣Bi)P(Bi)/&sum;P(B｜Aj)P(Aj)=P(B｜Ai)P(Ai)/P(B)称为贝叶斯公式。</p>

<p>说明：i，j均为下标，求和均是1到n</p>

<p><strong>贝叶斯分类器原理：</strong></p>

<p>通过某些特征对不同的内容进行分类。</p>

<p><strong>特征的定义</strong></p>

<p>任何可以用来判断内容中具备或缺失的东西。如要对文档进行分类时，所谓的内容就是文档，特征就是文档中的单词(当然你也可以选择其他合理的东西)</p>

<p>当向贝叶斯分类器输入一个要进行分类的样本后，分类器会先对该样本进行分析，确定其特征，然后将根据这些特征时，计算样本属于各分类的概率。</p>

<p>朴素贝叶斯分类器的具体工作步骤：</p>

<p>1) 学习：向分类器输入一系列的训练数据，注意这些数据是包括其所属类别的，分类器将对训练数据进行分析，计算出</p>

<p>1.各个特征在各个分类中出现的概率(=某分类中具有该特征的数据数目 / 该分类数目)如先计算出各个单词在各种分类的文档出现的概率。</p>

<p>将该概率作为某分类下某特征出现的条件概率P(feature | category)</p>

<p>2.任选一个样本属于某分类的概率(=某分类文章数 / 文章总数)</p>

<p>记该概率为p(category)</p>

<p>在朴素的贝叶斯分类器中，我们假设将要组合的各个概率相互独立(当然，很多时候并非如此。我们有时会发现，当样本拥有某一特征时，则它就更可能拥有另一项特征。)</p>

<p>2)分类计算：在向分类器提供大量学习数据后，我们就可以用它对新的样本进行分类了。</p>

<p>首先对样本进行分析，找出其具有的各种特征，利用这些特征，我们来计算各个分类中出现该样本的概率p(sample</p>

<p>| category)。为了完成这一计算，我们只要简单将该分类下在该文档中出现过的特征出现的条件概率相乘即可。即&pi; (P(feature | category) 这里的feature是该样本拥有的所有特征。</p>

<p>但是，我们实际要计算的是P (category | sample),即给定样本属于某分类的条件概率。</p>

<p>这里，就用到了贝叶斯定理：P(A | B)=P(B | A)P(A) / P(B)</p>

<p>这里就是：P(category | sample)= P(sample |</p>

<p>category)P(category) / P(sample)</p>

<p>其中，P(sample | category)P(category)都已经在学习中计算得到，而P(sample)是样本出现 的概率，我们可以计算它，但是这是没有意义的，因为我们会计算出各个分类的条件概率，然后比较它们的大小确定样本所属的分类，而对各个条件概率而言p(sample)是完全一样的。所以，我们就省去了对它的计算。</p>

<p>这样，我们就可以确定一个样本的具体分类了。</p>

<p>当然，以上算法是有很多改进的，比如对各分类定义一个最小阀值，一旦没有达到任一分类的阀值，则归属为未知。</p>

<p>另外，针对朴素的贝叶斯分类器的缺点，还有很多其他的计算方法，如费舍尔方法。</p>

<p><strong>费舍尔方法</strong>为文档中的每个特征都求得了分类的概率，然后又将这些概率组合起来，并判断其是否有可能构成一个随机集合。该方法还会返回每个分类的概率，这些概率彼此间可以进行比较。尽管这种方法更为复杂，但是因为它在为分类选择临界值（cutoff）时允许更大的灵活性，所以还是值得一学的。</p>

<p>不同于之前计算的P(feature | category)，费舍尔方法将计算P(category | feature)，即拥有某一特征的样本属于某分类的概率。首先用P(具有指定特征的属于某分类的样本数 |具有指定特征的样本数)作为这一概率，然后将特征出现在所有所有分类中的概率fresum=&sum;P(category | feature),最后用P(category | feature) / fresum作为新的P(category</p>

<p>| feature)。(这样修正后的值将比修正前更加有效)</p>

<p>然后，我们就可以通过将各个特征的概率组合起来得到待分类样本所属的类别了。我们可以通过简单的相乘完成这一目的，虽然这里也作了相互独立的假设，但也比之前号上很多了。费舍尔方法的计算方法是将所有概率相乘后取自然对数，在乘以-2.</p>

<p><strong>优缺点：</strong></p>

<p>朴素的贝叶斯分类器最大的优势是他在接受大量数据训练和查询时的高速度。尤其当训练量递增时更是如此(我们可以分多次的对其进行学习的训练，而一些其他的方法如决策树和支持向量机要一次传送整个训练数据集)</p>

<p>另一个优点是，其对分类器的学习情况有着比较简单的解释，我们可以简单的通过查询学习时计算的一些概率值来了解其分类原理。</p>

<p>朴素的贝叶斯分类最大的缺陷是它无法处理特征符合所产生的变化(即前面提到过的实际上难以满足的相互独立)</p>

<p>终于写完了&hellip;好累啊&hellip;还有8个算法&hellip;&hellip;</p>

<p>{{ template &ldquo;_internal/disqus.html&rdquo; . }}</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://luosha865.github.io/archives/22">
        读《你的灯亮这么》—走出问题的乌托邦
      </a>
    </h1>

    <span class="post-date">Tue, Aug 25, 2009</span>

    <p align="left">
  军训期间闲着无聊时,决定读一些&ldquo;杂书&rdquo;，其中有一本叫《你的灯亮着么?》的小册子，刚读完不久，趁着今晚休息的时间作以记录。
</p>

<p align="left">
  <strong>1)</strong><strong>动手解决问题前，好好想想问题的来源。2)如何从各个角度看待问题，找到其真正所在。3)为什么不要把人们的解决方法误以为是问题的定义，更不要把某个问题的解决方法误认为是问题的定义，特别是整个解决方法是你自己所使用的。4)永远不要肯定你已经有了一个正确的定义，即使是在问题好像已经解决之后。5)每一种解决方法都会带来新的问题。6)问题最难处理的部分恰恰是去意识到它们的存在。7)在理解问题前，至少要做好准别接受三种可能的出错情况。8)或许还可以改变问题的表述来获得不同的解决方法。9)当你沉迷于寻找问题的定义和解决方法时，不要忘记随时都回头看看，看看自己是不是已经迷路了&hellip;。10)当别人能很好的解决自己的问题时，千万不要越俎代庖。11)如果某人能够解决这个问题，但是他们并不会遇到这一问题时，那么你首先要做的就是让他们也感受一下问题。12)不管看上去如何，人们很少知道他们要什么，直到你给了他们所需要东西。13)甚至，事实上，并没有多少人真的希望他们的问题被解决。</strong>
</p>

<p align="left">
  以上摘自书中序言。
</p>

<p align="left">
  解决问题前，我们自然要先明确问题，比如问题的对象，问题的内容等等，虽然问题本身并不会有一个通俗简单的定义。但是书中的一种说法确实让人耳目一新&#8212;-&ldquo;<strong>问题就是你所期望的东西和你体验的东西之间的差别</strong>&rdquo;。对问题的定义是非常重要的―――同样是具有风险的，很多人在问题的定义中徘徊，因为他们不愿承担定义失误的风险。
</p>

<p align="left">
  作为一个问题的解决者，为了定义一个问题（当然，它并不唯一），我们可以利用经典的分治算法把一个问题变为一系列的问题。为了实现这一转变，我们需要去回答另外一些问题&#8212;比如&ldquo;谁有问题&rdquo;&ldquo;问题的本质是什么&rdquo;&ldquo;问题是谁引起的&rdquo;等等。
</p>

<p align="left">
  当我们做出了一个比较适合的定义后，我们就可以着手去解决它。由于&ldquo;问题就是你所期望的东西和你体验的东西之间的差别&rdquo;，我们可以从两个方面入手&#8212;-<strong>要么改变期望，要么改变体验</strong>。
</p>

<p align="left">
  要改变体验，有很多种方法，书中举例说&ldquo;很多人觉得等待电梯的时间太久&rdquo;―――&ldquo;那么我们的期望的就是更加快速有效的乘坐电梯，体验则是漫长的等待&rdquo;，而解决方法是―――&ldquo;在等待电梯的拐角放上一面镜子&rdquo;――――&ldquo;对着镜子整理衣着减少了人们体验到的时间&rdquo;。
</p>

<p align="left">
  你从例子中体验到了什么?我悟到的是&ldquo;<strong>体验!=(不等于)现实</strong>&rdquo;，我们可以在不对现实做出任何改变的同时，用某种手段改变人们的体验。
</p>

<p align="left">
  但是在解决这一问题后是什么呢?&#8212;-新的问题&#8212;有人在镜子上乱涂乱画！我们的问题解决者不得不继续想办法去解决它。
</p>

<p align="left">
  <strong>如果你想找到一个问题的解决方法，试试&ldquo;让情况变得更糟&rdquo;</strong>。基于这个原则，问题解决者把在镜子上涂画变成了一种娱乐的活动&#8212;效果是一样的，人们不会觉得电梯来得太慢了&#8212;他们甚至觉得来得太快了，不是么？
</p>

<p align="left">
  在结束这一章时，书中继续了那个很有趣的电梯的故事&#8212;&ldquo;在他们讨论解决问题时，曾经用说笑的口气提出过偷取隔壁大楼电梯使用时间的方法，但是被否决了。后来问题解决者发现隔壁大楼是一座百货商场，而且商场最近生意还不怎么样&#8212;他们巴不得有人去偷取他们的电梯时间呢！&rdquo;文中的结论是&ldquo;对那些没有幽默感的人，帮他们解决问题简直就是自寻烦恼&rdquo;（因为他对这个说笑口气提出的解决方案给予了严肃的批评），我觉得，这告诉我们，<strong>很多方案，我们并不能只从印象和表面去判断他是否可行&#8212;-因为那并不可靠。</strong>
</p>

<p align="left">
  然后是一个新的故事&#8212;-在这里不对那个故事进行复述了，我觉得这个故事中最重要的结论是&ldquo;<strong>不要把他们的解决方法误认为是问题的定义</strong>&rdquo;即是说，我们要自己去了解问题，而不要从别人那里&#8212;尤其是他们的解决方案那里得到问题的答案。很多时候我们试图从别人那里去得到问题的定义，但是那永远是局部的，这和我们在做题做不出时，会去重读题目一样&#8212;最原始的资料，虽然最难以使用，但却又是最为有效的。
</p>

<p align="left">
  另外一个结论是：<strong>如果你太轻易地解决了他们的问题，他们永远都不会相信你真的解决了他们的问题。</strong>
</p>

<p align="left">
  人总是过于自信的，这使他们不愿承认自己错误的估计了一个问题的难度。这使得我们有时为了解决一个问题，会浪费比解决问题更多的时间去说服哪些人&#8212;&#8211;为了避免这一点，我们必须在适当的时候承认自己的愚昧和无知。当然，倒过来想，绝大多数问题可以是简单的，只是我们用错了方法，走错了方向。仅此而已。
</p>

<p align="left">
  在下一个故事中，再次强调了以下的事实：
</p>

<p align="left">
  <strong>每一种解决问题的方法都会到来新的问题。我们永远都不能消灭问题。问题、解决问题的方法和新的问题编织成一条无穷无尽的锁链。在解决一个问题的时候，要找出至少三个可能出现的新问题，否则说明我们对于当前问题的理解还不够透彻。</strong>
</p>

<p align="left">
  另外：<strong>问题最难以处理的部分恰恰是去意识到它们的存在。</strong>如果我们能够意识到问题的存在，那么很多问题是很容易解决的。一个典型的例子是交通限速与交通事故的关系。当能源危机使美国限速减低到55英里时，交通事故大量减少。但是在这以前呢？我们常把原因归因与酒后驾车等问题,根本没有人意识到他们习以为常的交通限速根本就不合理！这是因为我们思维中的惯性的存在。因此，换一个身份进行思考，（孩子，外国人等等）也许你会对问题有一个全新的解读。因为很多我们习以为常的东西其实并不合理，或者说并不完美。
</p>

<p align="left">
  这也就代入了&ldquo;问题的表述&rdquo;的问题，不同的问题表述可以给我们不同的解决方案，同样会带来不同的新的问题。
</p>

<p align="left">
  &nbsp;只要我们记得对自己提问：&ldquo;<strong>我们要怎样改变问题的表述才能获得不同的解决方法？</strong>&rdquo;也许我们就能得到不同表述与答案。
</p>

<p align="left">
  一个简单的例子是一个简单的圆。我们可以问&ldquo;这个物体是什么?&rdquo;，也可以问&ldquo;这个常见的物体什么?&rdquo;&ldquo;这个不常见的物体是什么?&rdquo;你的答案一定会大不一样吧。
</p>

<p align="left">
  这里我又想到了一个加鸡蛋的故事：&ldquo;您要加鸡蛋么？&rdquo;&ldquo;您要加一个还是两个鸡蛋？&rdquo;这样提问的两家商店可以有着完全不同的营业额。
</p>

<p align="left">
  提问的内容与方法确实可以制约到人的思维，进而控制了我们的答案。
</p>

<p>这其实是一种文字游戏。</p>

<p>有时我们可以利用它，有时我们却要减少文字引起的不确定性，因此，一旦你用文字来表述一个问题，请仔细推敲这些文字以使这种表述在每个人的头脑中都是一个意思。</p>

<p>&nbsp;&nbsp;&nbsp; 另外，由于问题中存在的种种陷阱<strong>：</strong><strong>当你在寻找问题定义的道路上疲倦地游荡时，不要忘记随时都回头看看，看看你是不是已经迷路了。</strong></p>

<p align="left">
  又是新的故事。
</p>

<p align="left">
  如果一些人产生了问题，你最好不要随便的插干涉它&#8212;&ldquo;<strong>当别人能够很好地解决自己问题的时候，千万不要越俎代庖。</strong>&rdquo;因为外力的入侵或许会使问题产生一些我们事先没有想到的变化&#8212;-比如引入新的变量，改变问题的性质等等。
</p>

<p align="left">
  如果这是他们的麻烦，就让它成为他们的麻烦吧。
</p>

<p align="left">
  &nbsp;&nbsp; &nbsp;但是当你无法解决你所解决的问题而需要寻求帮助时，你也许会发现有人可以轻易的解决它。你要如何寻找帮助呢?威逼和利诱都不是最好的选择&#8212;-<strong>你只需要让他也感受到这一问题的存在。</strong>（当然，这不是永远有效的，因为也许那个人根本就不在乎，或者他会认为你是在给他捣乱！）
</p>

<p align="left">
  如果你用尽方法都行不通的话，<strong>为什么不试试指责你自己呢</strong>？人们倾向于在别人身上寻找问题，确不会降低自己的期望。还记得我们对问题的定义么&ldquo;问题其实就是你期望的东西和你体验的东西之间的差别&rdquo;除了改变体验外，降低期望同样是一种方法&#8212;-虽然你并不喜欢。但是事实是，很多问题的根源在你自己身上。
</p>

<p align="left">
  不得不提的是书中最经典的一个例子:在一个隧道的入口处有一个照牌&ldquo;警告：前有隧道请打开车头灯&rdquo;，那么隧道的出口呢？&ldquo;请关灯？&rdquo;如果是晚上呢？也许我们可以用非常麻烦的语法分析各种情况写出一个完美的招牌，但是谁会去读它？最简单的方法是&ldquo;如果这是他的问题，把问题留给他好了&rdquo;&#8212;简单的在牌子上写上&ldquo;<strong>你的灯亮这么</strong><strong>?</strong>&rdquo;&#8212;我们没有必要为所有人解决一个对每个人都很简单，组合起来确又非常复杂的问题，不是么？
</p>

<p align="left">
  最后，书中讨论了一个很奇怪的问题&ldquo;我们真的想解决问题么？&rdquo;虽然很奇怪，但是这种情况确实经常出现。也许你只是在享受问题解决过程的乐趣，也许你解决问题是为了否定它,谁知道呢?
</p>

<p align="left">
  最后的最后，是书中的最后说明的一句话：
</p>

<p>&nbsp; <strong>&nbsp;</strong><strong>&ldquo;首先，对自己要真诚。&rdquo;</strong></p>

<p><strong>&nbsp;&nbsp;</strong> <strong>&ldquo;</strong><strong>This above all</strong><strong>，</strong> <strong>to thine own self be true</strong><strong>。&rdquo;</strong></p>

<p>&nbsp;&nbsp;&nbsp; 在解决和定义一个问题前：&ldquo;道德是最为重要的&rdquo;</p>

<p align="left">
  &nbsp;
</p>

<p align="left">
  &nbsp;&nbsp;&nbsp; 虽然文章已经结束了，我还是想把书中一个很有趣的问题及解决与大家分享，这来自书的序篇。
</p>

<p align="left">
  序篇
</p>

<p align="left">
  问题：没有人会阅读序言
</p>

<p align="left">
  解决方法：把序言称为第一章
</p>

<p align="left">
  解决方法带来的新问题：第一章是单调沉闷的
</p>

<p align="left">
  再次解决：把第一章扔了，再把第二章称为第一章
</p>

<p>{{ template &ldquo;_internal/disqus.html&rdquo; . }}</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://luosha865.github.io/archives/23">
        ACM暑假集训总结
      </a>
    </h1>

    <span class="post-date">Wed, Aug 19, 2009</span>

    <p>ACM的暑假集训结束了，趁着军训还没开始，对整个暑假接触到的东西作了一个总结，因为刚参加ACM不久，所以内容大都比较基础吧，文章中提到了些参考资料，如果需要的话，请留下邮箱。</p>

<p>目录</p>

<p>1)数据结构</p>

<p>1.并查集</p>

<p>2.高精度数</p>

<p>3.线段树</p>

<p>4.字典树&lt;未完成&gt;</p>

<p>2)常用算法</p>

<p>1.递推</p>

<p>2.动态规划</p>

<p>3.贪心</p>

<p>4.搜索</p>

<p>3)图论部分</p>

<p>1.2-SAT问题</p>

<p>2.差分约束系统</p>

<p>3.二分图</p>

<p>4.最短路(SPFA,Dijkstra)</p>

<p>5.欧拉回路&lt;未完成&gt;</p>

<p>6.最优比率生成树</p>

<p>7.关键路径</p>

<p>8.网络流(流的算法/应用)</p>

<p>最大流算法(3种)</p>

<p>最小费用最大流算法</p>

<p>图的连通性（最小点割集）&lt;未完成&gt;</p>

<p>混合欧拉回路</p>

<p>9.其他图论相关问题算法:</p>

<p>K短路</p>

<p>图的单向连通（包括2次DFS缩点）</p>

<p>4)其他</p>

<p>1.计算几何</p>

<p>2.数学(数论,组合数学,数值计算)</p>

<p>5)附录</p>

<p>1.A*算法</p>

<p>2.位运算之格雷码：</p>

<p>3.线性同余方程</p>

<p>一．数据结构：</p>

<p>1.并查集.</p>

<p>用于实现合并与查找两种操作的数据结构.</p>

<p>实现方法:线形数组,有根树.</p>

<p>优化:</p>

<p>把深度小的树合并到深度大的树. max(h1,h2), if h1&lt;&gt;h2. / h1+1, if</p>

<p>h1=h2.</p>

<p>合并操作时的路径压缩.</p>

<p>并查集的偏移向量:</p>

<p>并查集的偏移向量属于并查集的变形，只要适用于集合数目较少，或是固定的并查集类型。</p>

<p>增加一个offset字段,表示元素相对根的偏移量.</p>

<p>在 find函数中计算偏移量</p>

<p>int findset ( int x )</p>

<p>{</p>

<p>int t ;</p>

<p>if ( father [ x ] == x ) return x ;</p>

<p>else t = findset( father [ x ] ) ;</p>

<p>offset [ x ] = ( offset [ x ] + offset [ father [ x ] ] ) % DEPTH ;//DEPTH表示几个状态量</p>

<p>//如果1182中，DEPTH=3；</p>

<p>father [ x ] = t ;</p>

<p>return t ;</p>

<p>}//使用函数递归调用查找父亲在处理上优于循环。</p>

<p>union函数中计算偏移量</p>

<p>void union(int x,int y,int d){</p>

<p>int fx , fy ;</p>

<p>fx = find ( x ) ;</p>

<p>fy = find ( y ) ;</p>

<p>if ( fx == fy ) return ;</p>

<p>father [ fx ] = fy ;</p>

<p>offset [ fx ] = ( offset [ y ] &ndash; offset [ x ] + d +3 )</p>

<p>% 3 ;</p>

<p>}</p>

<p>2.高精度数</p>

<p>大数的加减乘除</p>

<p>小数的高精度计算参考pku1001</p>

<p>3.线段树</p>

<p>一棵二叉树，记为T (a,b)，参数a,b表示该节点表示区间[a,b]。区间的长度b-a记为L。递归定义T[a,b].</p>

<p>线段树能在O(logL)的时间内完成一条线段的插入、删除、查找等工作</p>

<p>应用举例</p>

<p>求面积:</p>

<p>1) 坐标离散化</p>

<p>2) 垂直边按x坐标排序</p>

<p>3) 从左往右用线段树处理垂直边</p>

<p>累计每个离散x区间长度和线段树长度的乘积</p>

<p>求周长:</p>

<p>1) 坐标离散化</p>

<p>2) 垂直边按x坐标排序, 第二关键字为入边优于出边</p>

<p>3) 从左往右用线段树处理垂直边</p>

<p>在每个离散点上先加入所有入边, 累计线段树长度变化值</p>

<p>再删除所有出边, 累计线段树长度变化值</p>

<p>4) 水平边按y坐标排序, 第二关键字为入边优于出边</p>

<p>5) 从上往下用线段树处理水平边</p>

<p>在每个离散点上先加入所有入边, 累计线段树长度变化值</p>

<p>再删除所有出边, 累计线段树长度变化值</p>

<p>参考资料: segment_tree.pdf</p>

<p>4字典树</p>

<p>用于多字符串匹配</p>

<p>加入KMP算法思想成为AC自动机.</p>

<p>二.常用算法</p>

<p>1.递推</p>

<p>f(n)与f(m) m&lt;N的关系</p>

<p>经典问题</p>

<p>约翰夫环的递推公式.</p>

<p>fib数（矩阵乘快速计算法）</p>

<p>参考&lt;具体数学&gt;第一章</p>

<p>2.动态规划</p>

<p>重叠子问题较多的问题</p>

<p>记录重叠子问题解得解</p>

<p>子状态的确定与状态转移函数.</p>

<p>3.贪心</p>

<p>在对问题求解时，总是作出在当前看来是最好的选择。也就是说，不从整体上加以考虑，它所作出的仅仅</p>

<p>是在某种意义上的局部最优解（是否是全局最优，需要证明）。</p>

<p>注意:若要用贪心算法求解某问题的整体最优解，必须首先证明贪心思想在该问题的应用结果就是最优解！</p>

<p>4.搜索</p>

<p>广度优先搜索，深度优先搜索。</p>

<p>双向广度优先搜索</p>

<p>启发试搜索(A*）（详细见附录部分）</p>

<p>搜索的减枝与优化</p>

<p>参考资料 搜索算法全集.pdf / 搜索.ppt / 启发式搜索.doc</p>

<p>三．图论部分</p>

<p>1.2-SAT问题</p>

<p>设B={b1,b2&hellip;bn}为一个有限布尔集变量，B&rsquo;={b1,b2,&hellip;bn,!b1,!b2,&hellip;，!bn}.(!为取反)设B2为B&rsquo;的非空子集,定义 ，对于给定的B1&rsquo;,B2&rsquo;&hellip;Bm&rsquo; B&rsquo;，求B，使得等式</p>

<p>成立，成为适应性问题，简称SAT。</p>

<p>当对给定的Bm，max{|Bx&rsquo;|}=k,我们就把这个问题称为k-适定性问题，简称k-SAT。</p>

<p>可以证明，当时，k-SAT是NP完全的。</p>

<p>(即每个集合都至少有一个成立)</p>

<p>2-SAT解法，构图法，对每个bx,!bx,都对应图中一个节点，共2n个节点，每个逻辑关系表示一条边，如pku2723：</p>

<p>1）对于一组相互排斥的钥匙 x，y，只能选一把，所以x &amp;y==0．　即 x &mdash;&gt;</p>

<p>~y ， y &mdash;&gt; ~x.。</p>

<p>2）对于门，因为必须打开所以 x|y==1.　即 ~x&mdash;&gt; y , ~y&mdash;&gt; x</p>

<p>参考资料：sat2_sjtu_zhaoshuang.pdf　/　2-SAT.PPT</p>

<p>2.差分约束系统</p>

<p>　比如有这样一组不等式：</p>

<p>X1 &ndash; X2 &lt;= 0</p>

<p>X1 &#8211; X5 &lt;= -1</p>

<p>X2 &#8211; X5 &lt;= 1</p>

<p>X3 &#8211; X1 &lt;= 5</p>

<p>X4 &#8211; X1 &lt;= 4</p>

<p>X4 &#8211; X3 &lt;= -1</p>

<p>X5 &#8211; X3 &lt;= -3</p>

<p>X5 &#8211; X4 &lt;= -3</p>

<p>全都是两个未知数的差小于等于某个常数（大于等于也可以，因为左右乘以-1就可以化成小于等于）。这样的不等式组就称作差分约束系统。</p>

<p>　　构图法:利用最短路中的三角不等式,即:d(v)-d(u)&lt;=w(u,v),每个未知数对应一个顶点,每个不等式对应一条边,(xi-xjvj,权值为c),最后在图上求一次最短路,则所有不等式都会满足,</p>

<p>图中的源点可以任意选择.也可建立一个x0作为源点.x0的相关性质可以任意设置.</p>

<p>参考资料: 差分约束系统.doc</p>

<p>3.二分图</p>

<p> 二分图又称作二部图，是图论中的一种特殊模型。</p>

<p> 设G=(V,{R})是一个无向图。如顶点集V可分割为两个互不相交的子集，并且图中每条边依附的两个顶点都分属两个不同的子集。则称图G为二分图。</p>

<p> 给定一个二分图G，在G的一个子图M中，M的边集{E}中的任意两条边都不依附于同一个顶点，则称M是一个匹配。</p>

<p> 选择这样的边数最大的子集称为图的最大匹配问题(maximal matching problem)</p>

<p> 如果一个匹配中，图中的每个顶点都和图中某条边相关联，则称此匹配为完全匹配，也称作完备匹配。</p>

<p>匈牙利算法：</p>

<p>不断寻找增广路经，其核心是DFS。</p>

<p>bool path (int u)</p>

<p>{</p>

<p>sx [u] = true;</p>

<p>for (int v = 0; v &lt; n; v ++)</p>

<p>if (!sy [v] &amp;&amp; lx[u] + ly [v] == weight [u] [v])</p>

<p>{</p>

<p>sy [v] = true;</p>

<p>if (match [v] == -1 || path (match [v]))</p>

<p>{</p>

<p>match [v] = u;</p>

<p>return true;</p>

<p>}</p>

<p>}</p>

<p>return false;</p>

<p>}</p>

<p>对每个顶点求一次增广路经即可。（可以证明，如果某次从某个顶点出发可以找到一条增广路经，则</p>

<p>以后不可能再该定点找到增光路经，而如果某个定点出发找到了增广路经，则该店就成为路经中的点）</p>

<p>&bull; 如果边上带权的话，找出权和最大的匹配叫做求最佳匹配</p>

<p>KM算法：</p>

<p>&bull; 设M是一个带权完全二分图G的一个完备匹配，给每个顶点一个可行顶标(第i个x顶点的可行标用lx[i]表示，第j个y顶点的可行标用ly[j]表示)，如果对所有的边(i,j)</p>

<p>in G,都有lx[i]+ly[j]&gt;=w[i,j]成立(w[i,j]表示边的权)，且对所有的边(i,j) in M,都有lx[i]+ly[j]=w[i,j]成立，则M是图G的一个最佳匹配。</p>

<p>步骤：</p>

<p>　　　(1)初始化可行顶标的值（l(x) =</p>

<p>maxw(x,y),l(y) = 0</p>

<p>　　　(2)用匈牙利算法寻找完备匹配</p>

<p>　(3)若未找到完备匹配则修改可行顶标的值（根据最后一次不成功的寻找交错路的DFS，取所有i被访问到而j没被访问到的边(i,j)的lx[i]+ly[j]-w[i][j]的最小值d。将交错树中的所有左端点的顶标减小d，右端点的顶标增加d。）</p>

<p>(4)重复(2)(3)直到找到相等子图的完备匹配为止</p>

<p>优化：设slack[j]表示右边的点j的所有不在导出子图的边对应的lx[i]+ly[j]-w[i][j]的最小值，在find过程中，若某条边不在导出子图中就用它对相应的slack值进行更新。然后求只要用O(N)的时间找到slack中的最小值就可以用其调整权值了。（代码参考code/图/KM2）</p>

<p>优化前O（N3），优化后O(N2)</p>

<p>参考资料：二分图匹配.ppt</p>

<p>4.最短路(SPFA,Dijkstra)</p>

<p>SPFA算法可以处理负边。dij算法中每条边的最短路径值仅会受到在层次图中层次小于它的点影响，确　</p>

<p>定后不会改变，SPFA没有这些特点，所以可以通过多次迭代确定最短路。</p>

<p>具体参考。</p>

<p>参考资料：SPFA与Dijkstra,doc</p>

<p>5.欧拉回路</p>

<p>Fleury算法</p>

<p>　（1）任取v0&isin;V(G)，令P0=v0.</p>

<p>　（2）设Pi=v0e1v1e2&hellip;eivi已经行遍，按下面方法来从E(G)-{e1,e2,&hellip;,ei}中选取ei+1：</p>

<p>　　　（a）ei+1与vi相关联；</p>

<p>　　　（b）除非无别的边可供行遍，否则ei+1不应该为Gi=G-{e1,e2,&hellip;,ei}中的桥。</p>

<p>　（3）当（2）不能再进行时，算法停止。</p>

<p>连环法（未完成）</p>

<p>6.最优比率生成树</p>

<p>概念：</p>

<p>有带权图G, 对于图中每条边e[i], 都有c[i](收入)和d[i](花费), 我们要求的是一棵生成树T, 它使得有：&sum;(c[i]) / &sum;(d[i]), i&isin;T</p>

<p>最大(或最小).</p>

<p>0-1分数规划解法：</p>

<p>r=cx/dx (c,d,x都是向量) ,求最小的r,设为r*</p>

<p>z=cx-l*dx(1)把它的最小值记为z(l),对一个确定的l解释以lc-d为权的最小生成树.</p>

<p>若z(r*)<0;存在一组x使r\*>cx/dx,与r*是cx/dx的最小值矛盾.</p>

<p>若z(r*)&gt;0,不可能,因为有一组x*使r*=cx*/dx*,把这组x代入(1)得0,必有最小值&lt;=0</p>

<p>所以z(r*)==0;</p>

<p>z(l)递减</p>

<p>按上述二分查找计算</p>

<p>参考资料：最优比率生成树.doc</p>

<p>参考资料：最优比率生成树.doc</p>

<p>7.关键路径</p>

<p>如果有：整个工程完成的时间为：从有向图的源点到汇点的最长路径。</p>

<p>&ldquo;关键活动&rdquo;指的是：该弧上的权值增加 将使有向图上的最长路径的长度增加。</p>

<p>解法：DP递推</p>

<p>&ldquo;事件(顶点)&rdquo; 的 最早发生时间 ve(j)</p>

<p>ve(j) = 从源点到顶点j的最长路径长度;</p>

<p>&ldquo;事件(顶点)&rdquo; 的 最迟发生时间 vl(k)</p>

<p>vl(k) = 从顶点k到汇点的最短路径长度;</p>

<p>假设第 i 条弧为</p>

<p>则 对第 i 项活动言</p>

<p>&ldquo;活动(弧)&rdquo;的 最早开始时间 e(i)</p>

<p>e(i) = ve(j);</p>

<p>&ldquo;活动(弧)&rdquo;的 最迟开始时间 l(i)</p>

<p>l(i) = vl(k) &ndash; dut();</p>

<p>状态转移方程</p>

<p>ve(k) = Max{ve(j) + dut()}</p>

<p>vl(j) = Min{vl(k) &ndash; dut()}</p>

<p>解：</p>

<p>e(i) = ve(j);</p>

<p>l(i) = vl(k) &ndash; dut();</p>

<p>8.网络流(流的算法/应用)</p>

<p>最大流算法(3种)</p>

<ol>
<li>基本最大流算法 &mdash;&ndash; Edmonds-Karp算法</li>
</ol>

<p>O(VE2)</p>

<p>　　通过DFS每次寻找最短的增广路径增流。核心BFS。</p>

<p>2.dinic算法 O(V2E) BFS建立层次网络，DFS找增广路经增幅．</p>

<p>BFS 寻找终点太慢，而 DFS 又不能保证找到最短路径。1970年 Dinic 提出一种思想，结合了 BFS 与 DFS 的优势，</p>

<p>采用构造分层网络的方法可以较快找到最短增广路，此算法又称为阻塞流算法 (Blocking Flow</p>

<p>Algorithm)。</p>

<p>首先定义分层网络 AN(f)。在残量网络中从源点 s 起始进行 BFS，这样每个顶点在 BFS 树中会得到一个距源点s 的距离 d，如 d(s) = 0，直接从 s 出发可到达的点距离为 1，下一层距离为2 &hellip; 。称所有具有相同距离的顶点位于同一层，在分层网络中，只保留满足条件 d(i) +</p>

<p>1 = d(j) 的边，这样在分层网络中的任意路径就成为到达此顶点的最短路径。</p>

<p>Dinic 算法每次用一遍 BFS 构建分层网络 AN(f)，然后在 AN(f) 中一遍 DFS 找到所有到终点 t 的路径增广；之后重新构造 AN(f)，若终点 t 不在 AN(f) 中则算法结束。</p>

<ol>
<li>ISAP O(VE2)</li>
</ol>

<p>　通常的 SAP 类算法在寻找增广路时总要先进行 BFS，BFS 的最坏情况下复杂度为 O(E)，这样使得普通SAP 类算法最坏情况下时间复杂度达到了 O(VE2)。为了避免这种情况，Ahuja 和 Orlin 在1987年提出</p>

<p>了Improved SAP 算法，它充分利用了距离标号的作用，每次发现顶点无出弧时不是像 Dinic 算法那样到最后进行 BFS，而是就地对顶点距离重标号，这样相当于在遍历的同时顺便构建了新的分层网络，每轮寻找之间不必再插入全图的 BFS 操作，极大提高了运行效率。国内一般把这个算法称为 SAP&hellip;显然　这是不准确的，毕竟从字面意思上来看 E-K 和 Dinic 都属于 SAP，我还是习惯称为 ISAP 或改进的 SAP 算法。</p>

<p>　与 Dinic 算法不同，ISAP 中的距离标号是每个顶点到达终点 t 的距离。同样也不需显式构造分层网　</p>

<p>　络，只要保存每个顶点的距离标号即可。程序开始时用一个反向 BFS 初始化所有顶点的距离标号，之后从源点开始，进行如下三种操作：(1)当前顶点 i 为终点时增广 (2)</p>

<p>当前顶点有满足 dist[i] = dist[j] + 1的出弧时前进 (3) 当前顶点无满足条件的出弧时重标号并回退一步。整个循环当源点 s 的距离标号</p>

<p>dist[s] &gt;= n 时结束。对 i 点的重标号操作可概括为 dist[i] = 1 + min{dist[j] : (i,j)属于残量网络</p>

<p>Gf}。</p>

<p>实现代码见code/图/最大流多种实现-1273</p>

<p>最小费用最大流算法</p>

<p>每次增广所有路径中单位费用和最小的一条即可。</p>

<p>图的连通性（最小点割集）</p>

<p>构图求最大流：(未完成)</p>

<p>　</p>

<p>代码code图tojd</p>

<p>混合欧拉回路</p>

<p>构图求最大流：</p>

<p>(关键:欧拉回路存在的条件是每个个点的入度等于出度)</p>

<p>把该图的无向边随便定向，计算每个点的入度和出度。如果有某个点出入度之差为奇数，那么肯定不存在欧拉回路。因为欧拉回路要求每点入度 = 出度，也就是总度数为偶数，存在奇数度点必不能有欧拉回路。好了，现在每个点入度和出度之差均为偶数。那么将这个偶数除以2，得x。也就是说，对于每一个点，只要将x条边改变方向（入&gt;出就是变入，出&gt;入就是变出），就能保证出 = 入。如果每个点都是出= 入，那么很明显，该图就存在欧拉回路。</p>

<p>现在的问题就变成了：我该改变哪些边，可以让每个点出 = 入？构造网络流模型。首先，有向边是不能改变方向的，要之无用，删。一开始不是把无向边定向了吗？定的是什么向，就把网络构建成什么样，边长容量上限1。另新建s和t。对于入 &gt; 出的点u，连接边(u, t)、容量为x，对于出 &gt; 入的点v，连接边(s, v)，容量为x（注意对不同的点x不同）。之后，察看是否有满流的分配。有就是能有欧拉回路，没有就是没有。欧拉回路是哪个？察看流值分配，将所有流量非 0（上限是1，流值不是0就是1）的边反向，就能得到每点入度 = 出度的欧拉图。 由于是满流，所以每个入 &gt; 出的点，都有x条边进来，将这些进来的边反向，OK，入 = 出了。对于出 &gt; 入的点亦然。那么，没和s、t连接的点怎么办？和s连接的条件是出 &gt; 入，和t连接的条件是入</p>

<blockquote>
<p>出，那么这个既没和s也没和t连接的点，自然早在开始就已经满足入 = 出了。那么在网络流过程中，这些点属于&ldquo;中间点&rdquo;。我们知道中间点流量不允许有累积的，</p>
</blockquote>

<p>这样，进去多少就出来多少，反向之后，自然仍保持平衡。</p>

<p>代码：code图1637</p>

<p>9.其他图论相关问题算法:</p>

<p>K短路</p>

<p>A*搜索，搜索到终点K次时走的路径</p>

<p>函数:f(x)=h(x)+g(x) h(x)&mdash;点离目标点的距离(估计值) g(x)&mdash;点离起点的距离（确定值）</p>

<p>估计值可用反向dij得到的值代替，也可以跟据情况用其他值估计。</p>

<p>代码：code图2449</p>

<p>图的单向连通（包括2次DFS缩点）</p>

<p>判断途中任意两点是否存在至少一条通路．</p>

<p>首先，如果把句子&ldquo;either go from x to y, or from y to x.&rdquo;改为&ldquo;both go from x to y, and from 　y to x.&rdquo;则题意即为求证图是否为</p>

<p>强连通图。求强连通图的方法有很多，最简单的是从点v开始，正向floodfill一遍，反向floodfill一遍，然后其交集即为包含点v的最大强连通子图。</p>

<p>然而这道题要求判断的是是否为单向连通图，即对于任意两点u,v，要么存在路径从u到v，要么存在路径从v到u。</p>

<p>首先，强连通图肯定是单向连通图，但是反之不然。</p>

<p>其次，如果图中不存在任意一对双向连通的点，则该图肯定是有向无环图。考虑该图的拓扑序，则若存在序u&gt;v，必说明存在一条路从u到v。如</p>

<p>果上图还是单向连通图，说明任意两点都有序，则由有向无环的性质，该序可以唯一确定。则依该序排序图中所有点，结果必然唯一。即存在一条路，从某个点出发，到另一个点截止，中间经过所有的结点。</p>

<p>所以，只要把图中所有的最大强连通子图都找出来，并且各自缩为单一点。这样重构的图要么是一个点，要么是有向无环图。后者的话，做一次拓扑排序，只要在某一刻存在两个以上的点入度为0的话就判错；其他情况都判对。</p>

<p>　代码：code图2728</p>

<p>　缩点可参考　code图2443</p>

<p>四．其他</p>

<p>1.计算几何</p>

<p>注意模板的使用与精度问题</p>

<p>凸包问题</p>

<p>直线，点的各种关系的计算</p>

<p>点乘与叉乘</p>

<p>2.数学(数论,组合数学,数值计算)</p>

<p>数论：质数问题,分解因素，模预算，中国剩余定理(见附录)，进制转换</p>

<p>组合数学：容斥定理，雀巢定理，Catalan number</p>

<p>数值计算：二分法(f(x)=0) ,迭代法(g(x)=x)</p>

<p>五．附录</p>

<p>1.A*算法</p>

<p>在启发式搜索中，对于每个状态 x，启发函数 f(x) 通常是这样的形式：</p>

<p>f(x) = g(x) + h(x)</p>

<p>其中 g(x) 是从初始状态走到 x 所花的代价；h(x) 是从 x 走到目标状态所需要的代价的估计值。</p>

<p>相对于 h(x)，还有一个概念叫 h*(x)，表示从 x 走到目标状态所需要的实际最小代价（当然，这个值有时我们是事先无法知道的）。</p>

<p>如果在你的启发函数里，能保证 h(x) &lt;= h*(x)，也就是说，你不能高估了从 x 走到目标状态所需要的代价，那就可以说这个搜索是 A* 算法（这里的&ldquo;*&rdquo;，英文就读作 star）。</p>

<p>A* 算法的特点是，如果存在从初始状态走到目标状态的最小代价的解，那么用 A* 算法搜索时，第一个找到的解就一定是最小代价的。这就是所谓的可采纳（admissible）。</p>

<p>例:求前 K 短的 可以带环的 路径（的长度）</p>

<p>1.1. 典型的启发式搜索</p>

<p>设起点为 s；终点为 t；对于一个点 v，dt(v) 表示从 v 走到 t 的最短路径的长度（可以在初始化的时候全都算好）。</p>

<p>网友 richard 教会了我，可以用最典型的启发式搜索来解这个问题。一个状态 x 表示的是从 s 走到某个点的一条路径，把这个点记作 x.v，把这条路径的长度记作 x.len。接着，我们可以使用以下启发函数：</p>

<p>g(x) = x.len; h(x) = dt(x.v);</p>

<p>&there4; f(x) = g(x) + h(x) = x.len + dt(x.v)</p>

<p>初始状态中， x.v = s； x.len = 0。然后每次让优先队列（所谓的 Open 表）中 f(x) 值最小的状态 x 出队，再跟据图中所有从 x.v 出发的边发展下一层状态，让它们进队列。优先队列中不存在判重复的问题，因为每个状态所代表的路径肯定是不一样的。</p>

<p>不难想通，这是一个 A* 算法，因为这里的 h(x) 本身就是 h*(x)，当然满足 h(x) &lt;= h*(x)。因此可以说，在每次出队列的状态 x 中，第一次遇到 x.v == t 时，就找到了从 s 到 t 的第一短的路径，它的长度就是</p>

<p>f(x)&hellip;&hellip;第 k 次遇到 x.v == t 时，就找到了从 s 到 t 的第 k 短的路径。</p>

<p><a href="http://zone.emsky.net/?uid-2-action-viewspace-itemid-118">http://zone.emsky.net/?uid-2-action-viewspace-itemid-118</a> A*寻路.</p>

<p>2.位运算之格雷码：</p>

<p>这种遍历顺序作为一种编码方式存在，叫做Gray码（写个中文让蜘蛛来抓：格雷码）。它的应用范围很广。比如，n阶的Gray码相当于在n维立方体上的Hamilton回路，因为沿着立方体上的边走一步，n维坐标中只会有一个值改变。再比如，Gray码和Hanoi塔问题等价。Gray码改变的是第几个数，Hanoi塔就该移动哪个盘子。比如，3阶的Gray码每次改变的元素所在位置依次为1-2-1-3-1-2-1，这正好是3阶Hanoi塔每次移动盘子编号。如果我们可以快速求出Gray码的第n个数是多少，我们就可以输出任意步数后Hanoi塔的移动步骤。现在我告诉你，Gray码的第n个数（从0算起）是n xor (n</p>

<p>shr 1)，你能想出来这是为什么吗？先自己想想吧。</p>

<p>下面我们把二进制数和Gray码都写在下面，可以看到左边的数异或自身右移的结果就等于右边的数。</p>

<p>二进制数 Gray码</p>

<p>000 000</p>

<p>001 001</p>

<p>010 011</p>

<p>011 010</p>

<p>100 110</p>

<p>101 111</p>

<p>110 101</p>

<p>111 100</p>

<p>从二进制数的角度看，&ldquo;镜像&rdquo;位置上的数即是对原数进行not运算后的结果。比如，第3个数010和倒数第3个数101的每一位都正好相反。假设这两个数分别为x和y，那么x xor (x shr 1)和y</p>

<p>xor (y shr 1)的结果只有一点不同：后者的首位是1，前者的首位是0。而这正好是Gray码的生成方法。这就说明了，Gray码的第n个数确实是n xor</p>

<p>(n shr 1)。</p>

<p>今年四月份mashuo给我看了这道题，是二维意义上的Gray码。题目大意是说，把0到2^(n+m)-1的数写成2^n *</p>

<p>2^m的矩阵，使得位置相邻两数的二进制表示只有一位之差。答案其实很简单，所有数都是由m位的Gray码和n位Gray码拼接而成，需要用左移操作和or运算完成。完整的代码如下：</p>

<p>var</p>

<p>x,y,m,n,u:longint;</p>

<p>begin</p>

<p>readln(m,n);</p>

<p>for x:=0 to 1 shl m-1 do begin</p>

<p>u:=(x xor (x shr 1)) shl n; //输出数的左边是一个m位的Gray码</p>

<p>for y:=0 to 1 shl n-1 do</p>

<p>write(u or (y xor (y shr 1)),&#8217; &#8216;); //并上一个n位Gray码</p>

<p>writeln;</p>

<p>end;</p>

<p>end.</p>

<p>3,线性同余方程</p>

<p>问题简单来说就是 a = ai (mod ni) 求未知数a,</p>

<p>以下小结略去证明, 只是对定理作了必要的解释, 要了解相关定理,可查阅数论资料.</p>

<p>中国余数定理:</p>

<p>设 n=n1*n2&#8230;nk, 其中因子两两互质.有: a&#8212;&#8211;(a1,a2,&#8230;,ak), 其中ai = a mod ni, 则 a和(a1,a2,&#8230;,ak)关系是一一对应的.就是说可以由 a求出(a1,a2,&#8230;,ak),</p>

<p>也可以由(a1,a2,&#8230;,ak)求出a</p>

<p>推论1:</p>

<p>对于 a=ai (mod ni) 的同余方程,有唯一解</p>

<p>下面说说由(a1, a2, &#8230;, ak)求a的方法:</p>

<p>定义 mi = n1*n2*&#8230;nk / ni; ci = mi(mf mod ni); 其中 mi*mf mod ni = 1;</p>

<p>则 a = (a1*c1+a2*c2+&#8230;+ak*ck) (mod n) (注:由此等式可求a%n, 当n很大时)</p>

<p>中国剩余定理关键是mf的求法,如果理解了扩展欧几里得 ax+by=d, 就可以想到:</p>

<p>mi*mf mod ni = 1 =&gt; mi*mf+ni*y=1;</p>

<p>代码如下:</p>

<p>#include</p>

<p>#include</p>

<p>using namespace std;</p>

<p>const int MAXN = 100;</p>

<p>int nn, a[MAXN], n[MAXN];</p>

<p>int egcd(int a, int b, int &amp;x, int &amp;y) {</p>

<p>int d;</p>

<p>if (b == 0) {</p>

<p>x = 1; y = 0;</p>

<p>return a;</p>

<p>} else {</p>

<p>d = egcd(b, a%b, y, x);</p>

<p>y -= a/b*x;</p>

<p>return d;</p>

<p>}</p>

<p>}</p>

<p>int lmes() {</p>

<p>int i, tm=1, mf, y, ret=0, m;</p>

<p>for (i=0; i for (i=0; i</p>

<p>m = tm/n[i];</p>

<p>egcd(m, n[i], mf, y);</p>

<p>ret += (a[i]*m*(mf%n[i]))%tm;</p>

<p>}</p>

<p>return (ret+tm)%tm;</p>

<p>}</p>

<p>int main() {</p>

<p>a[0] = 4; a[1] = 5;</p>

<p>n[0] = 5; n[1] = 11;</p>

<p>nn = 2;</p>

<p>printf(&#8220;%dn&#8221;, lmes());</p>

<p>return 0;</p>

<p>}</p>

<p>附录2:</p>

<p>求最小点基 &lt;图论算法与程序设计&gt; P49</p>

<p>求点连通度 &lt;图论算法与程序设计&gt; P102</p>

<p>&nbsp;</p>

<p>附：北邮ACM50题</p>

<p>第一类 动态规划 (至少6题，2479 and 2593必做)</p>

<p>2479 and 2593 1015 1042 (也可贪心) 1141 1050 1080 1221 1260 2411 (稍难) 1276</p>

<p>第二类 搜索 (至少4题)</p>

<p>1011 1033 1129 2049 2056 2488 2492 (稍难，也可并查集)</p>

<p>第三类 贪心 (至少2题)</p>

<p>1065 2054 (难) 1521 2709</p>

<p>第四类 最短路 (至少3题)</p>

<p>1062 1125 1797 2253 2679 Bellman-Ford (难)</p>

<p>第五类 最小生成树 (至少2题, 而且 Prim 和 Kruskal 至少各用一次)</p>

<p>1251 1258 1789 2485</p>

<p>第六类 最大流 (至少2题)</p>

<p>1087 1459 1149 2516 (最小费用最大流) (难)</p>

<p>第七类 二分图 (至少3题)</p>

<p>1325 1469 2195 (KM 算法或最小费用最大流) (难) 2446 1422 and 2594</p>

<p>第八类 并查集 (至少2题)</p>

<p>1861 1182 (难) 1308 2524</p>

<p>第九类 快速查找 (B-Search, Hash and so on) (至少3题)</p>

<p>2503 2513 (+Euler回路的判定) 1035 1200 2002</p>

<p>第十类 数论 (至少2题)</p>

<p>1061 1142 2262 2407 1811(难) 2447 (难)</p>

<p>第十一类 线段树 (无最少题数要求)</p>

<p>2352 (可用简单方法) 2528</p>

<p>第十二类 计算几何 (至少2题，1113凸包算法必做)</p>

<p>1113 1292 2148 (难) 2653 1584</p>

<p>第十三类 高精度 (至少3题，1001必做)</p>

<p>1001 1047 1131 1503 1504 1060 and 1996 (多项式) SCU1002, 1003, 1004 (<a href="http://acm.scu.edu.cn/soj">http://acm.scu.edu.cn/soj</a>)</p>

<p>第十四类 模拟 (至少5题)</p>

<p>1029 and 1013 1083 and 2028 2234 and 1067 1012 1026 1068 1120 2271 2632</p>

<p>第十五类 数学 (至少4题)</p>

<p>2249 1023 2506 1079 1019 and 1095 1905 and 1064 (二分)</p>

<div>
  <embed id="lingoes_plugin_object" width="0" height="0" type="application/lingoes-npruntime-capture-word-plugin" hidden="true" />
</div>

<p>{{ template &ldquo;_internal/disqus.html&rdquo; . }}</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://luosha865.github.io/archives/24">
        有重复组合数
      </a>
    </h1>

    <span class="post-date">Thu, Apr 2, 2009</span>

    <p>从n个元素中有重复地取r个，不计顺序，则不同的取法有多少种？<br />
这个问题的答案被称为有重复组合数。结果很简洁，是C(n+r-1,r)。(注：这表示从n+r-1个数中取出r个数的组合数)<br />
【证明1】<br />
我们先把原命题具体化。假设这n个元素就是1~n这n个数。&nbsp;<br />
对于每一种选出来的组合a1，a2，a3，&hellip; ，am，我们要求：a1&lt;=a2&lt;=a3&lt;=&hellip;&lt;=ar<br />
我们的目的就是找出这样的a(i)组数<br />
这里我们构造b1=a1，b2= a2+1，&hellip; ，b(i)= a(i)+(i-1)，&hellip; ，b&reg;= a&reg;+(r-1)<br />
于是b(i)和a(i)一一对应，即所求a(i)组数对应于b(i)组数<br />
又：b1<b2<b3<&hellip;<br 且b(i)取值于1~ n+(r-1)  
亦即原命题等价于从1~ n+r-1中取得r个不重复排列数  
来源：<http://zhidao.baidu.com/question/16706714.html><br />
【证明2】<br />
将n个元素看做n个盒子,r看作r个无区别的球,则相当于:<br />
把r个同样的球放入n个顺次排列的盒子,求不计放球顺序的放法种数<br />
用0表示盒子,1表示球<br />
我们把这n个0和r个1写在一行上。<br />
由于球必须放在盒子中,规定某个0之前,到上一个0为止的1的个数,表示该盒子中装的球数<br />
注意到最后一个数必须是0<br />
所以相当于从前面n+r-1个位置中挑出r个位置放1，其余n-1个位置放0<br />
来源：<a href="http://pengzhe0302.spaces.live.com/blog/cns!529d86ea9ec40ca2!113.entry">http://pengzhe0302.spaces.live.com/blog/cns!529d86ea9ec40ca2!113.entry</a></p>

<div>
  <embed id="lingoes_plugin_object" width="0" height="0" type="application/lingoes-npruntime-capture-word-plugin" hidden="true" />
</div>

<p>{{ template &ldquo;_internal/disqus.html&rdquo; . }}</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://luosha865.github.io/archives/25">
        编译原理虎书java版本–Chapter 2-3
      </a>
    </h1>

    <span class="post-date">Sat, Mar 14, 2009</span>

    <p>options {</p>

<p>JAVA_UNICODE_ESCAPE = true;</p>

<p>}</p>

<p>PARSER_BEGIN(MiniJavaParser)</p>

<p>public class MiniJavaParser {}</p>

<p>PARSER_END(MiniJavaParser)</p>

<p>// Insert a specification of a lexical analysis here.</p>

<p>TOKEN :</p>

<p>{</p>

<p>&lt; LPAREN: &#8220;(&#8221; &gt;</p>

<p>| &lt; RPAREN: &#8220;)&#8221; &gt;</p>

<p>| &lt; LSQPAREN: &#8220;[&#8221; &gt;</p>

<p>| &lt; RSQPAREN: &#8220;]&#8221; &gt;</p>

<p>| &lt; LBRACE: &#8220;{&#8221; &gt;</p>

<p>| &lt; RBRACE: &#8220;}&#8221; &gt;</p>

<p>| &lt; DOT: &#8220;.&#8221; &gt;</p>

<p>| &lt; ASSIGN: &#8220;=&#8221; &gt;</p>

<p>| &lt; LT: &#8220;&lt;&#8221; &gt;</p>

<p>| &lt; PLUS: &#8220;+&#8221; &gt;</p>

<p>| &lt; MINUS: &#8220;-&#8221; &gt;</p>

<p>| &lt; AND : &#8220;&amp;&amp;&#8221; &gt;</p>

<p>| &lt; NOT : &#8220;!&#8221; &gt;</p>

<p>| &lt; SEMICOLON: &#8220;;&#8221; &gt;</p>

<p>| &lt; PUBLIC: &#8220;public&#8221; &gt;</p>

<p>| &lt; RETURN: &#8220;return&#8221; &gt;</p>

<p>| &lt; BOOLEAN: &#8220;boolean&#8221; &gt;</p>

<p>| &lt; CLASS: &#8220;class&#8221; &gt;</p>

<p>| &lt; INTERFACE: &#8220;interface&#8221; &gt;</p>

<p>| &lt; ELSE: &#8220;else&#8221; &gt;</p>

<p>| &lt; EXTENDS: &#8220;extends&#8221; &gt;</p>

<p>| &lt; FALSE: &#8220;false&#8221; &gt;</p>

<p>| &lt; IF: &#8220;if&#8221; &gt;</p>

<p>| &lt; WHILE: &#8220;while&#8221; &gt;</p>

<p>| &lt; INTEGER: &#8220;int&#8221; &gt;</p>

<p>| &lt; LENGTH: &#8220;length&#8221; &gt;</p>

<p>| &lt; MAIN: &#8220;main&#8221; &gt;</p>

<p>| &lt; NEW: &#8220;new&#8221; &gt;</p>

<p>| &lt; STATIC: &#8220;static&#8221; &gt;</p>

<p>| &lt; STRING: &#8220;String&#8221; &gt;</p>

<p>| &lt; THIS: &#8220;this&#8221; &gt;</p>

<p>| &lt; TRUE: &#8220;true&#8221; &gt;</p>

<p>| &lt; PRINT: &#8220;System.out.println&#8221; &gt;</p>

<p>| &lt; VOID: &#8220;void&#8221; &gt;</p>

<p>}</p>

<p>TOKEN : /* LITERALS */</p>

<p>{</p>

<p>&lt; INTEGER_LITERAL: ( [&#8220;1&#8243;-&#8220;9&#8243;] ([&#8220;0&#8243;-&#8220;9&#8243;])* | &#8220;0&#8221; ) &gt;</p>

<p>}</p>

<p>TOKEN : /* IDENTIFIERS */</p>

<p>{</p>

<p>&lt; IDENTIFIER: <LETTER> (<LETTER>|<DIGIT>)* &gt;</p>

<p>|</p>

<p>&lt; #LETTER:</p>

<p>[</p>

<p>&#8220;u0024&#8243;,</p>

<p>&#8220;u0041&#8243;-&#8220;u005a&#8221;,</p>

<p>&#8220;u005f&#8221;,</p>

<p>&#8220;u0061&#8243;-&#8220;u007a&#8221;,</p>

<p>&#8220;u00c0&#8243;-&#8220;u00d6&#8243;,</p>

<p>&#8220;u00d8&#8243;-&#8220;u00f6&#8243;,</p>

<p>&#8220;u00f8&#8243;-&#8220;u00ff&#8221;,</p>

<p>&#8220;u0100&#8243;-&#8220;u1fff&#8221;,</p>

<p>&#8220;u3040&#8243;-&#8220;u318f&#8221;,</p>

<p>&#8220;u3300&#8243;-&#8220;u337f&#8221;,</p>

<p>&#8220;u3400&#8243;-&#8220;u3d2d&#8221;,</p>

<p>&#8220;u4e00&#8243;-&#8220;u9fff&#8221;,</p>

<p>&#8220;uf900&#8243;-&#8220;ufaff&#8221;</p>

<p>]</p>

<blockquote>
</blockquote>

<p>|</p>

<p>&lt; #DIGIT:</p>

<p>[</p>

<p>&#8220;u0030&#8243;-&#8220;u0039&#8243;,</p>

<p>&#8220;u0660&#8243;-&#8220;u0669&#8243;,</p>

<p>&#8220;u06f0&#8243;-&#8220;u06f9&#8243;,</p>

<p>&#8220;u0966&#8243;-&#8220;u096f&#8221;,</p>

<p>&#8220;u09e6&#8243;-&#8220;u09ef&#8221;,</p>

<p>&#8220;u0a66&#8243;-&#8220;u0a6f&#8221;,</p>

<p>&#8220;u0ae6&#8243;-&#8220;u0aef&#8221;,</p>

<p>&#8220;u0b66&#8243;-&#8220;u0b6f&#8221;,</p>

<p>&#8220;u0be7&#8243;-&#8220;u0bef&#8221;,</p>

<p>&#8220;u0c66&#8243;-&#8220;u0c6f&#8221;,</p>

<p>&#8220;u0ce6&#8243;-&#8220;u0cef&#8221;,</p>

<p>&#8220;u0d66&#8243;-&#8220;u0d6f&#8221;,</p>

<p>&#8220;u0e50&#8243;-&#8220;u0e59&#8243;,</p>

<p>&#8220;u0ed0&#8243;-&#8220;u0ed9&#8243;,</p>

<p>&#8220;u1040&#8243;-&#8220;u1049&#8243;</p>

<p>]</p>

<blockquote>
</blockquote>

<p>}</p>

<p>SKIP :</p>

<p>{</p>

<p>&lt; &#8221; &#8221; &gt;</p>

<p>| &lt; &#8220;t&#8221; &gt;</p>

<p>| &lt; &#8220;n&#8221; &gt;</p>

<p>| &lt; &#8220;r&#8221; &gt;</p>

<p>| &lt; &#8220;//&#8221; (~[&#8220;n&#8221;])* &#8220;n&#8221; &gt;</p>

<p>| &lt;&#8220;/*&#8221; (~[&#8220;*&#8221;])* &#8220;*&#8221; (~[&#8220;/&#8221;] (~[&#8220;*&#8221;])* &#8220;*&#8221;)* &#8220;/&#8221;&gt;</p>

<p>}</p>

<p>// The following is a simple grammar that will allow you</p>

<p>// to test the generated lexer.</p>

<p>void Program() :</p>

<p>{}</p>

<p>{</p>

<p>MainClass() (ClassDecl())*</p>

<p>}</p>

<p>void MainClass() :</p>

<p>{}</p>

<p>{</p>

<p>&#8220;class&#8221; <IDENTIFIER> &#8220;{&#8221; &#8220;public&#8221; &#8220;static&#8221; &#8220;void&#8221; &#8220;main&#8221; &#8220;(&#8221; &#8220;String&#8221; &#8220;[&#8221; &#8220;]&#8221; <IDENTIFIER> &#8220;{&#8221; Statement() &#8220;}&#8221; &#8220;}&#8221;</p>

<p>}</p>

<p>void ext() :</p>

<p>{}</p>

<p>{</p>

<p>(&#8220;extends&#8221;  <IDENTIFIER> )?</p>

<p>}</p>

<p>void ClassDecl() :</p>

<p>{}</p>

<p>{</p>

<p>&#8220;class&#8221; <IDENTIFIER> ext()  &#8220;{&#8221; (VarDecl())* (MethodDecl())* &#8220;}&#8221;</p>

<p>}</p>

<p>void VarDecl():</p>

<p>{}</p>

<p>{ Type() <IDENTIFIER> &#8220;;&#8221;}</p>

<p>void MethodDecl():</p>

<p>{}</p>

<p>{&#8220;public&#8221; Type() <IDENTIFIER></p>

<p>&#8220;(&#8221; FormaList() &#8220;)&#8221;</p>

<p>&#8220;{&#8221; ( LOOKAHEAD(2) VarDecl() )* (Statement())*  &#8220;return&#8221; Exp() &#8220;;&#8221; &#8220;}&#8221;</p>

<p>}</p>

<p>&nbsp;</p>

<p>void FormaList():</p>

<p>{}</p>

<p>{(Type()  <IDENTIFIER> &#8220;FormalRest()&#8221;)?}</p>

<p>void FormaRest():</p>

<p>{}</p>

<p>{&#8220;,&#8221; Type() <IDENTIFIER>}</p>

<p>void Type():</p>

<p>{}</p>

<p>{<IDENTIFIER></p>

<p>|&#8221;boolean&#8221;</p>

<p>|LOOKAHEAD(2)</p>

<p>&#8220;int&#8221;</p>

<p>|&#8221;int&#8221; &#8220;[&#8221; &#8220;]&#8221;</p>

<p>}</p>

<p>void Statement():</p>

<p>{}</p>

<p>{&#8220;{&#8221; (Statement())* &#8220;}&#8221;</p>

<p>|&#8221;while&#8221; &#8220;(&#8221; Exp() &#8220;)&#8221; Statement()</p>

<p>|&#8221;System.out.println&#8221;  &#8220;(&#8221; Exp() &#8220;)&#8221;</p>

<p>|<IDENTIFIER> instat1() &#8220;=&#8221; Exp() &#8220;;&#8221;</p>

<p>|&#8221;if&#8221; &#8220;(&#8221; Exp() &#8220;)&#8221; Statement() inif()</p>

<p>}</p>

<p>void inif():</p>

<p>{}</p>

<p>{(LOOKAHEAD(2) &#8220;else&#8221; Statement())?}</p>

<p>void instat1():</p>

<p>{}</p>

<p>{(&#8220;[&#8221; Exp() &#8220;]&#8221;)?}</p>

<p>void Exp():</p>

<p>{}</p>

<p>{Expa() (LOOKAHEAD(2) (Expb()))?</p>

<p>}</p>

<p>void Expa():</p>

<p>{}</p>

<p>{&#8220;true&#8221;</p>

<p>|&#8221;false&#8221;</p>

<p>|<IDENTIFIER></p>

<p>|&#8221;this&#8221;</p>

<p>|&#8221;!&#8221; Exp()</p>

<p>|&#8221;(&#8221; Exp() &#8220;)&#8221;</p>

<p>|LOOKAHEAD(2)</p>

<p>&#8220;new&#8221; &#8220;int&#8221; &#8220;[&#8221; Exp() &#8220;]&#8221;</p>

<p>|&#8221;new&#8221; <IDENTIFIER> &#8220;(&#8221; &#8220;)&#8221;</p>

<p>}</p>

<p>void Expb():</p>

<p>{}</p>

<p>{</p>

<p>op() Exp()</p>

<p>|&#8221;[&#8221; Exp() &#8220;]&#8221;Exp()</p>

<p>|LOOKAHEAD(2)</p>

<p>&#8220;.&#8221; &#8220;length&#8221;</p>

<p>|&#8221;.&#8221; <IDENTIFIER></p>

<p>}</p>

<p>void op():</p>

<p>{}</p>

<p>{&#8220;&amp;&amp;&#8221;</p>

<p>|&#8221;&lt;&#8221;</p>

<p>|&#8221;+&#8221;</p>

<p>|&#8221;-&#8221;</p>

<p>|&#8221;*&#8221;}</p>

<p>&nbsp;</p>

<p>void ExpList():</p>

<p>{}</p>

<p>{(Exp()  (ExpRest())*)?}</p>

<p>void ExpRest():</p>

<p>{}</p>

<p>{&#8220;,&#8221; Exp()}</p>

<p>void Goal() :</p>

<p>{}</p>

<p>{</p>

<p>( MiniJavaToken() )*</p>

<p><EOF></p>

<p>}</p>

<p>void MiniJavaToken():</p>

<p>{}</p>

<p>{</p>

<p>&#8220;class&#8221;  |  <IDENTIFIER> | &#8220;{&#8221; | &#8220;public&#8221; | &#8220;static&#8221; | &#8220;void&#8221; |</p>

<p>&#8220;main&#8221; | &#8220;(&#8221; | &#8220;String&#8221;  | &#8220;[&#8221; | &#8220;]&#8221; | &#8220;)&#8221; | &#8220;}&#8221; | &#8220;extends&#8221; | &#8220;;&#8221;</p>

<p>| &#8220;return&#8221; | &#8220;,&#8221; | &#8220;int&#8221; | &#8220;boolean&#8221; | &#8220;=&#8221; | &#8220;if&#8221; | &#8220;else&#8221; | &#8220;while&#8221;</p>

<p>| &#8220;System.out.println&#8221; | &#8220;&amp;&amp;&#8221; | &#8220;&lt;&#8221; | &#8220;+&#8221; | &#8220;-&#8221; | &#8220;*&#8221; | &#8220;.&#8221; |</p>

<p>&#8220;length&#8221; | <INTEGER_LITERAL> | &#8220;true&#8221; | &#8220;false&#8221; | &#8220;this&#8221; | &#8220;new&#8221; |</p>

<p>&#8220;!&#8221;</p>

<p>}</p>

<p>&nbsp;</p>

<p>{{ template &ldquo;_internal/disqus.html&rdquo; . }}</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://luosha865.github.io/archives/26">
        KMP算法复杂度分析
      </a>
    </h1>

    <span class="post-date">Wed, Mar 11, 2009</span>

    <p>KMP算法也算接触很久了，今天却突然发现不知道那个的复杂度是怎么来的<br />
于是想啊想，查啊查，总结如下<br />
设代码为<br />
s=0;<br />
for(i=1;i&lt;=m,i++){<br />
while(s&gt;0&amp;&amp;a[i]!=b[s+1])s=next(s)<br />
if(a[i]==b[s+1])s++;<br />
if(s==n) return (i-n)</p>

<p>分析的关键是那个while循环循环会让s减少<br />
而s又只会在第五行增加，于是j最多增加m次，<br />
在然后我们就知道j最多减少m次(因为不能为负)<br />
平摊到每个for上就是一次<br />
所以复杂度就是O(m)了<br />
不过也有书上说是O(m+n)<br />
这个就不是很明白了&#8230;<br />
想想在说&#8230;..</p>

<div>
  <embed type="application/lingoes-npruntime-capture-word-plugin" width="0" height="0" id="lingoes_plugin_object" hidden="true" />
</div>

<p>{{ template &ldquo;_internal/disqus.html&rdquo; . }}</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://luosha865.github.io/archives/27">
        终于还是开了个blog。。。
      </a>
    </h1>

    <span class="post-date">Sun, Mar 8, 2009</span>

    <p>RT<br />
以后常来看看吧</p>

<p>{{ template &ldquo;_internal/disqus.html&rdquo; . }}</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://luosha865.github.io/archives/28">
        编译原理虎书java版本–Chapter 1
      </a>
    </h1>

    <span class="post-date">Sun, Mar 8, 2009</span>

    <p>Count.java</p>

<p>public class  Count</p>

<p>{</p>

<p>int resolveStm(Stm stm){</p>

<p>int temp1=0,temp2=0;</p>

<p>if(stm.kind==1){</p>

<p>temp1=resolveStm(((CompoundStm)stm).stm1);</p>

<p>temp2=resolveStm(((CompoundStm)stm).stm2);</p>

<p>return temp1&gt;temp2? temp1:temp2;</p>

<p>}else if(stm.kind==2){</p>

<p>return resolveExp(((AssignStm)stm).exp);</p>

<p>}else if (stm.kind==3){</p>

<p>return countExpInExpList(((PrintStm)stm).exps);</p>

<p>}else{</p>

<p>return 0;</p>

<p>}</p>

<p>}</p>

<p>int countExpInExpList(ExpList expList){</p>

<p>if(expList.kind==1){</p>

<p>return 1;</p>

<p>}else if(expList.kind==2){</p>

<p>return 1+countExpInExpList(((PairExpList)expList).tail);</p>

<p>}else{</p>

<p>return 0;</p>

<p>}</p>

<p>}</p>

<p>int resolveExp(Exp exp){</p>

<p>int temp1,temp2;</p>

<p>if(exp.kind==1){</p>

<p>return 0;</p>

<p>}else if(exp.kind==2){</p>

<p>return 0;</p>

<p>}else if(exp.kind==3){</p>

<p>temp1 = resolveExp(((OpExp)exp).left);</p>

<p>temp2 = resolveExp(((OpExp)exp).right);</p>

<p>return temp1&gt;temp2?temp1:temp2;</p>

<p>}else if(exp.kind==4){</p>

<p>temp1=resolveStm(((EseqExp)exp).stm);</p>

<p>temp2=resolveExp(((EseqExp)exp).exp);</p>

<p>return temp1&gt;temp2?temp1:temp2;</p>

<p>}else{</p>

<p>return 0;</p>

<p>}</p>

<p>}</p>

<p>int resolveExpList(ExpList expList){</p>

<p>int temp1,temp2;</p>

<p>if(expList.kind==2){</p>

<p>temp1 = resolveExp(((PairExpList)expList).head);</p>

<p>temp2 = resolveExpList(((PairExpList)expList).tail);</p>

<p>return temp1&gt;temp2?temp1:temp2;</p>

<p>}else if(expList.kind==1){</p>

<p>return resolveExp(((LastExpList)expList).last);</p>

<p>}else{</p>

<p>return 0;</p>

<p>}</p>

<p>}</p>

<p>}</p>

<p>Interp.java</p>

<p>public class  Interp</p>

<p>{</p>

<p>void startinterpStm(Stm stm){</p>

<p>Table t=new Table(null,0,null);</p>

<p>interpStm(stm,t);</p>

<p>}</p>

<p>Table interpStm(Stm stm,Table t){</p>

<p>if(stm.kind==1){</p>

<p>Table t1=interpStm(((CompoundStm)stm).stm1,t);</p>

<p>Table t2=interpStm(((CompoundStm)stm).stm2,t1);</p>

<p>return t2;</p>

<p>}else if(stm.kind==2){</p>

<p>IntAndTable it1 = interExp(((AssignStm)stm).exp,t);</p>

<p>Table t1=update(it1.t,((AssignStm)stm).id,it1.i);</p>

<p>return t1;</p>

<p>}else if(stm.kind==3){</p>

<p>printExplist(((PrintStm)stm).exps,t);</p>

<p>return t;</p>

<p>}else{</p>

<p>return t;</p>

<p>}</p>

<p>}</p>

<p>IntAndTable interExp(Exp exp,Table t){</p>

<p>if(exp.kind==1){</p>

<p>int temp=lookup(t,((IdExp)exp).id);</p>

<p>return new IntAndTable(temp,t);</p>

<p>}else if(exp.kind==2){</p>

<p>return new IntAndTable(((NumExp)exp).num,t);</p>

<p>}else if(exp.kind==3){</p>

<p>IntAndTable it1= interExp(((OpExp)exp).left,t);</p>

<p>IntAndTable it2= interExp(((OpExp)exp).right,it1.t);</p>

<p>int x1,x2,result;</p>

<p>x1=it1.i;</p>

<p>x2=it2.i;</p>

<p>if(((OpExp)exp).oper==1){</p>

<p>result=x1+x2;</p>

<p>}else if(((OpExp)exp).oper==2){</p>

<p>result=x1-x2;</p>

<p>}else if(((OpExp)exp).oper==3){</p>

<p>result=x1*x2;</p>

<p>}else if(((OpExp)exp).oper==4){</p>

<p>result=x1/x2;</p>

<p>}else{</p>

<p>result=0;</p>

<p>}</p>

<p>return new IntAndTable(result,t);</p>

<p>}else if(exp.kind==4){</p>

<p>Table t1=interpStm(((EseqExp)exp).stm,t);</p>

<p>IntAndTable t3= interExp(((EseqExp)exp).exp,t1);</p>

<p>return t3;</p>

<p>}else{</p>

<p>return new IntAndTable(0,t);</p>

<p>}</p>

<p>}</p>

<p>Table update(Table t1,String i,int v){</p>

<p>Table t2=new Table(i,v,t1);</p>

<p>return t2;</p>

<p>}</p>

<p>int lookup(Table t,String key){</p>

<p>if(key.compareTo(t.id)==0){</p>

<p>return t.value;</p>

<p>}else return lookup(t.tail,key);</p>

<p>}</p>

<p>void printExplist(ExpList exps,Table t){</p>

<p>if(exps.kind==1){</p>

<p>IntAndTable temp=interExp(((LastExpList)exps).last,t);</p>

<p>System.out.println(temp.i);</p>

<p>}else if(exps.kind==2){</p>

<p>IntAndTable temp=interExp(((PairExpList)exps).head,t);</p>

<p>System.out.print(temp.i+&#8221; &#8220;);</p>

<p>printExplist(((PairExpList)exps).tail,t);</p>

<p>}else return;</p>

<p>}</p>

<p>// IntAndTable interExpList(ExpList explist,Table t){</p>

<p>// }</p>

<p>}</p>

<p>class Table</p>

<p>{</p>

<p>String id;</p>

<p>int value;</p>

<p>Table tail;</p>

<p>Table(String i,int v,Table t){id=i;value=v;tail=t;}</p>

<p>}</p>

<p>class IntAndTable</p>

<p>{</p>

<p>int i;</p>

<p>Table t;</p>

<p>IntAndTable(int ii,Table tt){i=ii;t=tt;};</p>

<p>}</p>

<p>{{ template &ldquo;_internal/disqus.html&rdquo; . }}</p>

  </div>
  
</div>
</div>

  </body>
</html>
